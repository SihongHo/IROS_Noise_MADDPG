Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  1.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -22.475036879241443, agent episode reward: [-36.03806510310848, 6.781514111933514, 6.781514111933514], time: 69.624
steps: 49975, episodes: 2000, mean episode reward: -19.52863920771805, agent episode reward: [-23.265416381149052, 1.8683885867154997, 1.8683885867154997], time: 122.107
steps: 74975, episodes: 3000, mean episode reward: -3.55578688105286, agent episode reward: [-12.55533642607401, 4.499774772510576, 4.499774772510576], time: 135.458
steps: 99975, episodes: 4000, mean episode reward: 2.128983520495788, agent episode reward: [-10.95503902515349, 6.542011272824639, 6.542011272824639], time: 136.009
steps: 124975, episodes: 5000, mean episode reward: 2.942707187554527, agent episode reward: [-9.606985356797558, 6.274846272176043, 6.274846272176043], time: 135.005
steps: 149975, episodes: 6000, mean episode reward: 2.1532955738642983, agent episode reward: [-9.353919769161243, 5.753607671512771, 5.753607671512771], time: 135.501
steps: 174975, episodes: 7000, mean episode reward: 2.4018780920574225, agent episode reward: [-8.919616759850669, 5.660747425954046, 5.660747425954046], time: 135.767
steps: 199975, episodes: 8000, mean episode reward: 2.0322198092938892, agent episode reward: [-9.766844668773498, 5.899532239033693, 5.899532239033693], time: 134.774
steps: 224975, episodes: 9000, mean episode reward: 1.9182360554945297, agent episode reward: [-10.199396964560579, 6.058816510027555, 6.058816510027555], time: 136.402
steps: 249975, episodes: 10000, mean episode reward: 2.110547288242252, agent episode reward: [-10.290130265061318, 6.200338776651786, 6.200338776651786], time: 136.112
steps: 274975, episodes: 11000, mean episode reward: 1.4720314184319727, agent episode reward: [-10.88717976996797, 6.1796055941999715, 6.1796055941999715], time: 136.064
steps: 299975, episodes: 12000, mean episode reward: 1.8471560035536303, agent episode reward: [-11.15348237586633, 6.500319189709979, 6.500319189709979], time: 136.303
steps: 324975, episodes: 13000, mean episode reward: 1.7036132460793263, agent episode reward: [-11.417325617153168, 6.560469431616248, 6.560469431616248], time: 135.547
steps: 349975, episodes: 14000, mean episode reward: 0.9552257222878131, agent episode reward: [-10.71955748728493, 5.837391604786371, 5.837391604786371], time: 135.712
steps: 374975, episodes: 15000, mean episode reward: 0.5797937977810754, agent episode reward: [-10.670956404330616, 5.625375101055846, 5.625375101055846], time: 136.264
steps: 399975, episodes: 16000, mean episode reward: 0.4968016993860898, agent episode reward: [-11.183331996398108, 5.8400668478921, 5.8400668478921], time: 135.125
steps: 424975, episodes: 17000, mean episode reward: 0.4575410681089179, agent episode reward: [-10.70931757861053, 5.583429323359725, 5.583429323359725], time: 136.011
steps: 449975, episodes: 18000, mean episode reward: 0.27813440258857614, agent episode reward: [-11.392294888120292, 5.8352146453544345, 5.8352146453544345], time: 136.635
steps: 474975, episodes: 19000, mean episode reward: -0.6292457264470509, agent episode reward: [-10.702444925391905, 5.036599599472427, 5.036599599472427], time: 136.308
steps: 499975, episodes: 20000, mean episode reward: -0.24910448345848038, agent episode reward: [-10.519856522686926, 5.135376019614223, 5.135376019614223], time: 134.968
steps: 524975, episodes: 21000, mean episode reward: -0.13593344425474116, agent episode reward: [-11.100382061011071, 5.482224308378165, 5.482224308378165], time: 135.072
steps: 549975, episodes: 22000, mean episode reward: -1.0461181822838528, agent episode reward: [-10.504136439747057, 4.729009128731602, 4.729009128731602], time: 135.476
steps: 574975, episodes: 23000, mean episode reward: -0.9314869523520625, agent episode reward: [-11.064101383184257, 5.0663072154160975, 5.0663072154160975], time: 136.123
steps: 599975, episodes: 24000, mean episode reward: -1.6278104782805405, agent episode reward: [-10.481548404920085, 4.426868963319773, 4.426868963319773], time: 136.344
steps: 624975, episodes: 25000, mean episode reward: -1.3430959048008078, agent episode reward: [-10.840823310944204, 4.748863703071698, 4.748863703071698], time: 136.176
steps: 649975, episodes: 26000, mean episode reward: -1.2023841076227877, agent episode reward: [-11.02407102448984, 4.9108434584335265, 4.9108434584335265], time: 136.036
steps: 674975, episodes: 27000, mean episode reward: -1.1331859565867517, agent episode reward: [-11.09278713225351, 4.979800587833378, 4.979800587833378], time: 136.355
steps: 699975, episodes: 28000, mean episode reward: -0.6358948838825043, agent episode reward: [-11.716824977366564, 5.540465046742029, 5.540465046742029], time: 135.798
steps: 724975, episodes: 29000, mean episode reward: -0.9225340125462171, agent episode reward: [-10.500488522745258, 4.78897725509952, 4.78897725509952], time: 135.608
steps: 749975, episodes: 30000, mean episode reward: -1.527015339016888, agent episode reward: [-11.48037903771469, 4.976681849348901, 4.976681849348901], time: 136.518
steps: 774975, episodes: 31000, mean episode reward: -1.1067072804034594, agent episode reward: [-11.76731770047473, 5.330305210035634, 5.330305210035634], time: 135.39
steps: 799975, episodes: 32000, mean episode reward: -1.035688787635936, agent episode reward: [-10.873575444765741, 4.918943328564903, 4.918943328564903], time: 135.255
steps: 824975, episodes: 33000, mean episode reward: -1.3458978895730727, agent episode reward: [-11.424088803512824, 5.039095456969875, 5.039095456969875], time: 135.367
steps: 849975, episodes: 34000, mean episode reward: -0.9105658081521517, agent episode reward: [-11.316286809331478, 5.202860500589662, 5.202860500589662], time: 135.234
steps: 874975, episodes: 35000, mean episode reward: -1.8599092923280778, agent episode reward: [-10.87048262543132, 4.50528666655162, 4.50528666655162], time: 135.46
steps: 899975, episodes: 36000, mean episode reward: -1.4306502451742358, agent episode reward: [-11.583986437104151, 5.076668095964957, 5.076668095964957], time: 135.387
steps: 924975, episodes: 37000, mean episode reward: -1.0942866235552169, agent episode reward: [-11.524524176136325, 5.215118776290555, 5.215118776290555], time: 135.81
steps: 949975, episodes: 38000, mean episode reward: -0.969578485144538, agent episode reward: [-11.686626375576258, 5.35852394521586, 5.35852394521586], time: 136.617
steps: 974975, episodes: 39000, mean episode reward: -1.795657713356849, agent episode reward: [-11.830593536572687, 5.01746791160792, 5.01746791160792], time: 134.931
steps: 999975, episodes: 40000, mean episode reward: -1.144742284342587, agent episode reward: [-11.589593643409795, 5.222425679533604, 5.222425679533604], time: 134.749
steps: 1024975, episodes: 41000, mean episode reward: -1.233258633115597, agent episode reward: [-11.51253906941054, 5.139640218147472, 5.139640218147472], time: 134.787
steps: 1049975, episodes: 42000, mean episode reward: -0.8237428534528524, agent episode reward: [-12.249917786193112, 5.71308746637013, 5.71308746637013], time: 135.7
steps: 1074975, episodes: 43000, mean episode reward: -1.383366444161567, agent episode reward: [-12.442778115775582, 5.529705835807007, 5.529705835807007], time: 136.166
steps: 1099975, episodes: 44000, mean episode reward: -1.711813816767102, agent episode reward: [-12.132372851422241, 5.21027951732757, 5.21027951732757], time: 135.276
steps: 1124975, episodes: 45000, mean episode reward: -1.955490059265314, agent episode reward: [-11.82569404035151, 4.935101990543097, 4.935101990543097], time: 136.967
steps: 1149975, episodes: 46000, mean episode reward: -2.1082526354192206, agent episode reward: [-12.278219736772083, 5.084983550676431, 5.084983550676431], time: 135.886
steps: 1174975, episodes: 47000, mean episode reward: -1.5815351298314861, agent episode reward: [-12.72580378265987, 5.572134326414192, 5.572134326414192], time: 136.109
steps: 1199975, episodes: 48000, mean episode reward: -1.841230386487261, agent episode reward: [-12.907608362099149, 5.533188987805944, 5.533188987805944], time: 136.539
steps: 1224975, episodes: 49000, mean episode reward: -1.667579818907435, agent episode reward: [-12.776486761938274, 5.55445347151542, 5.55445347151542], time: 135.443
steps: 1249975, episodes: 50000, mean episode reward: -0.9954011380244512, agent episode reward: [-13.118237344036292, 6.061418103005921, 6.061418103005921], time: 135.074
steps: 1274975, episodes: 51000, mean episode reward: -1.3490218761221575, agent episode reward: [-13.216751350690007, 5.933864737283926, 5.933864737283926], time: 135.64
steps: 1299975, episodes: 52000, mean episode reward: -1.0818997020308938, agent episode reward: [-12.828721234176351, 5.873410766072728, 5.873410766072728], time: 135.914
steps: 1324975, episodes: 53000, mean episode reward: -1.6825960459570715, agent episode reward: [-13.375000812765327, 5.846202383404128, 5.846202383404128], time: 134.632
steps: 1349975, episodes: 54000, mean episode reward: -2.2671267958162034, agent episode reward: [-13.582315430253868, 5.657594317218833, 5.657594317218833], time: 136.384
steps: 1374975, episodes: 55000, mean episode reward: -1.819207092732758, agent episode reward: [-13.63773662745639, 5.909264767361816, 5.909264767361816], time: 135.983
steps: 1399975, episodes: 56000, mean episode reward: -1.4175251758721503, agent episode reward: [-13.620828590258988, 6.101651707193421, 6.101651707193421], time: 135.026
steps: 1424975, episodes: 57000, mean episode reward: -1.13222828886097, agent episode reward: [-14.185656572126616, 6.526714141632823, 6.526714141632823], time: 136.093
steps: 1449975, episodes: 58000, mean episode reward: -1.1326193135761327, agent episode reward: [-13.633206534543284, 6.250293610483575, 6.250293610483575], time: 135.415
steps: 1474975, episodes: 59000, mean episode reward: -1.188009241200281, agent episode reward: [-14.051817610230682, 6.431904184515202, 6.431904184515202], time: 137.455
steps: 1499975, episodes: 60000, mean episode reward: -1.1213053955489007, agent episode reward: [-14.457578986026164, 6.668136795238631, 6.668136795238631], time: 134.571
...Finished total of 60001 episodes.
