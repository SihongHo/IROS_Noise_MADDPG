Using good policy maddpg and adv policy maddpg
Uncertainty type is:  None ; Uncertainty level is:  1.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -31.49565334147628, agent episode reward: [0.8842553899385568, 0.9616359940634871, 0.8719182416054813, 1.008209488180821, -15.51813690456571, -19.703535550698913], time: 149.68
steps: 49975, episodes: 2000, mean episode reward: -23.80404363460383, agent episode reward: [2.346868517717442, 2.6893795946606884, 2.700070024021722, 3.03302507343795, -15.665855450287953, -18.907531394153676], time: 254.05
steps: 74975, episodes: 3000, mean episode reward: 11.859352290340585, agent episode reward: [3.7405198633409067, 3.6789556344856185, 4.333081031303811, 4.551030924677748, -2.0796914359825918, -2.364543727484908], time: 272.068
steps: 99975, episodes: 4000, mean episode reward: 20.570257858221346, agent episode reward: [6.7585874716178385, 6.288042064443341, 6.991245577116775, 6.794841282061055, -2.768110422482486, -3.4943481145351827], time: 273.931
steps: 124975, episodes: 5000, mean episode reward: 26.41734067943615, agent episode reward: [8.604931897381151, 8.439442712031523, 8.7643085503988, 8.475554775381807, -3.348026244780938, -4.518871010976194], time: 272.683
steps: 149975, episodes: 6000, mean episode reward: 26.7106782833897, agent episode reward: [8.612307352579615, 8.72968128460184, 8.805251325826426, 8.670615786648991, -3.2042194223711284, -4.9029580438960405], time: 272.9
steps: 174975, episodes: 7000, mean episode reward: 26.20078762392752, agent episode reward: [8.455365352576777, 8.438684917728121, 8.690295219207776, 8.550086021208939, -3.7378844475640127, -4.19575943923008], time: 272.622
steps: 199975, episodes: 8000, mean episode reward: 23.852588736699794, agent episode reward: [7.995198949188274, 7.994337988650876, 8.216100513940066, 8.11554680545492, -4.4352057800536, -4.03338974048074], time: 272.966
steps: 224975, episodes: 9000, mean episode reward: 23.238606610874072, agent episode reward: [7.987117617836403, 7.8434604408805635, 8.038615011029961, 7.962450338677481, -4.167595585400024, -4.4254412121503135], time: 271.987
steps: 249975, episodes: 10000, mean episode reward: 25.78535930608731, agent episode reward: [8.856832416480083, 8.71633760028479, 8.827411122259608, 8.739987738638307, -4.695116296725753, -4.660093274849724], time: 272.968
steps: 274975, episodes: 11000, mean episode reward: 24.968332277532134, agent episode reward: [8.466331432822932, 8.395014984585545, 8.448457883656355, 8.414708397053046, -4.347600842575699, -4.408579578010038], time: 272.972
steps: 299975, episodes: 12000, mean episode reward: 25.12027295408529, agent episode reward: [8.579758248623271, 8.477705649208776, 8.570389802265149, 8.49864430998106, -4.398608032335415, -4.607617023657548], time: 272.171
steps: 324975, episodes: 13000, mean episode reward: 24.2187205020065, agent episode reward: [8.085617046003792, 8.070846894387692, 8.129574803317954, 7.989592358277866, -4.5958280475699835, -3.461082552410822], time: 273.919
steps: 349975, episodes: 14000, mean episode reward: 26.137998001251177, agent episode reward: [8.78933031619134, 8.735595677873986, 8.853342001174864, 8.749430918253442, -5.229731560340837, -3.7599693519016184], time: 274.013
steps: 374975, episodes: 15000, mean episode reward: 23.540300076512818, agent episode reward: [7.902666491979897, 7.722626802104378, 7.954952462451917, 7.833709203750896, -4.6199881657550295, -3.2536667180192387], time: 272.465
steps: 399975, episodes: 16000, mean episode reward: 20.668361742581343, agent episode reward: [7.110297944054731, 6.918978804121242, 7.2367338002924235, 7.087760608375808, -4.364119991758361, -3.321289422504501], time: 272.321
steps: 424975, episodes: 17000, mean episode reward: 19.606976612585818, agent episode reward: [6.763437839015126, 6.524780499799021, 6.807933250087291, 6.775303538951801, -4.082897463613104, -3.181581051654314], time: 273.489
steps: 449975, episodes: 18000, mean episode reward: 22.154140794595733, agent episode reward: [7.36398330691329, 7.212968691999301, 7.445984476379105, 7.416930740121509, -4.235394387203227, -3.050332033614246], time: 273.259
steps: 474975, episodes: 19000, mean episode reward: 22.75815961921378, agent episode reward: [7.818904145812548, 7.655325566283539, 7.869384672902257, 7.8082989492593775, -4.086575404997983, -4.307178310045958], time: 271.677
steps: 499975, episodes: 20000, mean episode reward: 20.363478931829913, agent episode reward: [7.06397892943718, 6.827867960550353, 7.118777091717329, 7.068496847682894, -3.8014938897535826, -3.9141480078042634], time: 270.172
steps: 524975, episodes: 21000, mean episode reward: 22.303235746271202, agent episode reward: [7.588742349659074, 7.359988212947307, 7.638785755049854, 7.638321215820714, -3.438185872622188, -4.484415914583553], time: 272.356
steps: 549975, episodes: 22000, mean episode reward: 19.755734118680113, agent episode reward: [6.911248834015363, 6.748615321513131, 6.92549010114749, 6.970041225541061, -3.9114395397258646, -3.8882218238110626], time: 271.869
steps: 574975, episodes: 23000, mean episode reward: 21.47588184770377, agent episode reward: [7.407865516646608, 7.176701875427647, 7.435170542834706, 7.415597956240973, -4.014963253686188, -3.9444907897599797], time: 271.355
steps: 599975, episodes: 24000, mean episode reward: 23.54136426206651, agent episode reward: [7.853157089901885, 7.622036574921674, 7.888409572405602, 7.86027342633432, -3.519946438349287, -4.162565963147688], time: 271.46
steps: 624975, episodes: 25000, mean episode reward: 19.731161261966225, agent episode reward: [6.9709260911877635, 6.746960550878405, 6.967028055309023, 6.923894614303914, -3.490621497898928, -4.387026551813953], time: 271.786
steps: 649975, episodes: 26000, mean episode reward: 21.333473166803554, agent episode reward: [7.456756714924986, 7.209112153620172, 7.404283280485874, 7.31286736072998, -3.9131374714329845, -4.136408871524474], time: 273.395
steps: 674975, episodes: 27000, mean episode reward: 21.04088310591911, agent episode reward: [7.421293919165584, 7.051122305544501, 7.209291257163457, 7.027406104727696, -3.02566530782471, -4.642565172857417], time: 270.705
steps: 699975, episodes: 28000, mean episode reward: 21.041019467706494, agent episode reward: [7.224170647299371, 6.899113383545795, 7.061823457254963, 6.981256721845628, -2.8243590620030172, -4.3009856802362485], time: 272.725
steps: 724975, episodes: 29000, mean episode reward: 20.63949580441998, agent episode reward: [7.081293620587761, 6.802542427240175, 6.901717486762833, 6.780201949684103, -2.7138469595143553, -4.2124127203405335], time: 269.985
steps: 749975, episodes: 30000, mean episode reward: 18.887699261352896, agent episode reward: [6.479493705844049, 6.157475533982315, 6.348691755049797, 6.2026729278134685, -2.488751766857037, -3.8118828944796967], time: 268.74
steps: 774975, episodes: 31000, mean episode reward: 22.739573521074817, agent episode reward: [7.828188077200649, 7.608614529135908, 7.719440970001057, 7.618678667775734, -2.778317014741011, -5.2570317082975215], time: 266.673
steps: 799975, episodes: 32000, mean episode reward: 28.193820354136335, agent episode reward: [9.512446624250606, 9.30603447197776, 9.365220563442614, 9.25781617436113, -3.3608080574559924, -5.8868894224397845], time: 267.897
steps: 824975, episodes: 33000, mean episode reward: 26.904215314736657, agent episode reward: [9.165945838087744, 8.961205927283245, 9.118027139900466, 8.96899363700591, -3.505245399873346, -5.804711827667367], time: 267.643
steps: 849975, episodes: 34000, mean episode reward: 26.893213635514396, agent episode reward: [9.20750720160173, 9.043770469634731, 9.12125387835204, 9.02824778832349, -3.2365745829673296, -6.27099111943027], time: 267.469
steps: 874975, episodes: 35000, mean episode reward: 26.48201203374353, agent episode reward: [8.97806306078208, 8.830509623056438, 8.874578075158917, 8.852716556429506, -3.5247935952481, -5.529061686435311], time: 262.88
steps: 899975, episodes: 36000, mean episode reward: 25.624553244124165, agent episode reward: [8.879053808222597, 8.77085929898165, 8.809048534049381, 8.726343770637902, -3.6320515320534987, -5.928700635713867], time: 265.701
steps: 924975, episodes: 37000, mean episode reward: 27.492308595132865, agent episode reward: [9.307449116834785, 9.237106407809376, 9.228370933814936, 9.150462990648597, -3.5999801209638336, -5.831100733011002], time: 263.28
steps: 949975, episodes: 38000, mean episode reward: 26.607059824945175, agent episode reward: [9.291879416041438, 9.210791999464924, 9.207842460565676, 9.186451392043976, -3.7102746934929884, -6.579630749677856], time: 263.811
steps: 974975, episodes: 39000, mean episode reward: 27.66523562612751, agent episode reward: [9.49172496243067, 9.274988351675153, 9.400277398177398, 9.387455077971827, -3.4174827865572492, -6.4717273775702875], time: 263.689
steps: 999975, episodes: 40000, mean episode reward: 28.885547084023013, agent episode reward: [9.83033811530992, 9.663580937446271, 9.77509554865993, 9.775300942391576, -3.457386920596012, -6.701381539188675], time: 263.342
steps: 1024975, episodes: 41000, mean episode reward: 33.558111218672956, agent episode reward: [11.46348793630617, 11.27632192373249, 11.224787882197484, 11.31819235222474, -4.746304259000966, -6.978374616786962], time: 263.93
steps: 1049975, episodes: 42000, mean episode reward: 33.713410088118984, agent episode reward: [11.760858208517922, 11.55826190792448, 11.561257413304098, 11.68927585136206, -5.242374114578346, -7.6138691784112345], time: 261.123
steps: 1074975, episodes: 43000, mean episode reward: 32.70680307643092, agent episode reward: [11.50567002747875, 11.320781005465804, 11.299641911631593, 11.441396360808033, -4.811438522535034, -8.049247706418228], time: 260.231
steps: 1099975, episodes: 44000, mean episode reward: 35.06912881049235, agent episode reward: [12.239905813676891, 11.956176564110272, 11.971270730388206, 12.036457174289792, -4.459032367577883, -8.675649104394925], time: 261.263
steps: 1124975, episodes: 45000, mean episode reward: 40.957829529377676, agent episode reward: [14.021285712063055, 13.700191690955766, 13.737059556131582, 13.765241448051812, -4.610624437184608, -9.65532444063994], time: 261.039
steps: 1149975, episodes: 46000, mean episode reward: 37.669401572461574, agent episode reward: [12.95817086945007, 12.684529032567523, 12.644036889396677, 12.818148522355408, -5.015536984273776, -8.419946757034333], time: 264.656
steps: 1174975, episodes: 47000, mean episode reward: 38.697286482031195, agent episode reward: [13.45993400938176, 13.220403816074214, 13.078330407486687, 13.283402434517921, -5.5707088669651945, -8.774075318464183], time: 263.769
steps: 1199975, episodes: 48000, mean episode reward: 41.315106818963365, agent episode reward: [14.149469567727007, 13.97333886380793, 13.814906991943655, 14.133242774658118, -6.066346127611978, -8.68950525156136], time: 261.434
steps: 1224975, episodes: 49000, mean episode reward: 33.70017138104624, agent episode reward: [11.603832341667752, 11.47071821355134, 11.263654007901893, 11.660767104436276, -5.813543941273503, -6.485256345237521], time: 260.269
steps: 1249975, episodes: 50000, mean episode reward: 33.01821833080909, agent episode reward: [11.24412642590686, 11.111193255573856, 11.062838719415987, 11.286163931378008, -6.459549912273317, -5.226554089192297], time: 261.118
steps: 1274975, episodes: 51000, mean episode reward: 33.16927280871443, agent episode reward: [11.398324973740694, 11.252809461994682, 11.193192684686137, 11.416454399457303, -7.034083894291476, -5.057424816872897], time: 265.016
steps: 1299975, episodes: 52000, mean episode reward: 36.12576645979883, agent episode reward: [12.199169918702548, 12.179245021037971, 12.131799323094883, 12.185805207358328, -7.349278124429549, -5.22097488596535], time: 262.119
steps: 1324975, episodes: 53000, mean episode reward: 36.659300451833865, agent episode reward: [12.507382850811082, 12.448191809191147, 12.527572817553395, 12.444931750870321, -7.1276326216063755, -6.141146154985703], time: 261.365
steps: 1349975, episodes: 54000, mean episode reward: 34.032694020379495, agent episode reward: [11.767050274466841, 11.72167593741327, 11.758974993581946, 11.698428807980676, -7.633470482676965, -5.279965510386279], time: 259.068
steps: 1374975, episodes: 55000, mean episode reward: 35.61561964247997, agent episode reward: [12.527249268683876, 12.51295029406733, 12.474976101060463, 12.261358124825064, -7.840324361554342, -6.320589784602414], time: 260.029
steps: 1399975, episodes: 56000, mean episode reward: 34.69837092310835, agent episode reward: [12.144602633310763, 12.100863937292722, 12.038141154269837, 11.944167983856689, -7.7810690547924, -5.748335730829254], time: 260.165
steps: 1424975, episodes: 57000, mean episode reward: 40.434255794897815, agent episode reward: [14.017361419672163, 14.107969820683321, 13.932539016645212, 13.802123164320685, -9.163414076396279, -6.26232355002729], time: 262.103
steps: 1449975, episodes: 58000, mean episode reward: 44.04068225100388, agent episode reward: [14.83447735198756, 14.886627509084592, 14.692127475822748, 14.719033099258459, -8.929680772407893, -6.161902412741585], time: 259.592
steps: 1474975, episodes: 59000, mean episode reward: 44.31517792613457, agent episode reward: [14.93824170302466, 14.930886586645684, 14.801352495775715, 14.804805119588112, -8.546155877224875, -6.613952101674727], time: 262.349
steps: 1499975, episodes: 60000, mean episode reward: 41.683183139491724, agent episode reward: [14.164507542885945, 14.030009506589192, 13.971472047686483, 13.839826388362297, -7.548959632692772, -6.773672713339416], time: 257.687
...Finished total of 60001 episodes.
