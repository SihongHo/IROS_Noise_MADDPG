Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  0.5
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -21.761558642399958, agent episode reward: [-38.66648837435989, 8.452464865979964, 8.452464865979964], time: 87.047
steps: 49975, episodes: 2000, mean episode reward: -16.827508759612957, agent episode reward: [-21.813387511334398, 2.4929393758607197, 2.4929393758607197], time: 114.925
steps: 74975, episodes: 3000, mean episode reward: 0.804807762785871, agent episode reward: [-12.420374698001785, 6.612591230393829, 6.612591230393829], time: 113.785
steps: 99975, episodes: 4000, mean episode reward: 2.8415766821358313, agent episode reward: [-10.246744501764995, 6.544160591950413, 6.544160591950413], time: 114.217
steps: 124975, episodes: 5000, mean episode reward: 3.034500825357422, agent episode reward: [-9.414507765459321, 6.224504295408371, 6.224504295408371], time: 114.878
steps: 149975, episodes: 6000, mean episode reward: 2.388803118687736, agent episode reward: [-9.629063511576279, 6.008933315132007, 6.008933315132007], time: 115.354
steps: 174975, episodes: 7000, mean episode reward: 1.8180647203520652, agent episode reward: [-9.883597183170819, 5.850830951761442, 5.850830951761442], time: 115.041
steps: 199975, episodes: 8000, mean episode reward: 1.7818706063324763, agent episode reward: [-10.40511470775002, 6.093492657041248, 6.093492657041248], time: 114.548
steps: 224975, episodes: 9000, mean episode reward: 1.7761508627137468, agent episode reward: [-10.236909027868343, 6.006529945291044, 6.006529945291044], time: 114.894
steps: 249975, episodes: 10000, mean episode reward: 0.7062379093899539, agent episode reward: [-11.265106913357437, 5.985672411373694, 5.985672411373694], time: 114.286
steps: 274975, episodes: 11000, mean episode reward: 0.9871954529854129, agent episode reward: [-11.680498322262094, 6.3338468876237535, 6.3338468876237535], time: 114.789
steps: 299975, episodes: 12000, mean episode reward: 0.006618721181355738, agent episode reward: [-11.177801159574923, 5.592209940378139, 5.592209940378139], time: 115.808
steps: 324975, episodes: 13000, mean episode reward: -0.7546101290803464, agent episode reward: [-11.526108607556159, 5.3857492392379065, 5.3857492392379065], time: 114.655
steps: 349975, episodes: 14000, mean episode reward: 0.09374578922693576, agent episode reward: [-11.488148043437608, 5.790946916332272, 5.790946916332272], time: 115.087
steps: 374975, episodes: 15000, mean episode reward: -1.025297344166318, agent episode reward: [-10.985904591446122, 4.980303623639902, 4.980303623639902], time: 115.268
steps: 399975, episodes: 16000, mean episode reward: 0.02947043131810564, agent episode reward: [-11.651977035335568, 5.840723733326837, 5.840723733326837], time: 114.707
steps: 424975, episodes: 17000, mean episode reward: -0.5830229139980486, agent episode reward: [-11.63071838614766, 5.523847736074805, 5.523847736074805], time: 114.654
steps: 449975, episodes: 18000, mean episode reward: -0.8597649091220804, agent episode reward: [-11.518999658636435, 5.329617374757178, 5.329617374757178], time: 114.679
steps: 474975, episodes: 19000, mean episode reward: -0.9110391328220562, agent episode reward: [-11.773704574392516, 5.43133272078523, 5.43133272078523], time: 115.231
steps: 499975, episodes: 20000, mean episode reward: -1.7479671171553186, agent episode reward: [-12.063927989630468, 5.157980436237573, 5.157980436237573], time: 115.393
steps: 524975, episodes: 21000, mean episode reward: -1.1779400887074132, agent episode reward: [-10.916142094269253, 4.869101002780921, 4.869101002780921], time: 115.251
steps: 549975, episodes: 22000, mean episode reward: -0.8333146323649072, agent episode reward: [-11.082527784226974, 5.1246065759310335, 5.1246065759310335], time: 115.133
steps: 574975, episodes: 23000, mean episode reward: -0.9263942061759415, agent episode reward: [-11.123904106962142, 5.098754950393101, 5.098754950393101], time: 115.395
steps: 599975, episodes: 24000, mean episode reward: -0.6382315016635955, agent episode reward: [-11.327857510527156, 5.34481300443178, 5.34481300443178], time: 115.904
steps: 624975, episodes: 25000, mean episode reward: -1.2377239765911163, agent episode reward: [-11.611166264262598, 5.186721143835741, 5.186721143835741], time: 115.36
steps: 649975, episodes: 26000, mean episode reward: -1.875488160225855, agent episode reward: [-11.534483595670503, 4.829497717722323, 4.829497717722323], time: 115.346
steps: 674975, episodes: 27000, mean episode reward: -1.969005326620346, agent episode reward: [-11.304195785451212, 4.667595229415432, 4.667595229415432], time: 114.479
steps: 699975, episodes: 28000, mean episode reward: -1.9382288389347122, agent episode reward: [-11.835189385088091, 4.948480273076689, 4.948480273076689], time: 114.746
steps: 724975, episodes: 29000, mean episode reward: -2.4868488763159475, agent episode reward: [-10.992282843999584, 4.252716983841819, 4.252716983841819], time: 114.912
steps: 749975, episodes: 30000, mean episode reward: -2.14971648837112, agent episode reward: [-11.831906737502917, 4.841095124565898, 4.841095124565898], time: 115.967
steps: 774975, episodes: 31000, mean episode reward: -3.347480764069398, agent episode reward: [-11.466296474909177, 4.05940785541989, 4.05940785541989], time: 115.037
steps: 799975, episodes: 32000, mean episode reward: -3.3727961853296797, agent episode reward: [-11.840546691971868, 4.233875253321093, 4.233875253321093], time: 114.112
steps: 824975, episodes: 33000, mean episode reward: -2.7614645960971775, agent episode reward: [-11.82126672135569, 4.529901062629254, 4.529901062629254], time: 115.277
steps: 849975, episodes: 34000, mean episode reward: -3.141110925767084, agent episode reward: [-11.797028542468885, 4.327958808350901, 4.327958808350901], time: 114.38
steps: 874975, episodes: 35000, mean episode reward: -2.529027723007439, agent episode reward: [-11.542968785972684, 4.506970531482622, 4.506970531482622], time: 114.984
steps: 899975, episodes: 36000, mean episode reward: -2.256248052260555, agent episode reward: [-11.047475362632856, 4.395613655186151, 4.395613655186151], time: 114.568
steps: 924975, episodes: 37000, mean episode reward: -3.394039039200546, agent episode reward: [-11.683386251123334, 4.144673605961394, 4.144673605961394], time: 116.058
steps: 949975, episodes: 38000, mean episode reward: -2.854998437484782, agent episode reward: [-12.089464510152869, 4.617233036334043, 4.617233036334043], time: 115.798
steps: 974975, episodes: 39000, mean episode reward: -3.5173671601398184, agent episode reward: [-11.409755359749331, 3.946194099804756, 3.946194099804756], time: 115.611
steps: 999975, episodes: 40000, mean episode reward: -2.4721306564899503, agent episode reward: [-11.363325258003758, 4.445597300756905, 4.445597300756905], time: 114.321
steps: 1024975, episodes: 41000, mean episode reward: -2.7459794644625863, agent episode reward: [-12.266653833982705, 4.7603371847600595, 4.7603371847600595], time: 115.122
steps: 1049975, episodes: 42000, mean episode reward: -4.086440586987245, agent episode reward: [-12.166402849035979, 4.0399811310243665, 4.0399811310243665], time: 114.752
steps: 1074975, episodes: 43000, mean episode reward: -3.655523310667107, agent episode reward: [-12.613628910231899, 4.479052799782395, 4.479052799782395], time: 115.286
steps: 1099975, episodes: 44000, mean episode reward: -3.223782087649897, agent episode reward: [-12.157973613789611, 4.467095763069856, 4.467095763069856], time: 113.104
steps: 1124975, episodes: 45000, mean episode reward: -3.262073109033019, agent episode reward: [-12.233437264172935, 4.485682077569959, 4.485682077569959], time: 114.708
steps: 1149975, episodes: 46000, mean episode reward: -3.2320013320737053, agent episode reward: [-12.19872601248594, 4.483362340206116, 4.483362340206116], time: 114.918
steps: 1174975, episodes: 47000, mean episode reward: -3.0344315270286253, agent episode reward: [-13.037439516449693, 5.001503994710532, 5.001503994710532], time: 115.196
steps: 1199975, episodes: 48000, mean episode reward: -3.0471852192251023, agent episode reward: [-13.231133914269853, 5.091974347522377, 5.091974347522377], time: 116.308
steps: 1224975, episodes: 49000, mean episode reward: -1.8925889535222602, agent episode reward: [-12.484567775039338, 5.295989410758538, 5.295989410758538], time: 114.661
steps: 1249975, episodes: 50000, mean episode reward: -1.5068886298485593, agent episode reward: [-13.354180325430766, 5.923645847791104, 5.923645847791104], time: 115.15
steps: 1274975, episodes: 51000, mean episode reward: -1.694085160519039, agent episode reward: [-13.379569708604128, 5.8427422740425445, 5.8427422740425445], time: 115.397
steps: 1299975, episodes: 52000, mean episode reward: -2.915960552275421, agent episode reward: [-13.164319049379174, 5.124179248551876, 5.124179248551876], time: 115.929
steps: 1324975, episodes: 53000, mean episode reward: -1.6364232124100178, agent episode reward: [-13.275950591744527, 5.819763689667254, 5.819763689667254], time: 115.152
steps: 1349975, episodes: 54000, mean episode reward: -1.99512850940035, agent episode reward: [-13.175891168369178, 5.590381329484414, 5.590381329484414], time: 116.089
steps: 1374975, episodes: 55000, mean episode reward: -2.0673781650039365, agent episode reward: [-13.573821157126826, 5.753221496061444, 5.753221496061444], time: 114.456
steps: 1399975, episodes: 56000, mean episode reward: -1.3531463755137538, agent episode reward: [-14.510333058423475, 6.5785933414548605, 6.5785933414548605], time: 114.599
steps: 1424975, episodes: 57000, mean episode reward: -1.5092017694187811, agent episode reward: [-13.635886147882873, 6.063342189232046, 6.063342189232046], time: 114.821
steps: 1449975, episodes: 58000, mean episode reward: -1.9511267438111832, agent episode reward: [-13.449840197759842, 5.74935672697433, 5.74935672697433], time: 115.348
steps: 1474975, episodes: 59000, mean episode reward: -1.6384450082834137, agent episode reward: [-13.56821192471689, 5.964883458216738, 5.964883458216738], time: 117.18
steps: 1499975, episodes: 60000, mean episode reward: -0.4886422088295737, agent episode reward: [-13.283482965531825, 6.397420378351126, 6.397420378351126], time: 110.95
...Finished total of 60001 episodes.
