Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  2.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -22.078287715568226, agent episode reward: [-34.29277448217639, 6.107243383304087, 6.107243383304087], time: 72.319
steps: 49975, episodes: 2000, mean episode reward: -16.593304523590863, agent episode reward: [-23.664156177564227, 3.5354258269866836, 3.5354258269866836], time: 106.686
steps: 74975, episodes: 3000, mean episode reward: -2.022606545264988, agent episode reward: [-16.78319194030331, 7.380292697519162, 7.380292697519162], time: 105.109
steps: 99975, episodes: 4000, mean episode reward: 4.494096394661647, agent episode reward: [-14.61840669787193, 9.55625154626679, 9.55625154626679], time: 105.077
steps: 124975, episodes: 5000, mean episode reward: 3.8640566079252916, agent episode reward: [-10.735524551611757, 7.299790579768525, 7.299790579768525], time: 105.119
steps: 149975, episodes: 6000, mean episode reward: 2.943834372383232, agent episode reward: [-9.713398234861716, 6.328616303622473, 6.328616303622473], time: 105.489
steps: 174975, episodes: 7000, mean episode reward: 2.3591164825692483, agent episode reward: [-8.97935598995797, 5.669236236263608, 5.669236236263608], time: 105.225
steps: 199975, episodes: 8000, mean episode reward: 2.7777185415456387, agent episode reward: [-9.63860462189283, 6.208161581719234, 6.208161581719234], time: 105.197
steps: 224975, episodes: 9000, mean episode reward: 1.5990190583399286, agent episode reward: [-10.746973572381012, 6.172996315360471, 6.172996315360471], time: 104.84
steps: 249975, episodes: 10000, mean episode reward: 1.6539794339906597, agent episode reward: [-10.582387852833355, 6.1181836434120065, 6.1181836434120065], time: 105.124
steps: 274975, episodes: 11000, mean episode reward: 1.0755110915156723, agent episode reward: [-11.485354418554067, 6.2804327550348695, 6.2804327550348695], time: 105.413
steps: 299975, episodes: 12000, mean episode reward: 1.590168160127832, agent episode reward: [-10.62626948702593, 6.10821882357688, 6.10821882357688], time: 105.336
steps: 324975, episodes: 13000, mean episode reward: 0.7213601841371828, agent episode reward: [-10.303852635835701, 5.512606409986441, 5.512606409986441], time: 105.109
steps: 349975, episodes: 14000, mean episode reward: 0.44374592933962903, agent episode reward: [-10.684702774918517, 5.564224352129073, 5.564224352129073], time: 104.974
steps: 374975, episodes: 15000, mean episode reward: 0.482944450462541, agent episode reward: [-11.113984609294294, 5.798464529878417, 5.798464529878417], time: 105.572
steps: 399975, episodes: 16000, mean episode reward: 0.4223186439461902, agent episode reward: [-11.300410785062875, 5.861364714504533, 5.861364714504533], time: 104.929
steps: 424975, episodes: 17000, mean episode reward: 0.005966751970239294, agent episode reward: [-11.504376536284399, 5.755171644127319, 5.755171644127319], time: 104.925
steps: 449975, episodes: 18000, mean episode reward: -0.3039556885004823, agent episode reward: [-11.264218817852619, 5.480131564676068, 5.480131564676068], time: 104.714
steps: 474975, episodes: 19000, mean episode reward: 0.14165593453374414, agent episode reward: [-11.540251387114198, 5.8409536608239705, 5.8409536608239705], time: 106.608
steps: 499975, episodes: 20000, mean episode reward: -0.7279971672025222, agent episode reward: [-11.691713558324908, 5.481858195561194, 5.481858195561194], time: 105.277
steps: 524975, episodes: 21000, mean episode reward: -0.5340758981350072, agent episode reward: [-11.677748316924205, 5.5718362093946, 5.5718362093946], time: 104.904
steps: 549975, episodes: 22000, mean episode reward: -0.772493426028174, agent episode reward: [-10.786541598088201, 5.007024086030013, 5.007024086030013], time: 104.256
steps: 574975, episodes: 23000, mean episode reward: -0.47885451337505835, agent episode reward: [-11.443162675760636, 5.482154081192789, 5.482154081192789], time: 104.32
steps: 599975, episodes: 24000, mean episode reward: -1.3834345166400228, agent episode reward: [-11.38899259106205, 5.002779037211014, 5.002779037211014], time: 105.012
steps: 624975, episodes: 25000, mean episode reward: -0.6035407047628628, agent episode reward: [-11.529044600213698, 5.462751947725417, 5.462751947725417], time: 101.766
steps: 649975, episodes: 26000, mean episode reward: -0.7027599844334288, agent episode reward: [-11.000350653901055, 5.148795334733815, 5.148795334733815], time: 100.459
steps: 674975, episodes: 27000, mean episode reward: -0.8163153990506575, agent episode reward: [-11.95523134970351, 5.569457975326426, 5.569457975326426], time: 99.213
steps: 699975, episodes: 28000, mean episode reward: -0.6593826695752235, agent episode reward: [-12.000924706722728, 5.6707710185737525, 5.6707710185737525], time: 98.26
steps: 724975, episodes: 29000, mean episode reward: -1.294833075045938, agent episode reward: [-11.006199060441979, 4.8556829926980205, 4.8556829926980205], time: 99.159
steps: 749975, episodes: 30000, mean episode reward: -0.7671306480916169, agent episode reward: [-11.17693173666023, 5.204900544284307, 5.204900544284307], time: 100.401
steps: 774975, episodes: 31000, mean episode reward: -1.3136355894093388, agent episode reward: [-11.810273039447791, 5.248318725019226, 5.248318725019226], time: 99.279
steps: 799975, episodes: 32000, mean episode reward: -1.9457730618200053, agent episode reward: [-12.010643556236039, 5.032435247208017, 5.032435247208017], time: 97.021
steps: 824975, episodes: 33000, mean episode reward: -2.1649300695172506, agent episode reward: [-12.404959521213662, 5.120014725848206, 5.120014725848206], time: 99.114
steps: 849975, episodes: 34000, mean episode reward: -1.0147139165626626, agent episode reward: [-12.449077948099584, 5.717182015768461, 5.717182015768461], time: 98.965
steps: 874975, episodes: 35000, mean episode reward: -1.4026093740393597, agent episode reward: [-11.821121094161809, 5.209255860061225, 5.209255860061225], time: 99.728
steps: 899975, episodes: 36000, mean episode reward: -0.729959055729825, agent episode reward: [-11.854933784882721, 5.562487364576447, 5.562487364576447], time: 98.973
steps: 924975, episodes: 37000, mean episode reward: -0.8133354304260777, agent episode reward: [-12.678132146624217, 5.93239835809907, 5.93239835809907], time: 98.674
steps: 949975, episodes: 38000, mean episode reward: -0.7446108739913825, agent episode reward: [-12.811233942034432, 6.033311534021524, 6.033311534021524], time: 99.83
steps: 974975, episodes: 39000, mean episode reward: -1.0057115533294556, agent episode reward: [-13.167298590926496, 6.08079351879852, 6.08079351879852], time: 99.311
steps: 999975, episodes: 40000, mean episode reward: -0.4141237601833003, agent episode reward: [-13.102950605526178, 6.3444134226714395, 6.3444134226714395], time: 99.145
steps: 1024975, episodes: 41000, mean episode reward: -0.6242263939815745, agent episode reward: [-12.737320981594923, 6.056547293806674, 6.056547293806674], time: 99.056
steps: 1049975, episodes: 42000, mean episode reward: 0.041678890849937804, agent episode reward: [-13.68128474380575, 6.861481817327844, 6.861481817327844], time: 98.618
steps: 1074975, episodes: 43000, mean episode reward: -0.7665257947030328, agent episode reward: [-14.663640252180521, 6.948557228738744, 6.948557228738744], time: 98.059
steps: 1099975, episodes: 44000, mean episode reward: -0.1597364225857942, agent episode reward: [-13.11367096908937, 6.4769672732517884, 6.4769672732517884], time: 98.094
steps: 1124975, episodes: 45000, mean episode reward: -2.01601395585138, agent episode reward: [-14.604621877965096, 6.294303961056857, 6.294303961056857], time: 98.862
steps: 1149975, episodes: 46000, mean episode reward: -1.92235427269986, agent episode reward: [-14.013303576398917, 6.045474651849528, 6.045474651849528], time: 99.413
steps: 1174975, episodes: 47000, mean episode reward: -1.2432619037720078, agent episode reward: [-14.152563478984696, 6.454650787606345, 6.454650787606345], time: 99.267
steps: 1199975, episodes: 48000, mean episode reward: -1.3063941427204087, agent episode reward: [-13.639139917395237, 6.166372887337415, 6.166372887337415], time: 100.287
steps: 1224975, episodes: 49000, mean episode reward: -1.8072454419667374, agent episode reward: [-14.102111676998849, 6.147433117516057, 6.147433117516057], time: 99.267
steps: 1249975, episodes: 50000, mean episode reward: -1.3790092747691374, agent episode reward: [-13.94599479374078, 6.283492759485822, 6.283492759485822], time: 98.951
steps: 1274975, episodes: 51000, mean episode reward: -1.6735697035733652, agent episode reward: [-13.825712323497351, 6.076071309961994, 6.076071309961994], time: 99.906
steps: 1299975, episodes: 52000, mean episode reward: -0.8502367978477195, agent episode reward: [-12.889366994260353, 6.019565098206317, 6.019565098206317], time: 99.499
steps: 1324975, episodes: 53000, mean episode reward: -1.2181704081893645, agent episode reward: [-13.574971646189384, 6.17840061900001, 6.17840061900001], time: 99.604
steps: 1349975, episodes: 54000, mean episode reward: -0.8288798937891386, agent episode reward: [-14.232160393796635, 6.701640250003749, 6.701640250003749], time: 98.713
steps: 1374975, episodes: 55000, mean episode reward: -1.4991659628348406, agent episode reward: [-13.516683414982149, 6.008758726073653, 6.008758726073653], time: 99.953
steps: 1399975, episodes: 56000, mean episode reward: -0.8648009604735596, agent episode reward: [-13.404755490262872, 6.269977264894656, 6.269977264894656], time: 99.215
steps: 1424975, episodes: 57000, mean episode reward: -1.0558965407579408, agent episode reward: [-14.093023022312222, 6.518563240777141, 6.518563240777141], time: 99.365
steps: 1449975, episodes: 58000, mean episode reward: -1.5569407723673294, agent episode reward: [-13.367493337171608, 5.90527628240214, 5.90527628240214], time: 99.784
steps: 1474975, episodes: 59000, mean episode reward: -0.6565992185459981, agent episode reward: [-13.564744646145872, 6.4540727137999365, 6.4540727137999365], time: 100.109
steps: 1499975, episodes: 60000, mean episode reward: -0.4326064459168914, agent episode reward: [-13.224194859146435, 6.395794206614772, 6.395794206614772], time: 96.613
...Finished total of 60001 episodes.
