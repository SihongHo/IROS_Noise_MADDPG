Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  2.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -23.685395378413936, agent episode reward: [-24.219316194140585, 0.2669604078633247, 0.2669604078633247], time: 87.216
steps: 49975, episodes: 2000, mean episode reward: -26.48091580114782, agent episode reward: [-19.538364876753025, -3.471275462197397, -3.471275462197397], time: 110.215
steps: 74975, episodes: 3000, mean episode reward: -13.937056422056855, agent episode reward: [-13.614114451611465, -0.16147098522269585, -0.16147098522269585], time: 109.232
steps: 99975, episodes: 4000, mean episode reward: 7.877294559277958, agent episode reward: [-12.099985038213884, 9.98863979874592, 9.98863979874592], time: 109.441
steps: 124975, episodes: 5000, mean episode reward: 7.763750551229336, agent episode reward: [-12.695114744387073, 10.229432647808204, 10.229432647808204], time: 109.97
steps: 149975, episodes: 6000, mean episode reward: 7.773477507731628, agent episode reward: [-12.116987662458682, 9.945232585095157, 9.945232585095157], time: 110.114
steps: 174975, episodes: 7000, mean episode reward: 6.963590529970399, agent episode reward: [-11.500597344760886, 9.232093937365644, 9.232093937365644], time: 110.409
steps: 199975, episodes: 8000, mean episode reward: 6.1068888783638435, agent episode reward: [-11.510440279694832, 8.808664579029337, 8.808664579029337], time: 110.148
steps: 224975, episodes: 9000, mean episode reward: 5.3084799389024155, agent episode reward: [-11.410843569350764, 8.359661754126588, 8.359661754126588], time: 111.09
steps: 249975, episodes: 10000, mean episode reward: 5.631257490666121, agent episode reward: [-12.190788702961381, 8.911023096813752, 8.911023096813752], time: 110.057
steps: 274975, episodes: 11000, mean episode reward: 3.8464570952779193, agent episode reward: [-13.150353168606573, 8.498405131942247, 8.498405131942247], time: 110.397
steps: 299975, episodes: 12000, mean episode reward: 8.048354413093074, agent episode reward: [-14.29038045761098, 11.16936743535203, 11.16936743535203], time: 111.835
steps: 324975, episodes: 13000, mean episode reward: 6.081233665653035, agent episode reward: [-12.833841652427832, 9.457537659040433, 9.457537659040433], time: 111.351
steps: 349975, episodes: 14000, mean episode reward: 9.34603754976247, agent episode reward: [-14.479792000259014, 11.912914775010744, 11.912914775010744], time: 111.065
steps: 374975, episodes: 15000, mean episode reward: 9.902863509484416, agent episode reward: [-15.314185271435978, 12.608524390460195, 12.608524390460195], time: 111.702
steps: 399975, episodes: 16000, mean episode reward: 7.08083333032509, agent episode reward: [-15.358356224330834, 11.219594777327963, 11.219594777327963], time: 110.117
steps: 424975, episodes: 17000, mean episode reward: 6.214809010906232, agent episode reward: [-12.959709841234217, 9.587259426070224, 9.587259426070224], time: 110.939
steps: 449975, episodes: 18000, mean episode reward: 7.29650479983876, agent episode reward: [-14.240396135587941, 10.76845046771335, 10.76845046771335], time: 110.757
steps: 474975, episodes: 19000, mean episode reward: 8.623860508714046, agent episode reward: [-15.347417654288924, 11.985639081501485, 11.985639081501485], time: 111.168
steps: 499975, episodes: 20000, mean episode reward: 8.000435623346135, agent episode reward: [-14.410513906868506, 11.205474765107319, 11.205474765107319], time: 110.547
steps: 524975, episodes: 21000, mean episode reward: 9.255717302801536, agent episode reward: [-14.41970089752697, 11.837709100164252, 11.837709100164252], time: 111.011
steps: 549975, episodes: 22000, mean episode reward: 9.108962752272786, agent episode reward: [-14.413864311379841, 11.761413531826314, 11.761413531826314], time: 110.381
steps: 574975, episodes: 23000, mean episode reward: 10.742127238089354, agent episode reward: [-16.315661438282568, 13.528894338185962, 13.528894338185962], time: 110.719
steps: 599975, episodes: 24000, mean episode reward: 11.087647850038806, agent episode reward: [-25.192361172528347, 18.140004511283575, 18.140004511283575], time: 111.413
steps: 624975, episodes: 25000, mean episode reward: -3.3130678633688966, agent episode reward: [-22.89537626548783, 9.791154201059468, 9.791154201059468], time: 111.414
steps: 649975, episodes: 26000, mean episode reward: 6.430687705418931, agent episode reward: [-15.437243088266262, 10.933965396842597, 10.933965396842597], time: 111.309
steps: 674975, episodes: 27000, mean episode reward: 8.992485182771233, agent episode reward: [-14.039586963745297, 11.516036073258265, 11.516036073258265], time: 111.268
steps: 699975, episodes: 28000, mean episode reward: 9.460816440633662, agent episode reward: [-14.611262020807255, 12.036039230720457, 12.036039230720457], time: 111.095
steps: 724975, episodes: 29000, mean episode reward: 7.802599440072166, agent episode reward: [-13.835570913731123, 10.819085176901645, 10.819085176901645], time: 111.043
steps: 749975, episodes: 30000, mean episode reward: 14.389329196087138, agent episode reward: [-22.17558980622392, 18.28245950115553, 18.28245950115553], time: 110.736
steps: 774975, episodes: 31000, mean episode reward: 18.671709307637542, agent episode reward: [-26.78925587932144, 22.730482593479493, 22.730482593479493], time: 110.15
steps: 799975, episodes: 32000, mean episode reward: 19.430379704069523, agent episode reward: [-24.315955952577454, 21.87316782832349, 21.87316782832349], time: 110.688
steps: 824975, episodes: 33000, mean episode reward: 22.44323193497652, agent episode reward: [-25.99308170338723, 24.218156819181875, 24.218156819181875], time: 109.075
steps: 849975, episodes: 34000, mean episode reward: 19.795223747885846, agent episode reward: [-23.810749105022428, 21.802986426454137, 21.802986426454137], time: 110.262
steps: 874975, episodes: 35000, mean episode reward: 21.67601734446098, agent episode reward: [-24.335970931884198, 23.005994138172596, 23.005994138172596], time: 110.14
steps: 899975, episodes: 36000, mean episode reward: 21.79256869934255, agent episode reward: [-24.829333150406995, 23.31095092487477, 23.31095092487477], time: 110.324
steps: 924975, episodes: 37000, mean episode reward: 19.322779093097672, agent episode reward: [-22.870348147238197, 21.096563620167938, 21.096563620167938], time: 109.986
steps: 949975, episodes: 38000, mean episode reward: 18.694108787627012, agent episode reward: [-24.156738260379797, 21.425423524003403, 21.425423524003403], time: 112.053
steps: 974975, episodes: 39000, mean episode reward: 19.69783181064632, agent episode reward: [-23.534690399696142, 21.61626110517123, 21.61626110517123], time: 110.87
steps: 999975, episodes: 40000, mean episode reward: 19.58383625499298, agent episode reward: [-23.747720179304743, 21.665778217148862, 21.665778217148862], time: 111.463
steps: 1024975, episodes: 41000, mean episode reward: 18.190159536780065, agent episode reward: [-23.39340317436443, 20.791781355572247, 20.791781355572247], time: 110.819
steps: 1049975, episodes: 42000, mean episode reward: 18.32041705340436, agent episode reward: [-23.05740408962634, 20.68891057151535, 20.68891057151535], time: 111.06
steps: 1074975, episodes: 43000, mean episode reward: 15.516375723098598, agent episode reward: [-23.488191760541383, 19.502283741819994, 19.502283741819994], time: 111.955
steps: 1099975, episodes: 44000, mean episode reward: 16.956705901178108, agent episode reward: [-22.88752377179409, 19.922114836486095, 19.922114836486095], time: 110.942
steps: 1124975, episodes: 45000, mean episode reward: 16.959756652093244, agent episode reward: [-22.728690091243994, 19.84422337166862, 19.84422337166862], time: 111.791
steps: 1149975, episodes: 46000, mean episode reward: 15.299928904096063, agent episode reward: [-25.432198289341613, 20.36606359671884, 20.36606359671884], time: 111.443
steps: 1174975, episodes: 47000, mean episode reward: 7.287235912769596, agent episode reward: [-15.227940147294671, 11.257588030032133, 11.257588030032133], time: 111.154
steps: 1199975, episodes: 48000, mean episode reward: 6.4973061004316675, agent episode reward: [-13.26760892832495, 9.882457514378311, 9.882457514378311], time: 111.476
steps: 1224975, episodes: 49000, mean episode reward: 6.2420492107689665, agent episode reward: [-14.065282646242961, 10.153665928505964, 10.153665928505964], time: 112.062
steps: 1249975, episodes: 50000, mean episode reward: 5.360007292254339, agent episode reward: [-13.203217380175968, 9.281612336215153, 9.281612336215153], time: 111.853
steps: 1274975, episodes: 51000, mean episode reward: 8.776180928308873, agent episode reward: [-14.528230080455527, 11.652205504382199, 11.652205504382199], time: 111.94
steps: 1299975, episodes: 52000, mean episode reward: 8.668986095600859, agent episode reward: [-15.041527509847437, 11.85525680272415, 11.85525680272415], time: 112.471
steps: 1324975, episodes: 53000, mean episode reward: 9.779328173911669, agent episode reward: [-16.337702002536517, 13.058515088224093, 13.058515088224093], time: 111.418
steps: 1349975, episodes: 54000, mean episode reward: 10.653896394561665, agent episode reward: [-15.220250735712137, 12.937073565136899, 12.937073565136899], time: 112.476
steps: 1374975, episodes: 55000, mean episode reward: 12.330284178001135, agent episode reward: [-16.445524520359907, 14.38790434918052, 14.38790434918052], time: 111.881
steps: 1399975, episodes: 56000, mean episode reward: 12.630499324353131, agent episode reward: [-16.452233098214347, 14.541366211283737, 14.541366211283737], time: 111.723
steps: 1424975, episodes: 57000, mean episode reward: 12.489586549511936, agent episode reward: [-17.20080457420528, 14.845195561858606, 14.845195561858606], time: 112.042
steps: 1449975, episodes: 58000, mean episode reward: 13.243626820304906, agent episode reward: [-18.29408012896902, 15.768853474636964, 15.768853474636964], time: 112.007
steps: 1474975, episodes: 59000, mean episode reward: 13.76895958877861, agent episode reward: [-19.99498178528541, 16.881970687032013, 16.881970687032013], time: 110.099
steps: 1499975, episodes: 60000, mean episode reward: 13.163980725652182, agent episode reward: [-19.722892196466578, 16.443436461059378, 16.443436461059378], time: 78.574
...Finished total of 60001 episodes.
