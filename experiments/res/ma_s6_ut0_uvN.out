Using good policy maddpg and adv policy maddpg
Uncertainty type is:  None ; Uncertainty level is:  1.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -24.101895832661608, agent episode reward: [-24.228553799469836, 0.06332898340411296, 0.06332898340411296], time: 43.983
steps: 49975, episodes: 2000, mean episode reward: -17.542874252843795, agent episode reward: [-18.56768816035325, 0.512406953754729, 0.512406953754729], time: 84.061
steps: 74975, episodes: 3000, mean episode reward: -12.14364614766112, agent episode reward: [-12.92432771333666, 0.3903407828377706, 0.3903407828377706], time: 128.498
steps: 99975, episodes: 4000, mean episode reward: -10.022249364768024, agent episode reward: [-8.201196048439822, -0.9105266581641004, -0.9105266581641004], time: 127.072
steps: 124975, episodes: 5000, mean episode reward: -9.075913767809208, agent episode reward: [-13.72318252361577, 2.323634377903282, 2.323634377903282], time: 126.935
steps: 149975, episodes: 6000, mean episode reward: 4.255652524577479, agent episode reward: [-13.521538550623264, 8.888595537600374, 8.888595537600374], time: 127.453
steps: 174975, episodes: 7000, mean episode reward: 10.340615337384545, agent episode reward: [-23.4019892267757, 16.871302282080123, 16.871302282080123], time: 126.921
steps: 199975, episodes: 8000, mean episode reward: 14.381299595685052, agent episode reward: [-17.781272571288763, 16.08128608348691, 16.08128608348691], time: 127.428
steps: 224975, episodes: 9000, mean episode reward: 15.060108677175691, agent episode reward: [-17.38827043202534, 16.224189554600517, 16.224189554600517], time: 127.285
steps: 249975, episodes: 10000, mean episode reward: 14.29393580360577, agent episode reward: [-16.080143986029707, 15.187039894817739, 15.187039894817739], time: 127.647
steps: 274975, episodes: 11000, mean episode reward: 14.98813406383304, agent episode reward: [-16.82542563054293, 15.906779847187988, 15.906779847187988], time: 127.093
steps: 299975, episodes: 12000, mean episode reward: 17.38446224055594, agent episode reward: [-19.006770995134247, 18.195616617845094, 18.195616617845094], time: 126.97
steps: 324975, episodes: 13000, mean episode reward: 17.67616430966452, agent episode reward: [-19.31814444049947, 18.49715437508199, 18.49715437508199], time: 127.186
steps: 349975, episodes: 14000, mean episode reward: 16.360088452680216, agent episode reward: [-17.93684099549226, 17.148464724086235, 17.148464724086235], time: 127.218
steps: 374975, episodes: 15000, mean episode reward: 16.93317252787416, agent episode reward: [-18.48434707328596, 17.70875980058006, 17.70875980058006], time: 126.636
steps: 399975, episodes: 16000, mean episode reward: 16.139265576773994, agent episode reward: [-17.638109574201376, 16.888687575487687, 16.888687575487687], time: 127.501
steps: 424975, episodes: 17000, mean episode reward: 16.155567764731035, agent episode reward: [-17.718823766846523, 16.937195765788776, 16.937195765788776], time: 126.961
steps: 449975, episodes: 18000, mean episode reward: 15.134368085645972, agent episode reward: [-19.2507630532808, 17.192565569463387, 17.192565569463387], time: 127.227
steps: 474975, episodes: 19000, mean episode reward: 13.729070403283249, agent episode reward: [-16.45731570633941, 15.093193054811326, 15.093193054811326], time: 127.394
steps: 499975, episodes: 20000, mean episode reward: 15.339391228708058, agent episode reward: [-16.81309678034625, 16.076244004527155, 16.076244004527155], time: 127.128
steps: 524975, episodes: 21000, mean episode reward: 15.458229053204294, agent episode reward: [-16.965610081870345, 16.21191956753732, 16.21191956753732], time: 127.222
steps: 549975, episodes: 22000, mean episode reward: 14.975702599637417, agent episode reward: [-16.60316414425141, 15.789433371944412, 15.789433371944412], time: 127.869
steps: 574975, episodes: 23000, mean episode reward: 15.225649216582145, agent episode reward: [-16.842672809147523, 16.034161012864836, 16.034161012864836], time: 127.163
steps: 599975, episodes: 24000, mean episode reward: 15.583187033889208, agent episode reward: [-17.16205527412656, 16.372621154007884, 16.372621154007884], time: 127.24
steps: 624975, episodes: 25000, mean episode reward: 15.348282019353942, agent episode reward: [-16.900218136221337, 16.124250077787636, 16.124250077787636], time: 126.874
steps: 649975, episodes: 26000, mean episode reward: 15.542005831400493, agent episode reward: [-17.15178167371648, 16.346893752558486, 16.346893752558486], time: 127.119
steps: 674975, episodes: 27000, mean episode reward: 15.358022153022477, agent episode reward: [-17.014960592542796, 16.18649137278264, 16.18649137278264], time: 127.171
steps: 699975, episodes: 28000, mean episode reward: 15.503440829438572, agent episode reward: [-17.10715401232467, 16.30529742088162, 16.30529742088162], time: 127.279
steps: 724975, episodes: 29000, mean episode reward: 15.157959990109386, agent episode reward: [-16.87703365231599, 16.01749682121269, 16.01749682121269], time: 126.894
steps: 749975, episodes: 30000, mean episode reward: 15.328756724892973, agent episode reward: [-17.00963001447847, 16.169193369685722, 16.169193369685722], time: 127.202
steps: 774975, episodes: 31000, mean episode reward: 15.17986341483972, agent episode reward: [-16.813239829990902, 15.99655162241531, 15.99655162241531], time: 127.148
steps: 799975, episodes: 32000, mean episode reward: 15.446351017463781, agent episode reward: [-16.96880775131858, 16.20757938439118, 16.20757938439118], time: 127.576
steps: 824975, episodes: 33000, mean episode reward: 15.315700147347302, agent episode reward: [-16.93966280094986, 16.12768147414858, 16.12768147414858], time: 126.868
steps: 849975, episodes: 34000, mean episode reward: 15.443774170709244, agent episode reward: [-16.996549819768727, 16.220161995238985, 16.220161995238985], time: 126.787
steps: 874975, episodes: 35000, mean episode reward: 15.235088547160903, agent episode reward: [-16.75153629238587, 15.993312419773387, 15.993312419773387], time: 127.116
steps: 899975, episodes: 36000, mean episode reward: 15.087743366888445, agent episode reward: [-16.696643387041107, 15.892193376964775, 15.892193376964775], time: 127.184
steps: 924975, episodes: 37000, mean episode reward: 15.252852769922235, agent episode reward: [-16.796498331885253, 16.024675550903744, 16.024675550903744], time: 127.062
steps: 949975, episodes: 38000, mean episode reward: 15.269072201778025, agent episode reward: [-16.77734871422057, 16.023210457999294, 16.023210457999294], time: 126.928
steps: 974975, episodes: 39000, mean episode reward: 15.143161895742436, agent episode reward: [-16.720992573747754, 15.932077234745094, 15.932077234745094], time: 126.9
steps: 999975, episodes: 40000, mean episode reward: 15.116009234234143, agent episode reward: [-16.64711155283485, 15.881560393534498, 15.881560393534498], time: 127.327
steps: 1024975, episodes: 41000, mean episode reward: 15.33071080014829, agent episode reward: [-16.855610518029422, 16.093160659088856, 16.093160659088856], time: 127.503
steps: 1049975, episodes: 42000, mean episode reward: 15.325262302745191, agent episode reward: [-16.877088955037536, 16.101175628891365, 16.101175628891365], time: 126.756
steps: 1074975, episodes: 43000, mean episode reward: 15.120436750277866, agent episode reward: [-16.726435543061427, 15.923436146669644, 15.923436146669644], time: 127.222
steps: 1099975, episodes: 44000, mean episode reward: 15.395336454769527, agent episode reward: [-16.78761931732348, 16.0914778860465, 16.0914778860465], time: 127.326
steps: 1124975, episodes: 45000, mean episode reward: 15.24207281297285, agent episode reward: [-17.417990590735368, 16.33003170185411, 16.33003170185411], time: 126.976
steps: 1149975, episodes: 46000, mean episode reward: 12.62662474961575, agent episode reward: [-21.335581683028064, 16.981103216321905, 16.981103216321905], time: 127.37
steps: 1174975, episodes: 47000, mean episode reward: 6.6233745441488585, agent episode reward: [-16.42275292513552, 11.52306373464219, 11.52306373464219], time: 126.983
steps: 1199975, episodes: 48000, mean episode reward: 15.521009480176497, agent episode reward: [-18.408241335017642, 16.964625407597072, 16.964625407597072], time: 127.256
steps: 1224975, episodes: 49000, mean episode reward: 13.433423734503755, agent episode reward: [-17.622242956595084, 15.52783334554942, 15.52783334554942], time: 126.889
steps: 1249975, episodes: 50000, mean episode reward: 11.3558560252643, agent episode reward: [-14.86391649221941, 13.109886258741856, 13.109886258741856], time: 127.125
steps: 1274975, episodes: 51000, mean episode reward: 19.629125674607543, agent episode reward: [-21.16848214356803, 20.39880390908779, 20.39880390908779], time: 127.588
steps: 1299975, episodes: 52000, mean episode reward: 8.775691824883925, agent episode reward: [-17.772348357457957, 13.27402009117094, 13.27402009117094], time: 127.318
steps: 1324975, episodes: 53000, mean episode reward: 15.552872160584304, agent episode reward: [-17.00334391072286, 16.27810803565358, 16.27810803565358], time: 127.005
steps: 1349975, episodes: 54000, mean episode reward: 15.655781873141137, agent episode reward: [-17.113024133473985, 16.38440300330756, 16.38440300330756], time: 127.009
steps: 1374975, episodes: 55000, mean episode reward: 15.585368065528288, agent episode reward: [-17.123031815115386, 16.354199940321834, 16.354199940321834], time: 126.942
steps: 1399975, episodes: 56000, mean episode reward: 15.109712503202493, agent episode reward: [-16.542852152998297, 15.826282328100394, 15.826282328100394], time: 127.481
steps: 1424975, episodes: 57000, mean episode reward: 14.645331946437741, agent episode reward: [-16.18333142925063, 15.414331687844184, 15.414331687844184], time: 126.903
steps: 1449975, episodes: 58000, mean episode reward: 14.830973027861615, agent episode reward: [-16.34459865483143, 15.587785841346523, 15.587785841346523], time: 127.663
steps: 1474975, episodes: 59000, mean episode reward: 13.865327555031023, agent episode reward: [-17.75877495837365, 15.812051256702336, 15.812051256702336], time: 127.322
steps: 1499975, episodes: 60000, mean episode reward: 11.034069210661583, agent episode reward: [-22.24061879193355, 16.63734400129757, 16.63734400129757], time: 127.045
...Finished total of 60001 episodes.
