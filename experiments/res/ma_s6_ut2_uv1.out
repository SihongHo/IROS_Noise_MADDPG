Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  1.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -23.546113981034566, agent episode reward: [-23.974287780582493, 0.2140868997739615, 0.2140868997739615], time: 60.55
steps: 49975, episodes: 2000, mean episode reward: -19.63276337916079, agent episode reward: [-21.82817537373116, 1.0977059972851835, 1.0977059972851835], time: 80.686
steps: 74975, episodes: 3000, mean episode reward: -9.32247847104173, agent episode reward: [-4.936231292086593, -2.1931235894775685, -2.1931235894775685], time: 80.775
steps: 99975, episodes: 4000, mean episode reward: -6.539284126473134, agent episode reward: [-11.463118778328665, 2.4619173259277654, 2.4619173259277654], time: 81.571
steps: 124975, episodes: 5000, mean episode reward: -27.73166493708694, agent episode reward: [-36.43892343849545, 4.353629250704257, 4.353629250704257], time: 81.39
steps: 149975, episodes: 6000, mean episode reward: 0.8086715099141941, agent episode reward: [-18.996430465717417, 9.902550987815806, 9.902550987815806], time: 81.697
steps: 174975, episodes: 7000, mean episode reward: -12.24320142247187, agent episode reward: [-12.414990801946306, 0.08589468973721864, 0.08589468973721864], time: 82.84
steps: 199975, episodes: 8000, mean episode reward: -11.00042955735001, agent episode reward: [-12.209472956189922, 0.6045216994199564, 0.6045216994199564], time: 81.172
steps: 224975, episodes: 9000, mean episode reward: -12.289857098386852, agent episode reward: [-13.78373862493406, 0.746940763273604, 0.746940763273604], time: 81.548
steps: 249975, episodes: 10000, mean episode reward: -11.563166383536437, agent episode reward: [-15.988624916961458, 2.2127292667125102, 2.2127292667125102], time: 82.798
steps: 274975, episodes: 11000, mean episode reward: -4.644885151530869, agent episode reward: [-22.547679521858043, 8.951397185163588, 8.951397185163588], time: 80.999
steps: 299975, episodes: 12000, mean episode reward: 7.895190693630619, agent episode reward: [-22.2636660118271, 15.07942835272886, 15.07942835272886], time: 82.364
steps: 324975, episodes: 13000, mean episode reward: 3.2918767389421606, agent episode reward: [-26.34300476830832, 14.817440753625238, 14.817440753625238], time: 82.133
steps: 349975, episodes: 14000, mean episode reward: -3.545999118188129, agent episode reward: [-30.820495327228635, 13.637248104520253, 13.637248104520253], time: 81.603
steps: 374975, episodes: 15000, mean episode reward: 4.31650547676247, agent episode reward: [-26.872644007716413, 15.594574742239443, 15.594574742239443], time: 81.819
steps: 399975, episodes: 16000, mean episode reward: 11.649674979019382, agent episode reward: [-25.20025884265481, 18.424966910837096, 18.424966910837096], time: 80.856
steps: 424975, episodes: 17000, mean episode reward: 16.552225887218945, agent episode reward: [-24.714808672219903, 20.633517279719424, 20.633517279719424], time: 81.61
steps: 449975, episodes: 18000, mean episode reward: 16.254331579602255, agent episode reward: [-25.165001154408966, 20.70966636700561, 20.70966636700561], time: 82.738
steps: 474975, episodes: 19000, mean episode reward: 19.165083127521832, agent episode reward: [-24.447313872505838, 21.80619850001384, 21.80619850001384], time: 82.971
steps: 499975, episodes: 20000, mean episode reward: 20.664152975507882, agent episode reward: [-26.170126997228703, 23.417139986368294, 23.417139986368294], time: 81.77
steps: 524975, episodes: 21000, mean episode reward: 16.22947254421712, agent episode reward: [-29.84549689746411, 23.037484720840613, 23.037484720840613], time: 81.942
steps: 549975, episodes: 22000, mean episode reward: 22.051878129738867, agent episode reward: [-31.39192464778886, 26.721901388763865, 26.721901388763865], time: 82.816
steps: 574975, episodes: 23000, mean episode reward: 19.480691239450884, agent episode reward: [-27.611732358662568, 23.546211799056728, 23.546211799056728], time: 82.311
steps: 599975, episodes: 24000, mean episode reward: 18.31587399569023, agent episode reward: [-23.994927316525235, 21.15540065610773, 21.15540065610773], time: 83.627
steps: 624975, episodes: 25000, mean episode reward: 17.58381398993805, agent episode reward: [-21.88279142663425, 19.733302708286153, 19.733302708286153], time: 82.156
steps: 649975, episodes: 26000, mean episode reward: 19.55531811085238, agent episode reward: [-23.394461040630766, 21.474889575741575, 21.474889575741575], time: 82.257
steps: 674975, episodes: 27000, mean episode reward: 19.735526249753203, agent episode reward: [-23.487958421981215, 21.61174233586721, 21.61174233586721], time: 81.488
steps: 699975, episodes: 28000, mean episode reward: 16.24215863047481, agent episode reward: [-20.751437519620705, 18.496798075047753, 18.496798075047753], time: 82.96
steps: 724975, episodes: 29000, mean episode reward: 18.90186905085515, agent episode reward: [-22.17941737928158, 20.540643215068364, 20.540643215068364], time: 82.887
steps: 749975, episodes: 30000, mean episode reward: 17.560998888688424, agent episode reward: [-21.644247842281665, 19.602623365485044, 19.602623365485044], time: 83.924
steps: 774975, episodes: 31000, mean episode reward: 16.40171612389788, agent episode reward: [-21.01860862044418, 18.71016237217103, 18.71016237217103], time: 82.381
steps: 799975, episodes: 32000, mean episode reward: 17.10057793213961, agent episode reward: [-22.731455851809912, 19.91601689197476, 19.91601689197476], time: 83.156
steps: 824975, episodes: 33000, mean episode reward: 19.17964517440134, agent episode reward: [-22.93276653219213, 21.056205853296735, 21.056205853296735], time: 82.408
steps: 849975, episodes: 34000, mean episode reward: 18.61064542048456, agent episode reward: [-22.226295794133215, 20.418470607308883, 20.418470607308883], time: 81.711
steps: 874975, episodes: 35000, mean episode reward: 12.731773815553685, agent episode reward: [-22.327419615449916, 17.5295967155018, 17.5295967155018], time: 82.1
steps: 899975, episodes: 36000, mean episode reward: 14.703295385764088, agent episode reward: [-24.802817803914504, 19.753056594839297, 19.753056594839297], time: 81.745
steps: 924975, episodes: 37000, mean episode reward: 19.823878972318074, agent episode reward: [-23.63933951764366, 21.73160924498087, 21.73160924498087], time: 82.237
steps: 949975, episodes: 38000, mean episode reward: 17.70486025180718, agent episode reward: [-23.803294806764242, 20.754077529285713, 20.754077529285713], time: 83.728
steps: 974975, episodes: 39000, mean episode reward: 17.872747467118142, agent episode reward: [-21.10706857830387, 19.48990802271101, 19.48990802271101], time: 81.879
steps: 999975, episodes: 40000, mean episode reward: 15.649095362455759, agent episode reward: [-22.451408535070748, 19.050251948763254, 19.050251948763254], time: 82.251
steps: 1024975, episodes: 41000, mean episode reward: 12.056608372741971, agent episode reward: [-25.11619250883246, 18.586400440787212, 18.586400440787212], time: 79.026
steps: 1049975, episodes: 42000, mean episode reward: 4.551062290763691, agent episode reward: [-26.366325190761188, 15.45869374076244, 15.45869374076244], time: 75.396
steps: 1074975, episodes: 43000, mean episode reward: 15.471052448209674, agent episode reward: [-26.245022454868852, 20.85803745153926, 20.85803745153926], time: 75.588
steps: 1099975, episodes: 44000, mean episode reward: 15.819907676426599, agent episode reward: [-20.33512884694806, 18.077518261687327, 18.077518261687327], time: 76.487
steps: 1124975, episodes: 45000, mean episode reward: 16.017182191977426, agent episode reward: [-20.09486173891005, 18.056021965443737, 18.056021965443737], time: 76.325
steps: 1149975, episodes: 46000, mean episode reward: 14.057781198738637, agent episode reward: [-20.945771483261197, 17.501776340999914, 17.501776340999914], time: 75.275
steps: 1174975, episodes: 47000, mean episode reward: 12.386748325508206, agent episode reward: [-23.24352044693387, 17.815134386221033, 17.815134386221033], time: 75.354
steps: 1199975, episodes: 48000, mean episode reward: 17.825239520367745, agent episode reward: [-22.80374521166594, 20.314492366016843, 20.314492366016843], time: 76.141
steps: 1224975, episodes: 49000, mean episode reward: 15.782502337666044, agent episode reward: [-23.414502000921768, 19.59850216929391, 19.59850216929391], time: 75.376
steps: 1249975, episodes: 50000, mean episode reward: 7.872435691859746, agent episode reward: [-24.512800055173553, 16.19261787351665, 16.19261787351665], time: 74.812
steps: 1274975, episodes: 51000, mean episode reward: 17.225707170576072, agent episode reward: [-22.441500973485727, 19.833604072030898, 19.833604072030898], time: 75.292
steps: 1299975, episodes: 52000, mean episode reward: 16.977056739720204, agent episode reward: [-24.2810247334949, 20.629040736607553, 20.629040736607553], time: 75.707
steps: 1324975, episodes: 53000, mean episode reward: 18.363308284968582, agent episode reward: [-24.415336540296458, 21.389322412632524, 21.389322412632524], time: 75.6
steps: 1349975, episodes: 54000, mean episode reward: 13.543061034665653, agent episode reward: [-24.83693032189346, 19.189995678279555, 19.189995678279555], time: 77.264
steps: 1374975, episodes: 55000, mean episode reward: 14.178620777471279, agent episode reward: [-22.508817374550496, 18.343719076010885, 18.343719076010885], time: 76.94
steps: 1399975, episodes: 56000, mean episode reward: 16.839571926277163, agent episode reward: [-23.907123494186017, 20.373347710231588, 20.373347710231588], time: 76.447
steps: 1424975, episodes: 57000, mean episode reward: 17.56533400578879, agent episode reward: [-23.884369977354652, 20.72485199157172, 20.72485199157172], time: 76.179
steps: 1449975, episodes: 58000, mean episode reward: 3.062661241192948, agent episode reward: [-8.105260194672308, 5.583960717932628, 5.583960717932628], time: 76.48
steps: 1474975, episodes: 59000, mean episode reward: -3.464068146899925, agent episode reward: [-2.36982488065731, -0.5471216331213072, -0.5471216331213072], time: 78.143
steps: 1499975, episodes: 60000, mean episode reward: -3.470444739526663, agent episode reward: [-1.7017930207535836, -0.8843258593865396, -0.8843258593865396], time: 75.726
