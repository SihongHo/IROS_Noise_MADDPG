Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  1.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -38.26149161646109, agent episode reward: [0.8308440004659556, 0.8090173896060321, 0.7747459208941095, 0.7425460507882806, -26.345422879365593, -15.073222098849874], time: 206.094
steps: 49975, episodes: 2000, mean episode reward: -35.450561664866555, agent episode reward: [2.5130479507840975, 3.0327127941247936, 2.9154287050073737, 2.9307942089706787, -33.77612329064519, -13.066422033108305], time: 260.353
steps: 74975, episodes: 3000, mean episode reward: 10.340663179578808, agent episode reward: [3.5802257896717182, 3.8923139683819032, 4.165907254036345, 3.9829570493603597, -2.3658994942530156, -2.914841387618502], time: 281.361
steps: 99975, episodes: 4000, mean episode reward: 13.528050446661208, agent episode reward: [4.138029798752336, 4.638000572408718, 4.560658394638878, 4.704210144174635, -2.0604473637469027, -2.4524010995664556], time: 287.478
steps: 124975, episodes: 5000, mean episode reward: 18.49087416202671, agent episode reward: [5.986614029495631, 5.936156120553287, 6.153047083007194, 6.408670817359364, -3.1579998219772016, -2.835614066411564], time: 293.674
steps: 149975, episodes: 6000, mean episode reward: 20.037833348797026, agent episode reward: [6.418920527374359, 6.564690625782732, 6.344320444422519, 6.976500975533359, -3.3460254175595745, -2.9205738067563685], time: 296.771
steps: 174975, episodes: 7000, mean episode reward: 21.681822092541854, agent episode reward: [7.242476197429888, 7.200787688277748, 6.701625319018819, 7.341379346734812, -3.1689419916600623, -3.635504467259352], time: 297.717
steps: 199975, episodes: 8000, mean episode reward: 27.806085094103416, agent episode reward: [9.03682185347558, 9.106745293822064, 8.79707328602523, 9.230279628706231, -4.0296782696873095, -4.335156698238381], time: 295.183
steps: 224975, episodes: 9000, mean episode reward: 33.16840172548995, agent episode reward: [10.831878714434206, 10.644561181659931, 10.684418080166866, 10.986317405516733, -4.661003131469894, -5.3177705248178935], time: 297.415
steps: 249975, episodes: 10000, mean episode reward: 42.06257586621663, agent episode reward: [13.749180881417876, 13.640591157169602, 13.678199931032372, 13.819208815726482, -6.645462733717081, -6.179142185412614], time: 296.338
steps: 274975, episodes: 11000, mean episode reward: 43.72754269319204, agent episode reward: [14.225716831027155, 14.23244634173056, 14.226053983306446, 14.361778644727773, -6.96417676816024, -6.354276339439652], time: 296.78
steps: 299975, episodes: 12000, mean episode reward: 44.157176172033374, agent episode reward: [14.451801107890985, 14.434466241854702, 14.275506399957395, 14.409216013981334, -6.689481567916396, -6.724332023734643], time: 298.752
steps: 324975, episodes: 13000, mean episode reward: 45.54098917738843, agent episode reward: [14.904027035557801, 14.891188771253422, 14.731913276826297, 14.813125695012879, -6.403871473548835, -7.395394127713125], time: 296.372
steps: 349975, episodes: 14000, mean episode reward: 45.685196027749974, agent episode reward: [15.03865671491305, 15.030403338235399, 14.75950806126472, 14.932844355516439, -7.2419577119576415, -6.834258730221991], time: 296.932
steps: 374975, episodes: 15000, mean episode reward: 46.85460873957545, agent episode reward: [15.504826842988706, 15.456946175670021, 15.253533261811752, 15.434007166669788, -8.399395831344462, -6.3953088762203585], time: 299.086
steps: 399975, episodes: 16000, mean episode reward: 48.694539939281704, agent episode reward: [16.07735350587424, 15.993612654904107, 15.807976535326167, 15.982116884034301, -7.392529584223771, -7.77399005663334], time: 297.577
steps: 424975, episodes: 17000, mean episode reward: 49.32535562950441, agent episode reward: [16.401048617650936, 16.398014255814555, 16.203575763672074, 16.32709827674189, -8.131141319715928, -7.8732399646591205], time: 295.881
steps: 449975, episodes: 18000, mean episode reward: 42.09374080099264, agent episode reward: [14.037396330530857, 14.004783372820464, 13.860481990162901, 13.924666187460517, -5.6107278611913864, -8.122859218790708], time: 298.397
steps: 474975, episodes: 19000, mean episode reward: 48.128285220917824, agent episode reward: [15.9761981607472, 15.919473595078587, 15.763848425246874, 15.907851394283808, -6.559120775419064, -8.879965579019583], time: 298.619
steps: 499975, episodes: 20000, mean episode reward: 42.049660055360015, agent episode reward: [14.03914884410857, 13.935149753255732, 13.832459387511888, 13.944951448472013, -5.486290465505606, -8.215758912482585], time: 298.703
steps: 524975, episodes: 21000, mean episode reward: 42.34676229838413, agent episode reward: [14.122318701913104, 14.034566601454273, 13.932185864092046, 13.991767535293944, -6.647620607680837, -7.086455796688409], time: 296.046
steps: 549975, episodes: 22000, mean episode reward: 39.47536127959704, agent episode reward: [13.454506948734197, 13.366721439944605, 13.219577540471226, 13.333030647653548, -6.497865879456176, -7.400609417750357], time: 298.796
steps: 574975, episodes: 23000, mean episode reward: 39.76466917494213, agent episode reward: [13.698571306951424, 13.57975742494624, 13.45320592979824, 13.57486214477768, -6.470070198763369, -8.071657432768083], time: 299.438
steps: 599975, episodes: 24000, mean episode reward: 29.497085757130666, agent episode reward: [10.700131213163042, 10.607280570230868, 10.549293094279857, 10.600082803747092, -6.287522223330783, -6.672179700959414], time: 300.724
steps: 624975, episodes: 25000, mean episode reward: 15.454158642325085, agent episode reward: [8.447515281936539, 8.303448457532594, 8.35279439568353, 8.368194521536216, -5.243953023899281, -12.77384099046451], time: 296.189
steps: 649975, episodes: 26000, mean episode reward: 13.982438278216994, agent episode reward: [7.130695234338429, 7.091206599010424, 7.1382643049064285, 7.087557397561588, -5.218354119473028, -9.246931138126849], time: 297.336
steps: 674975, episodes: 27000, mean episode reward: 16.896717458109787, agent episode reward: [7.6457701185760385, 7.457612803995218, 7.493447254643066, 7.475817596273623, -6.7033419439834, -6.4725883713947585], time: 298.162
steps: 699975, episodes: 28000, mean episode reward: 11.803461143797856, agent episode reward: [5.3920306939216225, 5.244758043067737, 5.2200868414359505, 5.289572639418096, -5.261087772809313, -4.081899301236233], time: 295.183
steps: 724975, episodes: 29000, mean episode reward: 19.256477816309786, agent episode reward: [7.515280645122897, 7.336072726139919, 7.406781051247439, 7.368367124845825, -5.586757797343376, -4.783265933702914], time: 294.726
steps: 749975, episodes: 30000, mean episode reward: 15.380979832425268, agent episode reward: [6.883477801324439, 6.700839628027153, 6.7109446394762475, 6.677379573766735, -7.388920505010789, -4.2027413051585185], time: 296.058
steps: 774975, episodes: 31000, mean episode reward: 15.107548031737307, agent episode reward: [6.759660716850285, 6.570610890940765, 6.645828068880975, 6.647013159659867, -7.51839400567215, -3.997170798922436], time: 291.184
steps: 799975, episodes: 32000, mean episode reward: 15.732705769228707, agent episode reward: [6.533411237891539, 6.461380360300961, 6.493632327936296, 6.4220446094776085, -6.583776339696995, -3.5939864266807033], time: 285.925
steps: 824975, episodes: 33000, mean episode reward: 14.374923585873672, agent episode reward: [6.488019703151955, 6.3062090700463225, 6.395707432894031, 6.305380884083223, -7.057617065607572, -4.062776438694289], time: 281.265
steps: 849975, episodes: 34000, mean episode reward: 13.814608577708427, agent episode reward: [6.7911400497916485, 6.590128117089739, 6.687102182922186, 6.625109196391363, -7.955395405360247, -4.923475563126264], time: 282.244
steps: 874975, episodes: 35000, mean episode reward: 11.000095206603438, agent episode reward: [7.730456702812111, 7.4809253772008475, 7.579719998243381, 7.576850255390575, -12.993977656204967, -6.373879470838509], time: 281.333
steps: 899975, episodes: 36000, mean episode reward: 14.58144553275227, agent episode reward: [6.683288293835521, 6.489959033214649, 6.591265457312956, 6.575417022104044, -7.828919904975257, -3.929564368739641], time: 280.249
steps: 924975, episodes: 37000, mean episode reward: 21.55368947866798, agent episode reward: [8.258001165736228, 8.082165830002763, 8.180587800036612, 8.149030016037221, -6.87263673944429, -4.243458593700556], time: 283.67
steps: 949975, episodes: 38000, mean episode reward: 21.30632899163489, agent episode reward: [8.334144750378439, 8.160376651494753, 8.241154245378972, 8.208632271736896, -7.223280494837243, -4.414698432516929], time: 281.136
steps: 974975, episodes: 39000, mean episode reward: 21.00259347094718, agent episode reward: [8.063097668835706, 7.923997449533358, 8.023628474503605, 7.956173191142786, -7.355816905531606, -3.6084864075366694], time: 280.448
steps: 999975, episodes: 40000, mean episode reward: 26.19910737638746, agent episode reward: [9.504413708911748, 9.35138247646748, 9.42602185659765, 9.446162908705505, -7.584805691810343, -3.9440678824845783], time: 282.394
steps: 1024975, episodes: 41000, mean episode reward: 24.580165281412995, agent episode reward: [8.633001192605427, 8.513555975377306, 8.630156457673428, 8.559776265861808, -6.153048784760078, -3.6032758253448964], time: 282.135
steps: 1049975, episodes: 42000, mean episode reward: 22.194487097771095, agent episode reward: [8.44301437548253, 8.269995726643344, 8.429029079948533, 8.2979106506125, -7.580311233223083, -3.6651515016927325], time: 280.702
steps: 1074975, episodes: 43000, mean episode reward: 20.266316336206888, agent episode reward: [8.508761357749979, 8.246412037408005, 8.48727902347047, 8.333640497921005, -7.911033568598051, -5.398743011744526], time: 281.596
steps: 1099975, episodes: 44000, mean episode reward: 24.18456062499925, agent episode reward: [8.782839589273788, 8.55933267821986, 8.814360553322418, 8.602027509781324, -6.056697847941606, -4.5173018576565385], time: 283.294
steps: 1124975, episodes: 45000, mean episode reward: 24.446532669241, agent episode reward: [8.43283815279957, 8.375481408473155, 8.613783749063678, 8.41069649361005, -5.749298093800963, -3.6369690409044835], time: 280.211
steps: 1149975, episodes: 46000, mean episode reward: 23.237735139054166, agent episode reward: [7.891309028180515, 7.874136386626611, 8.129688025678005, 7.934677561220915, -5.405947864717706, -3.1861279979341757], time: 277.473
steps: 1174975, episodes: 47000, mean episode reward: 22.346468141020377, agent episode reward: [7.6453944011533315, 7.579831235688392, 7.739582520941356, 7.543154865263897, -4.961777743892089, -3.1997171381345115], time: 279.274
steps: 1199975, episodes: 48000, mean episode reward: 24.359702925739544, agent episode reward: [8.351808829173981, 8.361017837574945, 8.426011406236753, 8.24031882605437, -5.632774842421151, -3.3866791308793553], time: 276.153
steps: 1224975, episodes: 49000, mean episode reward: 24.512159617994367, agent episode reward: [8.512011463453495, 8.319390995681156, 8.52845349228922, 8.24992405685139, -5.3163661951573085, -3.7812541951235854], time: 277.755
steps: 1249975, episodes: 50000, mean episode reward: 24.10239490988466, agent episode reward: [8.442200190772114, 8.288860169932336, 8.524408021853672, 8.215360956405926, -5.902776615851473, -3.4656578132279225], time: 277.191
steps: 1274975, episodes: 51000, mean episode reward: 25.032428710177243, agent episode reward: [8.376767930810361, 8.311783772596776, 8.548353555997936, 8.299449866860618, -5.142503561803495, -3.361422854284956], time: 278.412
steps: 1299975, episodes: 52000, mean episode reward: 22.365252690497634, agent episode reward: [7.55576206688048, 7.571812422501624, 7.722036060815118, 7.58389491854062, -5.2472061053852945, -2.821046672854915], time: 277.461
steps: 1324975, episodes: 53000, mean episode reward: 21.652983290187187, agent episode reward: [7.375187345233744, 7.223236445006478, 7.505447896453091, 7.355413637438045, -5.242919113548548, -2.5633829203956218], time: 276.415
steps: 1349975, episodes: 54000, mean episode reward: 19.652942014888477, agent episode reward: [7.101720965471432, 6.909984369244719, 7.143203376227345, 7.00864527553703, -5.401729827223317, -3.1088821443687302], time: 277.115
steps: 1374975, episodes: 55000, mean episode reward: 21.469336136205463, agent episode reward: [7.240970064893948, 7.213471544050139, 7.435721720019694, 7.152504863566658, -5.411011393548874, -2.162320662776102], time: 276.651
steps: 1399975, episodes: 56000, mean episode reward: 21.135491329616265, agent episode reward: [7.190481134772792, 7.159400470689656, 7.321914795939385, 7.108515174586622, -5.211381293353265, -2.4334389530189244], time: 276.111
steps: 1424975, episodes: 57000, mean episode reward: 19.560645400732792, agent episode reward: [6.906304252691457, 6.802057339549392, 6.893196188693528, 6.692848045295356, -5.306816172089936, -2.426944253407004], time: 274.436
steps: 1449975, episodes: 58000, mean episode reward: 21.734958174819507, agent episode reward: [7.804266240348592, 7.503320434997166, 7.612215492989926, 7.497076022700726, -6.611703977890459, -2.070216038326441], time: 279.544
steps: 1474975, episodes: 59000, mean episode reward: 23.16089102382957, agent episode reward: [8.173060859133493, 8.021060011495335, 8.024252960084917, 7.782157973483907, -6.704616961954144, -2.1350238184139387], time: 276.265
steps: 1499975, episodes: 60000, mean episode reward: 23.236665984276943, agent episode reward: [8.116673175471528, 7.886404868313815, 7.902593587813595, 7.762227810433018, -6.622533839905146, -1.8086996178498669], time: 261.85
...Finished total of 60001 episodes.
