Using good policy maddpg and adv policy maddpg
Uncertainty type is:  None ; Uncertainty level is:  1.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -22.901654612727203, agent episode reward: [-34.47936495946176, 5.788855173367279, 5.788855173367279], time: 45.599
steps: 49975, episodes: 2000, mean episode reward: -14.674150253272227, agent episode reward: [-28.01430097768202, 6.670075362204896, 6.670075362204896], time: 59.664
steps: 74975, episodes: 3000, mean episode reward: 3.7577252400910974, agent episode reward: [-9.388861693442236, 6.573293466766667, 6.573293466766667], time: 62.348
steps: 99975, episodes: 4000, mean episode reward: 2.6907091494418034, agent episode reward: [-9.154172671753415, 5.92244091059761, 5.92244091059761], time: 74.686
steps: 124975, episodes: 5000, mean episode reward: 2.460834421025926, agent episode reward: [-9.535591294692782, 5.998212857859355, 5.998212857859355], time: 74.841
steps: 149975, episodes: 6000, mean episode reward: 2.2097887895831207, agent episode reward: [-10.325758787333525, 6.267773788458323, 6.267773788458323], time: 74.808
steps: 174975, episodes: 7000, mean episode reward: 1.2872042276873334, agent episode reward: [-10.173543246454365, 5.73037373707085, 5.73037373707085], time: 74.976
steps: 199975, episodes: 8000, mean episode reward: 0.1837554062689959, agent episode reward: [-10.019728538906467, 5.101741972587732, 5.101741972587732], time: 74.765
steps: 224975, episodes: 9000, mean episode reward: -0.763874424125238, agent episode reward: [-10.108699437181704, 4.672412506528233, 4.672412506528233], time: 74.906
steps: 249975, episodes: 10000, mean episode reward: -0.5892656857664292, agent episode reward: [-10.624387576198, 5.017560945215785, 5.017560945215785], time: 75.241
steps: 274975, episodes: 11000, mean episode reward: -1.5499244996837274, agent episode reward: [-9.919699029649863, 4.184887264983067, 4.184887264983067], time: 74.491
steps: 299975, episodes: 12000, mean episode reward: -1.2868119120752954, agent episode reward: [-9.77242048036132, 4.242804284143014, 4.242804284143014], time: 74.842
steps: 324975, episodes: 13000, mean episode reward: -1.3950790874085806, agent episode reward: [-10.322812082228419, 4.463866497409917, 4.463866497409917], time: 75.019
steps: 349975, episodes: 14000, mean episode reward: -1.2841872406499593, agent episode reward: [-10.193673030936377, 4.45474289514321, 4.45474289514321], time: 74.849
steps: 374975, episodes: 15000, mean episode reward: -0.5802045998949543, agent episode reward: [-10.72514392320091, 5.0724696616529785, 5.0724696616529785], time: 74.738
steps: 399975, episodes: 16000, mean episode reward: -0.4966509145796449, agent episode reward: [-10.304621687626648, 4.903985386523501, 4.903985386523501], time: 75.459
steps: 424975, episodes: 17000, mean episode reward: -0.3124504905762224, agent episode reward: [-10.768946763189382, 5.22824813630658, 5.22824813630658], time: 74.384
steps: 449975, episodes: 18000, mean episode reward: 0.13949854688362806, agent episode reward: [-10.999002409468236, 5.569250478175932, 5.569250478175932], time: 74.826
steps: 474975, episodes: 19000, mean episode reward: -0.14557753976731416, agent episode reward: [-11.392808151357796, 5.623615305795242, 5.623615305795242], time: 75.405
steps: 499975, episodes: 20000, mean episode reward: -0.07236102652312686, agent episode reward: [-11.284838142161716, 5.606238557819295, 5.606238557819295], time: 75.166
steps: 524975, episodes: 21000, mean episode reward: 0.269612462348816, agent episode reward: [-11.561152832866307, 5.915382647607563, 5.915382647607563], time: 75.384
steps: 549975, episodes: 22000, mean episode reward: -0.36556594236820755, agent episode reward: [-10.698329903988023, 5.166381980809908, 5.166381980809908], time: 75.31
steps: 574975, episodes: 23000, mean episode reward: -0.011695850611660234, agent episode reward: [-12.440247318218036, 6.214275733803188, 6.214275733803188], time: 75.399
steps: 599975, episodes: 24000, mean episode reward: 0.8178146134837786, agent episode reward: [-11.976228928511048, 6.397021770997414, 6.397021770997414], time: 75.184
steps: 624975, episodes: 25000, mean episode reward: 0.08561200266193271, agent episode reward: [-12.693261364604028, 6.3894366836329795, 6.3894366836329795], time: 74.795
steps: 649975, episodes: 26000, mean episode reward: 0.5299836927419087, agent episode reward: [-12.004400436659743, 6.267192064700827, 6.267192064700827], time: 75.366
steps: 674975, episodes: 27000, mean episode reward: 0.905820200112769, agent episode reward: [-11.963833343657562, 6.434826771885165, 6.434826771885165], time: 74.978
steps: 699975, episodes: 28000, mean episode reward: 1.3158581449280098, agent episode reward: [-12.408245145703622, 6.862051645315816, 6.862051645315816], time: 75.494
steps: 724975, episodes: 29000, mean episode reward: 1.8287082818333042, agent episode reward: [-12.586230129279, 7.207469205556153, 7.207469205556153], time: 75.579
steps: 749975, episodes: 30000, mean episode reward: 1.711219861032459, agent episode reward: [-12.481197248558821, 7.0962085547956395, 7.0962085547956395], time: 75.409
steps: 774975, episodes: 31000, mean episode reward: 2.3176753820822906, agent episode reward: [-12.11466054589211, 7.216167963987201, 7.216167963987201], time: 75.29
steps: 799975, episodes: 32000, mean episode reward: 2.2782652916060178, agent episode reward: [-12.080445601305437, 7.179355446455728, 7.179355446455728], time: 75.433
steps: 824975, episodes: 33000, mean episode reward: 2.3436249682758765, agent episode reward: [-12.440601465131087, 7.392113216703481, 7.392113216703481], time: 74.744
steps: 849975, episodes: 34000, mean episode reward: 2.5463595853007126, agent episode reward: [-12.94468524473334, 7.745522415017025, 7.745522415017025], time: 75.168
steps: 874975, episodes: 35000, mean episode reward: 2.086371255992768, agent episode reward: [-13.092171337629447, 7.589271296811107, 7.589271296811107], time: 75.211
steps: 899975, episodes: 36000, mean episode reward: 2.9842024781345624, agent episode reward: [-13.276142988975854, 8.130172733555208, 8.130172733555208], time: 75.471
steps: 924975, episodes: 37000, mean episode reward: 2.5056974457174164, agent episode reward: [-13.6817396642789, 8.09371855499816, 8.09371855499816], time: 75.536
steps: 949975, episodes: 38000, mean episode reward: 2.701021625259835, agent episode reward: [-13.354672133895676, 8.027846879577755, 8.027846879577755], time: 75.073
steps: 974975, episodes: 39000, mean episode reward: 2.700912735915008, agent episode reward: [-13.275114005706767, 7.988013370810888, 7.988013370810888], time: 75.439
steps: 999975, episodes: 40000, mean episode reward: 2.7170530694861608, agent episode reward: [-13.308302357243496, 8.012677713364827, 8.012677713364827], time: 75.22
steps: 1024975, episodes: 41000, mean episode reward: 2.8074229910658643, agent episode reward: [-13.362498427881816, 8.084960709473842, 8.084960709473842], time: 75.552
steps: 1049975, episodes: 42000, mean episode reward: 2.8572557287160616, agent episode reward: [-12.781764766090204, 7.819510247403132, 7.819510247403132], time: 74.468
steps: 1074975, episodes: 43000, mean episode reward: 2.3197473645739772, agent episode reward: [-13.074810853554267, 7.697279109064122, 7.697279109064122], time: 74.433
steps: 1099975, episodes: 44000, mean episode reward: 2.4712502758485217, agent episode reward: [-13.865132642190995, 8.16819145901976, 8.16819145901976], time: 73.468
steps: 1124975, episodes: 45000, mean episode reward: 1.594016171038569, agent episode reward: [-13.77718267748924, 7.685599424263904, 7.685599424263904], time: 74.484
steps: 1149975, episodes: 46000, mean episode reward: 1.4398727161498028, agent episode reward: [-13.56553536863143, 7.502704042390617, 7.502704042390617], time: 73.76
steps: 1174975, episodes: 47000, mean episode reward: 1.277180177829994, agent episode reward: [-13.754649536491794, 7.515914857160893, 7.515914857160893], time: 74.431
steps: 1199975, episodes: 48000, mean episode reward: 1.1716624342201571, agent episode reward: [-13.369505064828354, 7.270583749524256, 7.270583749524256], time: 74.152
steps: 1224975, episodes: 49000, mean episode reward: 1.3689495528219664, agent episode reward: [-13.674982990746159, 7.521966271784063, 7.521966271784063], time: 74.448
steps: 1249975, episodes: 50000, mean episode reward: 2.0154823016279186, agent episode reward: [-13.3521418102014, 7.68381205591466, 7.68381205591466], time: 74.392
steps: 1274975, episodes: 51000, mean episode reward: 1.3310319918403655, agent episode reward: [-13.31186727417209, 7.321449633006227, 7.321449633006227], time: 74.108
steps: 1299975, episodes: 52000, mean episode reward: 1.6930844002778576, agent episode reward: [-14.038881017859396, 7.865982709068627, 7.865982709068627], time: 74.1
steps: 1324975, episodes: 53000, mean episode reward: 1.8463503720622492, agent episode reward: [-14.137501890040948, 7.991926131051599, 7.991926131051599], time: 73.616
steps: 1349975, episodes: 54000, mean episode reward: 2.1647330271998153, agent episode reward: [-15.233286012737777, 8.699009519968795, 8.699009519968795], time: 74.304
steps: 1374975, episodes: 55000, mean episode reward: 2.431518092989386, agent episode reward: [-14.150279435656472, 8.290898764322929, 8.290898764322929], time: 74.337
steps: 1399975, episodes: 56000, mean episode reward: 2.410731186427264, agent episode reward: [-14.643456559902964, 8.527093873165114, 8.527093873165114], time: 74.226
steps: 1424975, episodes: 57000, mean episode reward: 2.384010087141656, agent episode reward: [-14.710812952331835, 8.547411519736745, 8.547411519736745], time: 73.059
steps: 1449975, episodes: 58000, mean episode reward: 2.2529286258743437, agent episode reward: [-14.41957669692397, 8.336252661399158, 8.336252661399158], time: 74.379
steps: 1474975, episodes: 59000, mean episode reward: 1.8040332947625264, agent episode reward: [-14.577440899004742, 8.190737096883636, 8.190737096883636], time: 73.937
steps: 1499975, episodes: 60000, mean episode reward: 2.6486144481549987, agent episode reward: [-14.123124195408659, 8.38586932178183, 8.38586932178183], time: 74.649
...Finished total of 60001 episodes.
