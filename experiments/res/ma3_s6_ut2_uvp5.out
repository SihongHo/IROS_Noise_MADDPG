Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  0.5
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -24.32749223384019, agent episode reward: [-24.465877640624967, 0.06919270339239117, 0.06919270339239117], time: 84.18
steps: 49975, episodes: 2000, mean episode reward: -24.063337563177374, agent episode reward: [-19.463972220585966, -2.299682671295702, -2.299682671295702], time: 109.526
steps: 74975, episodes: 3000, mean episode reward: -21.17777344671344, agent episode reward: [-18.207662094096012, -1.4850556763087155, -1.4850556763087155], time: 108.012
steps: 99975, episodes: 4000, mean episode reward: -23.90207686791714, agent episode reward: [-29.120384003496497, 2.6091535677896824, 2.6091535677896824], time: 110.471
steps: 124975, episodes: 5000, mean episode reward: -1.3722142092199183, agent episode reward: [-15.730949487649847, 7.179367639214965, 7.179367639214965], time: 110.338
steps: 149975, episodes: 6000, mean episode reward: 12.757792780611176, agent episode reward: [-21.25102105326578, 17.00440691693848, 17.00440691693848], time: 110.514
steps: 174975, episodes: 7000, mean episode reward: 20.836602610230493, agent episode reward: [-23.774831532852353, 22.305717071541427, 22.305717071541427], time: 110.317
steps: 199975, episodes: 8000, mean episode reward: 14.802018668166841, agent episode reward: [-24.9044450401256, 19.853231854146223, 19.853231854146223], time: 110.38
steps: 224975, episodes: 9000, mean episode reward: 20.501461656305416, agent episode reward: [-23.513739439284304, 22.00760054779486, 22.00760054779486], time: 109.634
steps: 249975, episodes: 10000, mean episode reward: 19.794441675655627, agent episode reward: [-23.07856939250581, 21.436505534080716, 21.436505534080716], time: 109.589
steps: 274975, episodes: 11000, mean episode reward: 18.62594762119807, agent episode reward: [-22.29164168105806, 20.458794651128063, 20.458794651128063], time: 110.29
steps: 299975, episodes: 12000, mean episode reward: 18.07749526553489, agent episode reward: [-21.87665288451022, 19.977074075022554, 19.977074075022554], time: 110.847
steps: 324975, episodes: 13000, mean episode reward: 6.584592448103538, agent episode reward: [-20.84081052943917, 13.712701488771355, 13.712701488771355], time: 111.479
steps: 349975, episodes: 14000, mean episode reward: 16.448322032504162, agent episode reward: [-19.865311700300577, 18.156816866402366, 18.156816866402366], time: 110.643
steps: 374975, episodes: 15000, mean episode reward: 17.994436466526647, agent episode reward: [-21.6799154284331, 19.837175947479874, 19.837175947479874], time: 110.549
steps: 399975, episodes: 16000, mean episode reward: 19.906416262602583, agent episode reward: [-23.477982339444424, 21.692199301023503, 21.692199301023503], time: 111.034
steps: 424975, episodes: 17000, mean episode reward: 19.320540472462067, agent episode reward: [-22.436879561859385, 20.878710017160728, 20.878710017160728], time: 110.47
steps: 449975, episodes: 18000, mean episode reward: 19.612344967531403, agent episode reward: [-22.565734727630232, 21.089039847580818, 21.089039847580818], time: 109.899
steps: 474975, episodes: 19000, mean episode reward: 18.50433264931377, agent episode reward: [-21.469314536729176, 19.986823593021473, 19.986823593021473], time: 111.147
steps: 499975, episodes: 20000, mean episode reward: 17.843330024491465, agent episode reward: [-21.196812306381585, 19.520071165436523, 19.520071165436523], time: 110.362
steps: 524975, episodes: 21000, mean episode reward: 17.12900976218193, agent episode reward: [-20.69036041602758, 18.909685089104755, 18.909685089104755], time: 109.997
steps: 549975, episodes: 22000, mean episode reward: 17.32936200255961, agent episode reward: [-20.637486597021866, 18.98342429979074, 18.98342429979074], time: 110.107
steps: 574975, episodes: 23000, mean episode reward: 17.809735086325695, agent episode reward: [-20.92049582179629, 19.365115454060994, 19.365115454060994], time: 110.61
steps: 599975, episodes: 24000, mean episode reward: 18.423232212156705, agent episode reward: [-21.458524217201884, 19.940878214679294, 19.940878214679294], time: 111.433
steps: 624975, episodes: 25000, mean episode reward: 16.744614257435604, agent episode reward: [-19.7048330705036, 18.224723663969606, 18.224723663969606], time: 110.742
steps: 649975, episodes: 26000, mean episode reward: 18.178068431837556, agent episode reward: [-21.30237702398415, 19.74022272791085, 19.74022272791085], time: 111.398
steps: 674975, episodes: 27000, mean episode reward: 18.07527163175482, agent episode reward: [-21.09600713038191, 19.58563938106836, 19.58563938106836], time: 110.715
steps: 699975, episodes: 28000, mean episode reward: 17.341083834124486, agent episode reward: [-20.377138560822626, 18.859111197473553, 18.859111197473553], time: 111.411
steps: 724975, episodes: 29000, mean episode reward: 16.48128578842499, agent episode reward: [-19.586213048509737, 18.033749418467362, 18.033749418467362], time: 110.872
steps: 749975, episodes: 30000, mean episode reward: 16.037944330164805, agent episode reward: [-18.89080018403278, 17.46437225709879, 17.46437225709879], time: 111.532
steps: 774975, episodes: 31000, mean episode reward: 15.980100373233954, agent episode reward: [-19.14559236625072, 17.562846369742335, 17.562846369742335], time: 110.467
steps: 799975, episodes: 32000, mean episode reward: 15.293925992842508, agent episode reward: [-18.086906559323346, 16.690416276082928, 16.690416276082928], time: 110.851
steps: 824975, episodes: 33000, mean episode reward: 16.069768474051386, agent episode reward: [-19.203642099074777, 17.636705286563082, 17.636705286563082], time: 111.113
steps: 849975, episodes: 34000, mean episode reward: 16.533020042609277, agent episode reward: [-19.7178701013311, 18.125445071970184, 18.125445071970184], time: 111.02
steps: 874975, episodes: 35000, mean episode reward: 17.465015865512612, agent episode reward: [-20.75828261168162, 19.111649238597114, 19.111649238597114], time: 109.882
steps: 899975, episodes: 36000, mean episode reward: 18.295986645185824, agent episode reward: [-21.651491385472944, 19.973739015329382, 19.973739015329382], time: 110.77
steps: 924975, episodes: 37000, mean episode reward: 16.815033176606253, agent episode reward: [-20.09940866694003, 18.45722092177314, 18.45722092177314], time: 109.832
steps: 949975, episodes: 38000, mean episode reward: 17.435880757277772, agent episode reward: [-20.55181701862942, 18.9938488879536, 18.9938488879536], time: 111.009
steps: 974975, episodes: 39000, mean episode reward: 17.271356680268894, agent episode reward: [-20.41774089187914, 18.844548786074018, 18.844548786074018], time: 110.199
steps: 999975, episodes: 40000, mean episode reward: 16.04929442612428, agent episode reward: [-19.6268940982504, 17.83809426218734, 17.83809426218734], time: 111.089
steps: 1024975, episodes: 41000, mean episode reward: 15.662816853915963, agent episode reward: [-18.901378397311206, 17.282097625613584, 17.282097625613584], time: 109.983
steps: 1049975, episodes: 42000, mean episode reward: 15.397188290208705, agent episode reward: [-19.301654478656054, 17.349421384432382, 17.349421384432382], time: 109.361
steps: 1074975, episodes: 43000, mean episode reward: 15.245657255129624, agent episode reward: [-20.2941553742398, 17.76990631468471, 17.76990631468471], time: 110.553
steps: 1099975, episodes: 44000, mean episode reward: 15.149380142215708, agent episode reward: [-19.320786216378714, 17.23508317929721, 17.23508317929721], time: 111.175
steps: 1124975, episodes: 45000, mean episode reward: 16.65776896546801, agent episode reward: [-20.779721674418674, 18.71874531994334, 18.71874531994334], time: 110.48
steps: 1149975, episodes: 46000, mean episode reward: 17.068794538399402, agent episode reward: [-21.668295294712763, 19.368544916556083, 19.368544916556083], time: 110.527
steps: 1174975, episodes: 47000, mean episode reward: 15.936333619578766, agent episode reward: [-25.20248802053456, 20.569410820056664, 20.569410820056664], time: 110.591
steps: 1199975, episodes: 48000, mean episode reward: 14.543397984651001, agent episode reward: [-19.010291976737104, 16.77684498069405, 16.77684498069405], time: 112.243
steps: 1224975, episodes: 49000, mean episode reward: 13.843308548770262, agent episode reward: [-18.458324412799527, 16.150816480784894, 16.150816480784894], time: 110.918
steps: 1249975, episodes: 50000, mean episode reward: 12.116327623938847, agent episode reward: [-17.936562211839913, 15.026444917889378, 15.026444917889378], time: 110.741
steps: 1274975, episodes: 51000, mean episode reward: 13.905964777302255, agent episode reward: [-18.82927204290121, 16.36761841010173, 16.36761841010173], time: 111.775
steps: 1299975, episodes: 52000, mean episode reward: 12.472427139297643, agent episode reward: [-25.859576007564776, 19.166001573431206, 19.166001573431206], time: 111.639
steps: 1324975, episodes: 53000, mean episode reward: 21.42710055809348, agent episode reward: [-24.71040630772078, 23.068753432907133, 23.068753432907133], time: 110.975
steps: 1349975, episodes: 54000, mean episode reward: 7.043014849998696, agent episode reward: [-13.09911241217699, 10.071063631087844, 10.071063631087844], time: 111.274
steps: 1374975, episodes: 55000, mean episode reward: 12.421656136179768, agent episode reward: [-29.017172650225884, 20.71941439320283, 20.71941439320283], time: 111.322
steps: 1399975, episodes: 56000, mean episode reward: 18.515869171772056, agent episode reward: [-28.022265878560116, 23.26906752516609, 23.26906752516609], time: 110.689
steps: 1424975, episodes: 57000, mean episode reward: 19.516601255094734, agent episode reward: [-24.82359379590428, 22.170097525499507, 22.170097525499507], time: 111.331
steps: 1449975, episodes: 58000, mean episode reward: 11.071112680684395, agent episode reward: [-15.41349791726127, 13.242305298972834, 13.242305298972834], time: 111.308
steps: 1474975, episodes: 59000, mean episode reward: -8.511512006575078, agent episode reward: [-19.217902710832867, 5.353195352128894, 5.353195352128894], time: 111.803
steps: 1499975, episodes: 60000, mean episode reward: -4.453177240156763, agent episode reward: [-35.390836017338934, 15.468829388591086, 15.468829388591086], time: 95.53
...Finished total of 60001 episodes.
