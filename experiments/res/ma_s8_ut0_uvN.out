Using good policy maddpg and adv policy maddpg
Uncertainty type is:  None ; Uncertainty level is:  1.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -27.144604882746282, agent episode reward: [0.7597186625228864, 0.8364147748622571, 0.7591415754170447, 0.8191286337963617, -12.420109617467107, -17.89889891187773], time: 146.219
steps: 49975, episodes: 2000, mean episode reward: -12.28508661427686, agent episode reward: [2.857943177098129, 2.870535136171779, 2.757006576576103, 2.9162306906023905, -13.640133090908167, -10.046669103817099], time: 248.991
steps: 74975, episodes: 3000, mean episode reward: 10.52919388967616, agent episode reward: [3.494037691264834, 3.443723664485592, 3.7502392647405216, 3.694769697857152, -1.9798843281503617, -1.8736921005215776], time: 272.606
steps: 99975, episodes: 4000, mean episode reward: 12.979971704185465, agent episode reward: [4.449186099208822, 4.325591268883954, 4.652431782683021, 4.2843251835399245, -2.1243592589636706, -2.6072033711665865], time: 272.42
steps: 124975, episodes: 5000, mean episode reward: 20.654007672175947, agent episode reward: [6.9087728956229295, 6.7982254901574946, 7.102030332102814, 6.726795412688035, -3.5011790619827687, -3.3806373964125607], time: 270.654
steps: 149975, episodes: 6000, mean episode reward: 25.47775787299651, agent episode reward: [8.468959704989826, 8.29012063693081, 8.422428802450195, 8.362465738306232, -4.192430320738588, -3.8737866889419674], time: 271.378
steps: 174975, episodes: 7000, mean episode reward: 30.471388564617282, agent episode reward: [10.074451141220806, 9.921139298467152, 9.774202071492866, 9.806020727648624, -4.420520799466325, -4.68390387474584], time: 272.114
steps: 199975, episodes: 8000, mean episode reward: 39.016245249683145, agent episode reward: [12.899235024063106, 12.830863100696991, 12.618444682821359, 12.531490982110503, -6.284708397192993, -5.579080142815821], time: 269.904
steps: 224975, episodes: 9000, mean episode reward: 38.84472214926724, agent episode reward: [12.770510100304964, 12.806725973499793, 12.766901011325203, 12.436057810532404, -5.916240043439573, -6.019232702955552], time: 270.876
steps: 249975, episodes: 10000, mean episode reward: 36.29709578931869, agent episode reward: [11.946188258134203, 11.983291577898909, 11.928997988278756, 11.683057826603733, -4.784402628232096, -6.4600372333648135], time: 272.144
steps: 274975, episodes: 11000, mean episode reward: 35.83791200721108, agent episode reward: [11.800763836988015, 11.790271671653976, 11.78212211224359, 11.538984516308762, -4.495543809577766, -6.5786863204054935], time: 271.726
steps: 299975, episodes: 12000, mean episode reward: 26.464225565410494, agent episode reward: [8.837464745302489, 8.682406854234166, 8.65182211741907, 8.557482033534649, -3.254036299587382, -5.010913885492497], time: 271.699
steps: 324975, episodes: 13000, mean episode reward: 23.62222892467603, agent episode reward: [8.27970508356731, 8.08087236086858, 8.094139920107938, 8.188476873745103, -4.73906473592206, -4.281900577690843], time: 273.133
steps: 349975, episodes: 14000, mean episode reward: 15.49245330062781, agent episode reward: [6.124290359036279, 5.958380663292979, 5.925716713249438, 6.017122882590873, -4.050630485883205, -4.482426831658556], time: 271.118
steps: 374975, episodes: 15000, mean episode reward: 15.906139282537065, agent episode reward: [6.0213957006593954, 5.8573618053253, 5.814251423393395, 5.924192979908388, -3.1046658192060166, -4.606396807543393], time: 272.542
steps: 399975, episodes: 16000, mean episode reward: 13.884789320534907, agent episode reward: [5.745987460572812, 5.637951181053934, 5.609062835561491, 5.631498734864976, -3.626825168665491, -5.112885722852815], time: 271.065
steps: 424975, episodes: 17000, mean episode reward: 15.105771413044067, agent episode reward: [5.838074465716009, 5.777195858048583, 5.7197458993427315, 5.763192843554356, -3.617561296238312, -4.3748763573793], time: 274.182
steps: 449975, episodes: 18000, mean episode reward: 17.114618589772313, agent episode reward: [6.123244688863514, 6.139729467364973, 6.057859505751707, 6.02381614959695, -3.56908598215439, -3.660945239650443], time: 272.547
steps: 474975, episodes: 19000, mean episode reward: 20.009929078104303, agent episode reward: [7.031958087901589, 7.040491743431429, 6.9542561930951745, 6.92047030908998, -3.8338100327536275, -4.103437222660239], time: 273.244
steps: 499975, episodes: 20000, mean episode reward: 19.360915584245728, agent episode reward: [6.932260245547448, 6.955676067687114, 6.893075262329321, 6.793227493682051, -3.7849735586250537, -4.428349926375151], time: 272.581
steps: 524975, episodes: 21000, mean episode reward: 22.06357145772015, agent episode reward: [7.7160910679952535, 7.657750230656549, 7.624106612921668, 7.575107952179772, -3.699728167923722, -4.809756238109371], time: 271.395
steps: 549975, episodes: 22000, mean episode reward: 20.425968778833944, agent episode reward: [6.835845251853342, 6.874490461306349, 6.907002541787395, 6.730111911589547, -2.736829339088299, -4.184652048614389], time: 272.078
steps: 574975, episodes: 23000, mean episode reward: 18.769693040783043, agent episode reward: [6.1013238583305025, 6.11792338260169, 6.18535440162899, 6.042974636793314, -2.5668159788956846, -3.1110672596757682], time: 270.962
steps: 599975, episodes: 24000, mean episode reward: 20.103900000796735, agent episode reward: [6.556249012480362, 6.461414836457194, 6.601611904380974, 6.431619819498644, -2.638085195905804, -3.3089103761146363], time: 272.165
steps: 624975, episodes: 25000, mean episode reward: 18.783515639960335, agent episode reward: [6.115011062041582, 6.016535679743098, 6.05960746521982, 6.056502385098877, -2.852623180062698, -2.611517772080345], time: 270.568
steps: 649975, episodes: 26000, mean episode reward: 19.41978823309975, agent episode reward: [6.444648988785895, 6.3498990793471615, 6.362234194517832, 6.4816430752892895, -3.366680805743148, -2.851956299097278], time: 270.921
steps: 674975, episodes: 27000, mean episode reward: 20.02915971783064, agent episode reward: [6.45193668999198, 6.315518228956721, 6.352672472333042, 6.446067616980261, -2.641984606715522, -2.8950506837158385], time: 271.013
steps: 699975, episodes: 28000, mean episode reward: 19.840099161719106, agent episode reward: [6.434371193985619, 6.342004167106727, 6.333811102313048, 6.379224667900545, -3.0701477263959687, -2.579164243190865], time: 271.567
steps: 724975, episodes: 29000, mean episode reward: 21.253246555452222, agent episode reward: [6.904708335779551, 6.844863410758283, 6.8158639746253495, 6.82964721689012, -3.754724688088481, -2.387111694512606], time: 270.155
steps: 749975, episodes: 30000, mean episode reward: 17.507898841567346, agent episode reward: [5.776336696840091, 5.72590501138402, 5.689097014830545, 5.65152716384402, -3.3329147257608307, -2.0020523195704993], time: 269.525
steps: 774975, episodes: 31000, mean episode reward: 17.619577546652057, agent episode reward: [5.870044281343213, 5.839385122483542, 5.865602178907164, 5.758541759396349, -3.334217535767836, -2.379778259710378], time: 266.968
steps: 799975, episodes: 32000, mean episode reward: 18.348528088881455, agent episode reward: [6.261500355423903, 6.252206855817328, 6.314323714067905, 6.160977143954585, -3.5351260142607837, -3.1053539661214846], time: 267.589
steps: 824975, episodes: 33000, mean episode reward: 20.159278690109232, agent episode reward: [6.788881661933575, 6.763964795271815, 6.773525418893591, 6.640076139181411, -4.193905099295981, -2.6132642258751777], time: 266.983
steps: 849975, episodes: 34000, mean episode reward: 24.514999803685047, agent episode reward: [8.200105177087057, 8.070291482796382, 8.139378155837708, 8.013594165202935, -5.108418374489061, -2.799950802749973], time: 267.152
steps: 874975, episodes: 35000, mean episode reward: 22.5977266311116, agent episode reward: [7.755944705221813, 7.7274665121724535, 7.785177141882568, 7.65766073559346, -5.989526800106096, -2.338995663652599], time: 263.893
steps: 899975, episodes: 36000, mean episode reward: 21.968685711799967, agent episode reward: [7.606830666401244, 7.516920004390501, 7.550285241172743, 7.394037209690952, -6.1386186793267115, -1.9607687305287569], time: 263.6
steps: 924975, episodes: 37000, mean episode reward: 23.013388158413356, agent episode reward: [7.856869881682027, 7.828546753570421, 7.943781721139808, 7.767124624688033, -5.593277992193483, -2.789656830473446], time: 262.302
steps: 949975, episodes: 38000, mean episode reward: 24.80105463949774, agent episode reward: [8.296913520629204, 8.347010038400652, 8.399869490688985, 8.216873399049096, -6.502542172121243, -1.9570696371489578], time: 263.25
steps: 974975, episodes: 39000, mean episode reward: 23.972083115789513, agent episode reward: [8.0805539131056, 8.061110149682863, 8.163763876821802, 7.9978110815592975, -6.307514098953714, -2.023641806426337], time: 262.872
steps: 999975, episodes: 40000, mean episode reward: 20.657785857626745, agent episode reward: [7.237369409775618, 7.402408018506287, 7.3747563428332255, 7.304732989873154, -6.694606007058298, -1.9668748963032412], time: 266.089
steps: 1024975, episodes: 41000, mean episode reward: 21.47750487512074, agent episode reward: [7.362160723748373, 7.618070183218642, 7.66895721950098, 7.65390110463927, -6.677214942378697, -2.1483694136078286], time: 262.251
steps: 1049975, episodes: 42000, mean episode reward: 24.506766727418217, agent episode reward: [8.298793707795546, 8.30772100953032, 8.370885084339628, 8.377776488530342, -7.036273788820232, -1.812135773957387], time: 263.848
steps: 1074975, episodes: 43000, mean episode reward: 25.089038426151596, agent episode reward: [8.469293438729586, 8.515360129843678, 8.415508152516711, 8.582715626090554, -6.620743581904, -2.273095339124933], time: 260.058
steps: 1099975, episodes: 44000, mean episode reward: 27.567631159220404, agent episode reward: [9.35300767784087, 9.321479785216571, 9.200379736724392, 9.367612674639888, -7.663324981908125, -2.011523733293185], time: 262.444
steps: 1124975, episodes: 45000, mean episode reward: 30.22721734276981, agent episode reward: [10.193291879882908, 10.065843239985313, 9.921824003380465, 10.067798879669084, -8.006813067484895, -2.014727592663065], time: 263.121
steps: 1149975, episodes: 46000, mean episode reward: 25.876652710636357, agent episode reward: [8.866260236979194, 8.797984631141153, 8.593754502198095, 8.730462127426712, -6.81452749579426, -2.29728129131454], time: 260.009
steps: 1174975, episodes: 47000, mean episode reward: 27.335936655842627, agent episode reward: [9.234655983913031, 9.126598142524555, 8.883481735163326, 9.019387233345988, -6.982002505689056, -1.94618393341522], time: 260.418
steps: 1199975, episodes: 48000, mean episode reward: 28.17715616612868, agent episode reward: [9.533525643732041, 9.364012637717734, 9.114753609873787, 9.236687061679033, -6.9067628071139175, -2.1650599797599925], time: 261.255
steps: 1224975, episodes: 49000, mean episode reward: 32.25126676941738, agent episode reward: [10.992841760355985, 10.755636805905953, 10.619702836614369, 10.619322377127064, -8.977194790142722, -1.7590422204432759], time: 263.124
steps: 1249975, episodes: 50000, mean episode reward: 33.39889511091368, agent episode reward: [11.458066322304127, 11.086857273153834, 11.028368499389169, 11.01514641750845, -9.120617665472034, -2.068925735969868], time: 259.795
steps: 1274975, episodes: 51000, mean episode reward: 33.60071281840966, agent episode reward: [11.343186201919504, 11.07275380659306, 11.065185593582145, 10.931209340674672, -8.977794799154676, -1.8338273252050505], time: 262.317
steps: 1299975, episodes: 52000, mean episode reward: 39.9990131406, agent episode reward: [13.45126297178425, 13.307640508833122, 13.15691451577664, 13.139447847255116, -11.073719736825241, -1.9825329662238855], time: 264.174
steps: 1324975, episodes: 53000, mean episode reward: 43.87379187401101, agent episode reward: [14.971713716713479, 14.678684122960139, 14.546095998033103, 14.549955640631433, -13.030092782194078, -1.8425648221330655], time: 263.386
steps: 1349975, episodes: 54000, mean episode reward: 43.39329306808237, agent episode reward: [15.134084729527254, 14.852978559597789, 14.720914638321716, 14.728789753684142, -13.258695235570553, -2.7847793774779706], time: 263.195
steps: 1374975, episodes: 55000, mean episode reward: 44.9494138714454, agent episode reward: [15.890440756239824, 15.469233190945628, 15.430902243082924, 15.340128754369903, -14.538842883405218, -2.6424481897876606], time: 260.427
steps: 1399975, episodes: 56000, mean episode reward: 39.86186508101966, agent episode reward: [13.91101298931822, 13.514546153831912, 13.388384609111435, 13.363842833755136, -12.891670057024728, -1.4242514479723185], time: 261.548
steps: 1424975, episodes: 57000, mean episode reward: 40.2230144417313, agent episode reward: [14.248967572589288, 13.77467587451007, 13.740044990628416, 13.588684757323215, -13.332551401463203, -1.7968073518564842], time: 261.195
steps: 1449975, episodes: 58000, mean episode reward: 39.558152633740235, agent episode reward: [14.30038214105921, 13.86545016996935, 13.773605333888307, 13.829858787850874, -13.554452193258829, -2.6566916057686765], time: 259.473
steps: 1474975, episodes: 59000, mean episode reward: 38.40072405616137, agent episode reward: [13.871464843495174, 13.560426494662902, 13.37391522678513, 13.47355648535025, -13.589855284586974, -2.288783709545112], time: 261.625
steps: 1499975, episodes: 60000, mean episode reward: 33.307230626711025, agent episode reward: [12.596310355494781, 12.278203170411116, 12.077435255245835, 12.236235523882883, -12.483369046232408, -3.3975846320911804], time: 261.314
...Finished total of 60001 episodes.
