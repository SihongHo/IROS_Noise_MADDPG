Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  2.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -21.76819326190295, agent episode reward: [-35.92178645282709, 7.076796595462069, 7.076796595462069], time: 89.809
steps: 49975, episodes: 2000, mean episode reward: -24.11850067236642, agent episode reward: [-33.23030132949693, 4.555900328565258, 4.555900328565258], time: 114.009
steps: 74975, episodes: 3000, mean episode reward: -0.8759043188133798, agent episode reward: [-14.34897630605858, 6.736535993622599, 6.736535993622599], time: 113.255
steps: 99975, episodes: 4000, mean episode reward: 2.1775352187379675, agent episode reward: [-10.835823750313967, 6.506679484525966, 6.506679484525966], time: 113.291
steps: 124975, episodes: 5000, mean episode reward: 2.740788519622356, agent episode reward: [-10.164662766424122, 6.452725643023239, 6.452725643023239], time: 113.969
steps: 149975, episodes: 6000, mean episode reward: 2.7205323485793125, agent episode reward: [-10.110579934218784, 6.4155561413990485, 6.4155561413990485], time: 114.298
steps: 174975, episodes: 7000, mean episode reward: 2.3887882756723875, agent episode reward: [-9.669695481945958, 6.029241878809173, 6.029241878809173], time: 114.686
steps: 199975, episodes: 8000, mean episode reward: 1.828844842037136, agent episode reward: [-9.852840580647742, 5.8408427113424395, 5.8408427113424395], time: 113.806
steps: 224975, episodes: 9000, mean episode reward: 1.5043689828642686, agent episode reward: [-10.166653488948027, 5.835511235906148, 5.835511235906148], time: 113.719
steps: 249975, episodes: 10000, mean episode reward: 1.3487284425385342, agent episode reward: [-10.349621967103296, 5.849175204820915, 5.849175204820915], time: 113.768
steps: 274975, episodes: 11000, mean episode reward: 1.3137457909535675, agent episode reward: [-11.526106869635433, 6.4199263302945, 6.4199263302945], time: 114.199
steps: 299975, episodes: 12000, mean episode reward: 0.19433571186031945, agent episode reward: [-11.643660788349571, 5.918998250104945, 5.918998250104945], time: 114.871
steps: 324975, episodes: 13000, mean episode reward: 0.4946515227969351, agent episode reward: [-11.810813102724572, 6.152732312760754, 6.152732312760754], time: 113.936
steps: 349975, episodes: 14000, mean episode reward: 0.33211461937494563, agent episode reward: [-12.7023162282747, 6.5172154238248226, 6.5172154238248226], time: 114.286
steps: 374975, episodes: 15000, mean episode reward: -0.22888584961877392, agent episode reward: [-12.086414874434224, 5.928764512407724, 5.928764512407724], time: 115.513
steps: 399975, episodes: 16000, mean episode reward: -0.07579799149807656, agent episode reward: [-11.989906946588105, 5.9570544775450145, 5.9570544775450145], time: 114.157
steps: 424975, episodes: 17000, mean episode reward: -0.5453465866884014, agent episode reward: [-11.746932448273736, 5.600792930792668, 5.600792930792668], time: 114.433
steps: 449975, episodes: 18000, mean episode reward: 0.5672638327671208, agent episode reward: [-12.079836377019502, 6.323550104893313, 6.323550104893313], time: 114.511
steps: 474975, episodes: 19000, mean episode reward: 0.5359848846009242, agent episode reward: [-12.533462047819555, 6.53472346621024, 6.53472346621024], time: 114.907
steps: 499975, episodes: 20000, mean episode reward: 0.4239167644564879, agent episode reward: [-11.88568871443257, 6.154802739444529, 6.154802739444529], time: 113.931
steps: 524975, episodes: 21000, mean episode reward: 0.13414674789365544, agent episode reward: [-12.549828108138213, 6.341987428015933, 6.341987428015933], time: 114.042
steps: 549975, episodes: 22000, mean episode reward: -0.7492420350027078, agent episode reward: [-11.898091752418582, 5.574424858707938, 5.574424858707938], time: 113.678
steps: 574975, episodes: 23000, mean episode reward: 0.00750431631893548, agent episode reward: [-13.689986710689464, 6.848745513504198, 6.848745513504198], time: 114.441
steps: 599975, episodes: 24000, mean episode reward: -0.3785397719168801, agent episode reward: [-13.069018387082211, 6.3452393075826645, 6.3452393075826645], time: 114.929
steps: 624975, episodes: 25000, mean episode reward: 0.07530764544218607, agent episode reward: [-11.860807086909945, 5.968057366176065, 5.968057366176065], time: 114.696
steps: 649975, episodes: 26000, mean episode reward: 0.7617268111752467, agent episode reward: [-12.964055486319737, 6.862891148747492, 6.862891148747492], time: 113.878
steps: 674975, episodes: 27000, mean episode reward: 0.36440441840943777, agent episode reward: [-12.949869910918974, 6.6571371646642055, 6.6571371646642055], time: 113.894
steps: 699975, episodes: 28000, mean episode reward: -0.34721161829779396, agent episode reward: [-13.071859374672677, 6.362323878187442, 6.362323878187442], time: 114.407
steps: 724975, episodes: 29000, mean episode reward: 0.3250782084117471, agent episode reward: [-12.83989349424314, 6.582485851327443, 6.582485851327443], time: 115.376
steps: 749975, episodes: 30000, mean episode reward: 0.5574285655129035, agent episode reward: [-18.03625490539086, 9.296841735451883, 9.296841735451883], time: 116.14
steps: 774975, episodes: 31000, mean episode reward: -0.45369593734091435, agent episode reward: [-14.333334097932584, 6.939819080295836, 6.939819080295836], time: 114.697
steps: 799975, episodes: 32000, mean episode reward: -0.01241222405680827, agent episode reward: [-15.255889736907807, 7.6217387564255, 7.6217387564255], time: 113.562
steps: 824975, episodes: 33000, mean episode reward: 0.08731252351684389, agent episode reward: [-13.083048542163178, 6.5851805328400115, 6.5851805328400115], time: 113.98
steps: 849975, episodes: 34000, mean episode reward: 0.3179363310281231, agent episode reward: [-12.893975282287094, 6.605955806657608, 6.605955806657608], time: 113.664
steps: 874975, episodes: 35000, mean episode reward: 0.9363291622288559, agent episode reward: [-12.563633809964372, 6.7499814860966145, 6.7499814860966145], time: 114.451
steps: 899975, episodes: 36000, mean episode reward: 0.9635623942164873, agent episode reward: [-11.578732521407407, 6.271147457811946, 6.271147457811946], time: 114.073
steps: 924975, episodes: 37000, mean episode reward: -0.6105209212714069, agent episode reward: [-12.31348207725454, 5.851480577991566, 5.851480577991566], time: 114.547
steps: 949975, episodes: 38000, mean episode reward: 0.34426011490944974, agent episode reward: [-12.562950317186182, 6.453605216047815, 6.453605216047815], time: 115.258
steps: 974975, episodes: 39000, mean episode reward: -0.35374315152903246, agent episode reward: [-12.126477106532507, 5.886366977501738, 5.886366977501738], time: 114.676
steps: 999975, episodes: 40000, mean episode reward: 0.6711914133858007, agent episode reward: [-13.243566818276344, 6.957379115831072, 6.957379115831072], time: 113.912
steps: 1024975, episodes: 41000, mean episode reward: 0.2630948885557633, agent episode reward: [-12.015897809916908, 6.139496349236336, 6.139496349236336], time: 114.79
steps: 1049975, episodes: 42000, mean episode reward: -0.21968735484605048, agent episode reward: [-11.997506477685118, 5.888909561419534, 5.888909561419534], time: 113.581
steps: 1074975, episodes: 43000, mean episode reward: 0.01640346562916281, agent episode reward: [-12.12003653063702, 6.068219998133091, 6.068219998133091], time: 114.535
steps: 1099975, episodes: 44000, mean episode reward: -0.28345908934162733, agent episode reward: [-12.624185048070718, 6.170362979364547, 6.170362979364547], time: 113.236
steps: 1124975, episodes: 45000, mean episode reward: 0.1287390569485543, agent episode reward: [-12.00771095345724, 6.068225005202897, 6.068225005202897], time: 114.386
steps: 1149975, episodes: 46000, mean episode reward: -0.4896802215068047, agent episode reward: [-12.037530524386627, 5.77392515143991, 5.77392515143991], time: 114.979
steps: 1174975, episodes: 47000, mean episode reward: -0.5298303087757, agent episode reward: [-11.820943107993, 5.645556399608649, 5.645556399608649], time: 115.212
steps: 1199975, episodes: 48000, mean episode reward: -0.6557224314701204, agent episode reward: [-11.449005047596645, 5.396641308063262, 5.396641308063262], time: 115.836
steps: 1224975, episodes: 49000, mean episode reward: -0.8130285398279453, agent episode reward: [-11.526109191289821, 5.356540325730937, 5.356540325730937], time: 114.834
steps: 1249975, episodes: 50000, mean episode reward: -0.25923580252218736, agent episode reward: [-12.521118097574412, 6.130941147526112, 6.130941147526112], time: 114.064
steps: 1274975, episodes: 51000, mean episode reward: -0.9548970882318029, agent episode reward: [-12.229488820443901, 5.637295866106048, 5.637295866106048], time: 114.269
steps: 1299975, episodes: 52000, mean episode reward: 0.16024263001973565, agent episode reward: [-12.056784249683245, 6.108513439851491, 6.108513439851491], time: 113.777
steps: 1324975, episodes: 53000, mean episode reward: -1.1025812726434252, agent episode reward: [-12.356142216938188, 5.626780472147381, 5.626780472147381], time: 114.567
steps: 1349975, episodes: 54000, mean episode reward: 0.07508191392713104, agent episode reward: [-11.877827159935984, 5.976454536931558, 5.976454536931558], time: 114.53
steps: 1374975, episodes: 55000, mean episode reward: -0.7677988840879002, agent episode reward: [-12.23942613711756, 5.73581362651483, 5.73581362651483], time: 113.926
steps: 1399975, episodes: 56000, mean episode reward: 0.24457188383315845, agent episode reward: [-12.859146557099459, 6.551859220466309, 6.551859220466309], time: 113.737
steps: 1424975, episodes: 57000, mean episode reward: -1.3416371561266538, agent episode reward: [-12.544473572409574, 5.60141820814146, 5.60141820814146], time: 114.924
steps: 1449975, episodes: 58000, mean episode reward: -1.7988130915163858, agent episode reward: [-13.136777767662876, 5.668982338073243, 5.668982338073243], time: 114.29
steps: 1474975, episodes: 59000, mean episode reward: -0.4294224505860154, agent episode reward: [-12.594501246457, 6.082539397935492, 6.082539397935492], time: 116.067
steps: 1499975, episodes: 60000, mean episode reward: -0.417222347622573, agent episode reward: [-12.2359432904285, 5.909360471402963, 5.909360471402963], time: 112.746
...Finished total of 60001 episodes.
