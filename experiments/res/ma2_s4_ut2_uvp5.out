Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  0.5
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -23.31318882799095, agent episode reward: [-37.96830677563638, 7.327558973822718, 7.327558973822718], time: 64.992
steps: 49975, episodes: 2000, mean episode reward: -22.969016069366074, agent episode reward: [-25.423280469308928, 1.227132199971425, 1.227132199971425], time: 103.946
steps: 74975, episodes: 3000, mean episode reward: -2.1835042385522936, agent episode reward: [-12.05964878505945, 4.938072273253579, 4.938072273253579], time: 105.365
steps: 99975, episodes: 4000, mean episode reward: 3.891497001926374, agent episode reward: [-10.253925231745209, 7.072711116835792, 7.072711116835792], time: 105.628
steps: 124975, episodes: 5000, mean episode reward: 3.418230566538639, agent episode reward: [-9.358258490755347, 6.388244528646992, 6.388244528646992], time: 105.84
steps: 149975, episodes: 6000, mean episode reward: 3.2488319015016742, agent episode reward: [-9.767114097810712, 6.507972999656194, 6.507972999656194], time: 105.551
steps: 174975, episodes: 7000, mean episode reward: 2.058157591302342, agent episode reward: [-9.996485008464912, 6.027321299883628, 6.027321299883628], time: 105.661
steps: 199975, episodes: 8000, mean episode reward: 1.796831185843809, agent episode reward: [-9.688601758999438, 5.742716472421622, 5.742716472421622], time: 104.987
steps: 224975, episodes: 9000, mean episode reward: 1.3612104692640488, agent episode reward: [-10.496968376563913, 5.9290894229139814, 5.9290894229139814], time: 106.023
steps: 249975, episodes: 10000, mean episode reward: 0.5410540125198683, agent episode reward: [-10.541085196345367, 5.541069604432618, 5.541069604432618], time: 105.905
steps: 274975, episodes: 11000, mean episode reward: -0.39009536542671563, agent episode reward: [-10.19118925548924, 4.9005469450312615, 4.9005469450312615], time: 105.718
steps: 299975, episodes: 12000, mean episode reward: -0.14654679239962964, agent episode reward: [-11.022364892880837, 5.437909050240604, 5.437909050240604], time: 106.013
steps: 324975, episodes: 13000, mean episode reward: -0.19994848651829425, agent episode reward: [-10.470578344829068, 5.135314929155387, 5.135314929155387], time: 105.442
steps: 349975, episodes: 14000, mean episode reward: 0.3775563987386136, agent episode reward: [-10.783486878962137, 5.580521638850375, 5.580521638850375], time: 105.06
steps: 374975, episodes: 15000, mean episode reward: 0.5913819111274381, agent episode reward: [-10.591045962401365, 5.591213936764401, 5.591213936764401], time: 105.516
steps: 399975, episodes: 16000, mean episode reward: 0.41110540169538307, agent episode reward: [-11.073302916501154, 5.742204159098268, 5.742204159098268], time: 105.493
steps: 424975, episodes: 17000, mean episode reward: -0.26872235242046394, agent episode reward: [-10.34308362792754, 5.037180637753537, 5.037180637753537], time: 105.352
steps: 449975, episodes: 18000, mean episode reward: -0.8242744951700683, agent episode reward: [-11.592680865017561, 5.384203184923747, 5.384203184923747], time: 105.321
steps: 474975, episodes: 19000, mean episode reward: 0.7124521745584877, agent episode reward: [-10.98202125263005, 5.847236713594268, 5.847236713594268], time: 105.894
steps: 499975, episodes: 20000, mean episode reward: -0.010656544361300717, agent episode reward: [-11.367291372756442, 5.67831741419757, 5.67831741419757], time: 105.359
steps: 524975, episodes: 21000, mean episode reward: -0.2939989245820217, agent episode reward: [-11.823885775890696, 5.764943425654337, 5.764943425654337], time: 105.224
steps: 549975, episodes: 22000, mean episode reward: -0.1324708163378742, agent episode reward: [-11.67508467192881, 5.771306927795467, 5.771306927795467], time: 104.354
steps: 574975, episodes: 23000, mean episode reward: -1.0339614747535033, agent episode reward: [-11.685402741711368, 5.325720633478933, 5.325720633478933], time: 104.083
steps: 599975, episodes: 24000, mean episode reward: -0.6458723949604737, agent episode reward: [-11.5808963613333, 5.467511983186412, 5.467511983186412], time: 105.02
steps: 624975, episodes: 25000, mean episode reward: -0.5483769473161224, agent episode reward: [-11.394817673207253, 5.423220362945565, 5.423220362945565], time: 103.288
steps: 649975, episodes: 26000, mean episode reward: -0.8049196648869371, agent episode reward: [-11.910044701977627, 5.552562518545345, 5.552562518545345], time: 101.452
steps: 674975, episodes: 27000, mean episode reward: -0.22266926621107025, agent episode reward: [-11.719858382207843, 5.748594557998386, 5.748594557998386], time: 99.317
steps: 699975, episodes: 28000, mean episode reward: -0.43460673954874474, agent episode reward: [-11.723719449674114, 5.644556355062685, 5.644556355062685], time: 98.602
steps: 724975, episodes: 29000, mean episode reward: -1.49129301237741, agent episode reward: [-11.866538406775692, 5.187622697199142, 5.187622697199142], time: 99.21
steps: 749975, episodes: 30000, mean episode reward: -1.3343350073263747, agent episode reward: [-11.686068462553823, 5.175866727613725, 5.175866727613725], time: 100.564
steps: 774975, episodes: 31000, mean episode reward: -1.6422996592296382, agent episode reward: [-11.999380309080234, 5.178540324925297, 5.178540324925297], time: 99.453
steps: 799975, episodes: 32000, mean episode reward: -1.2642907612884768, agent episode reward: [-11.565857928839948, 5.150783583775736, 5.150783583775736], time: 100.293
steps: 824975, episodes: 33000, mean episode reward: -1.2062765505045998, agent episode reward: [-11.209909728627538, 5.001816589061469, 5.001816589061469], time: 99.297
steps: 849975, episodes: 34000, mean episode reward: -1.4367721345804676, agent episode reward: [-12.47376366682406, 5.518495766121797, 5.518495766121797], time: 99.267
steps: 874975, episodes: 35000, mean episode reward: -2.081361535136332, agent episode reward: [-11.549683690503375, 4.734161077683521, 4.734161077683521], time: 99.659
steps: 899975, episodes: 36000, mean episode reward: -1.9537149432593115, agent episode reward: [-11.882944165267624, 4.964614611004157, 4.964614611004157], time: 98.842
steps: 924975, episodes: 37000, mean episode reward: -1.672282400436796, agent episode reward: [-12.61484743540602, 5.471282517484611, 5.471282517484611], time: 98.936
steps: 949975, episodes: 38000, mean episode reward: -1.7593173127464308, agent episode reward: [-12.352007291771777, 5.296344989512673, 5.296344989512673], time: 100.121
steps: 974975, episodes: 39000, mean episode reward: -1.9091460377743203, agent episode reward: [-13.461330718599454, 5.776092340412567, 5.776092340412567], time: 99.189
steps: 999975, episodes: 40000, mean episode reward: -2.2096491869850015, agent episode reward: [-12.347350578973874, 5.068850695994436, 5.068850695994436], time: 99.946
steps: 1024975, episodes: 41000, mean episode reward: -2.1974999995205007, agent episode reward: [-13.227655145762578, 5.5150775731210375, 5.5150775731210375], time: 98.545
steps: 1049975, episodes: 42000, mean episode reward: -1.7881934258180237, agent episode reward: [-12.813766306474925, 5.512786440328451, 5.512786440328451], time: 99.326
steps: 1074975, episodes: 43000, mean episode reward: -1.6764424381646823, agent episode reward: [-12.699785990869525, 5.511671776352421, 5.511671776352421], time: 99.818
steps: 1099975, episodes: 44000, mean episode reward: -2.763215035341117, agent episode reward: [-13.069346119127497, 5.15306554189319, 5.15306554189319], time: 99.723
steps: 1124975, episodes: 45000, mean episode reward: -2.3406769281269764, agent episode reward: [-12.933118101550168, 5.296220586711596, 5.296220586711596], time: 100.384
steps: 1149975, episodes: 46000, mean episode reward: -2.5821193642331592, agent episode reward: [-13.17010436867252, 5.29399250221968, 5.29399250221968], time: 100.237
steps: 1174975, episodes: 47000, mean episode reward: -2.545342978719717, agent episode reward: [-12.916303759720497, 5.185480390500391, 5.185480390500391], time: 99.247
steps: 1199975, episodes: 48000, mean episode reward: -2.745053821779731, agent episode reward: [-13.471695646992416, 5.3633209126063415, 5.3633209126063415], time: 101.389
steps: 1224975, episodes: 49000, mean episode reward: -2.5240153432378256, agent episode reward: [-12.994986675613731, 5.235485666187953, 5.235485666187953], time: 99.651
steps: 1249975, episodes: 50000, mean episode reward: -2.419080380591722, agent episode reward: [-13.163303006003224, 5.372111312705751, 5.372111312705751], time: 98.974
steps: 1274975, episodes: 51000, mean episode reward: -2.2705919388032814, agent episode reward: [-12.79900619830489, 5.264207129750804, 5.264207129750804], time: 99.406
steps: 1299975, episodes: 52000, mean episode reward: -1.765065494902915, agent episode reward: [-13.193588367184141, 5.714261436140613, 5.714261436140613], time: 99.136
steps: 1324975, episodes: 53000, mean episode reward: -1.5749675784302477, agent episode reward: [-13.53088469485044, 5.977958558210096, 5.977958558210096], time: 99.655
steps: 1349975, episodes: 54000, mean episode reward: -0.9667629464148196, agent episode reward: [-14.109044327836116, 6.571140690710648, 6.571140690710648], time: 98.922
steps: 1374975, episodes: 55000, mean episode reward: -0.9873800055804668, agent episode reward: [-13.934038119177737, 6.473329056798635, 6.473329056798635], time: 100.316
steps: 1399975, episodes: 56000, mean episode reward: -1.2184768080367423, agent episode reward: [-13.428453999670358, 6.104988595816808, 6.104988595816808], time: 98.904
steps: 1424975, episodes: 57000, mean episode reward: -1.0380517857564386, agent episode reward: [-14.154372694165614, 6.558160454204588, 6.558160454204588], time: 100.39
steps: 1449975, episodes: 58000, mean episode reward: -0.2180461682491166, agent episode reward: [-14.591392093788588, 7.1866729627697366, 7.1866729627697366], time: 99.187
steps: 1474975, episodes: 59000, mean episode reward: -0.7288859008483893, agent episode reward: [-14.699522399783907, 6.98531824946776, 6.98531824946776], time: 100.359
steps: 1499975, episodes: 60000, mean episode reward: -0.6820294197629643, agent episode reward: [-14.581499254191291, 6.949734917214164, 6.949734917214164], time: 98.418
...Finished total of 60001 episodes.
