Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  0.5
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -22.522299298944002, agent episode reward: [-36.02214957829587, 6.74992513967593, 6.74992513967593], time: 66.517
steps: 49975, episodes: 2000, mean episode reward: -19.469045092748527, agent episode reward: [-31.291493990195363, 5.911224448723419, 5.911224448723419], time: 117.397
steps: 74975, episodes: 3000, mean episode reward: 1.827179622678816, agent episode reward: [-18.83493641093024, 10.33105801680453, 10.33105801680453], time: 136.017
steps: 99975, episodes: 4000, mean episode reward: 6.01532655482168, agent episode reward: [-16.917667347571424, 11.466496951196552, 11.466496951196552], time: 135.525
steps: 124975, episodes: 5000, mean episode reward: 6.6280152794221205, agent episode reward: [-14.614277856405868, 10.621146567913994, 10.621146567913994], time: 135.931
steps: 149975, episodes: 6000, mean episode reward: 3.807098935352049, agent episode reward: [-10.406496163177131, 7.10679754926459, 7.10679754926459], time: 136.737
steps: 174975, episodes: 7000, mean episode reward: 3.2135955902284814, agent episode reward: [-10.343334197602948, 6.778464893915716, 6.778464893915716], time: 135.731
steps: 199975, episodes: 8000, mean episode reward: 2.8918622728986514, agent episode reward: [-10.682992131002186, 6.787427201950419, 6.787427201950419], time: 135.118
steps: 224975, episodes: 9000, mean episode reward: 2.1939660677534936, agent episode reward: [-10.551425064981602, 6.372695566367547, 6.372695566367547], time: 136.137
steps: 249975, episodes: 10000, mean episode reward: 1.6671895160970853, agent episode reward: [-10.368945952812007, 6.018067734454546, 6.018067734454546], time: 134.738
steps: 274975, episodes: 11000, mean episode reward: 0.7712775269713767, agent episode reward: [-10.578350262022107, 5.674813894496741, 5.674813894496741], time: 135.307
steps: 299975, episodes: 12000, mean episode reward: 0.9793596572861321, agent episode reward: [-11.59204879472561, 6.285704226005871, 6.285704226005871], time: 136.22
steps: 324975, episodes: 13000, mean episode reward: 0.6798677158213797, agent episode reward: [-11.650880405436322, 6.16537406062885, 6.16537406062885], time: 134.975
steps: 349975, episodes: 14000, mean episode reward: 0.31920832502735813, agent episode reward: [-10.990949682405203, 5.65507900371628, 5.65507900371628], time: 135.482
steps: 374975, episodes: 15000, mean episode reward: 0.2184300320219401, agent episode reward: [-11.038587676198993, 5.628508854110467, 5.628508854110467], time: 136.501
steps: 399975, episodes: 16000, mean episode reward: 0.33566792982163945, agent episode reward: [-11.245798249088093, 5.790733089454867, 5.790733089454867], time: 136.173
steps: 424975, episodes: 17000, mean episode reward: 0.5009654340508035, agent episode reward: [-10.886421404416698, 5.693693419233751, 5.693693419233751], time: 135.492
steps: 449975, episodes: 18000, mean episode reward: 0.19696623084213594, agent episode reward: [-11.467034768894285, 5.832000499868211, 5.832000499868211], time: 136.292
steps: 474975, episodes: 19000, mean episode reward: 0.22765027689350528, agent episode reward: [-12.100466448334064, 6.164058362613785, 6.164058362613785], time: 136.99
steps: 499975, episodes: 20000, mean episode reward: 0.34262761527018587, agent episode reward: [-11.300324983972793, 5.821476299621489, 5.821476299621489], time: 135.714
steps: 524975, episodes: 21000, mean episode reward: 0.4172634019502932, agent episode reward: [-11.49836373222376, 5.957813567087027, 5.957813567087027], time: 136.402
steps: 549975, episodes: 22000, mean episode reward: 0.8155363598192161, agent episode reward: [-11.41038019686777, 6.112958278343495, 6.112958278343495], time: 135.963
steps: 574975, episodes: 23000, mean episode reward: 1.1466751738848953, agent episode reward: [-12.910269183615823, 7.028472178750358, 7.028472178750358], time: 136.347
steps: 599975, episodes: 24000, mean episode reward: 1.119275540118463, agent episode reward: [-12.159048213095913, 6.639161876607188, 6.639161876607188], time: 136.385
steps: 624975, episodes: 25000, mean episode reward: 0.5944479012230729, agent episode reward: [-12.16582368119401, 6.3801357912085415, 6.3801357912085415], time: 134.993
steps: 649975, episodes: 26000, mean episode reward: 0.6118363252274422, agent episode reward: [-12.268073010211552, 6.439954667719497, 6.439954667719497], time: 134.935
steps: 674975, episodes: 27000, mean episode reward: 1.6802589008985456, agent episode reward: [-11.989878809044201, 6.835068854971374, 6.835068854971374], time: 136.305
steps: 699975, episodes: 28000, mean episode reward: 0.19343148075384312, agent episode reward: [-11.352871961236827, 5.773151720995336, 5.773151720995336], time: 135.697
steps: 724975, episodes: 29000, mean episode reward: 0.3522216793815511, agent episode reward: [-12.442071385012298, 6.397146532196924, 6.397146532196924], time: 135.26
steps: 749975, episodes: 30000, mean episode reward: 0.21072667275193732, agent episode reward: [-11.96372385185456, 6.087225262303249, 6.087225262303249], time: 136.567
steps: 774975, episodes: 31000, mean episode reward: 0.5549052807349344, agent episode reward: [-12.44840731330849, 6.501656297021711, 6.501656297021711], time: 135.941
steps: 799975, episodes: 32000, mean episode reward: 0.6950988520388894, agent episode reward: [-12.482654593087773, 6.588876722563331, 6.588876722563331], time: 134.969
steps: 824975, episodes: 33000, mean episode reward: 0.08868046672682739, agent episode reward: [-12.039380922173427, 6.0640306944501265, 6.0640306944501265], time: 135.568
steps: 849975, episodes: 34000, mean episode reward: -0.40548447392919784, agent episode reward: [-11.723406706834819, 5.658961116452811, 5.658961116452811], time: 135.525
steps: 874975, episodes: 35000, mean episode reward: 0.33103010233744307, agent episode reward: [-12.800120638259024, 6.565575370298234, 6.565575370298234], time: 136.33
steps: 899975, episodes: 36000, mean episode reward: 0.3949929393870609, agent episode reward: [-12.965520376533787, 6.680256657960425, 6.680256657960425], time: 135.784
steps: 924975, episodes: 37000, mean episode reward: 0.09033218589181907, agent episode reward: [-12.333380320761448, 6.2118562533266335, 6.2118562533266335], time: 136.009
steps: 949975, episodes: 38000, mean episode reward: 0.6274675289845252, agent episode reward: [-13.056433753714934, 6.8419506413497295, 6.8419506413497295], time: 136.544
steps: 974975, episodes: 39000, mean episode reward: 0.5204806546849529, agent episode reward: [-12.645700213499957, 6.583090434092456, 6.583090434092456], time: 135.889
steps: 999975, episodes: 40000, mean episode reward: 0.19917361389638022, agent episode reward: [-12.227131595880156, 6.2131526048882675, 6.2131526048882675], time: 135.159
steps: 1024975, episodes: 41000, mean episode reward: 0.5391205101293124, agent episode reward: [-12.420375210911446, 6.47974786052038, 6.47974786052038], time: 135.688
steps: 1049975, episodes: 42000, mean episode reward: 0.7635426861587985, agent episode reward: [-12.91048308803893, 6.837012887098864, 6.837012887098864], time: 135.106
steps: 1074975, episodes: 43000, mean episode reward: 0.8892818623555919, agent episode reward: [-12.367547932025321, 6.628414897190458, 6.628414897190458], time: 135.191
steps: 1099975, episodes: 44000, mean episode reward: 0.22165545852847623, agent episode reward: [-12.859354518651159, 6.540504988589817, 6.540504988589817], time: 135.284
steps: 1124975, episodes: 45000, mean episode reward: 0.37253995618409796, agent episode reward: [-13.029490556011615, 6.701015256097857, 6.701015256097857], time: 136.426
steps: 1149975, episodes: 46000, mean episode reward: -0.4273744212688241, agent episode reward: [-13.019846198660423, 6.296235888695799, 6.296235888695799], time: 135.505
steps: 1174975, episodes: 47000, mean episode reward: -0.02168084338143242, agent episode reward: [-13.36314295896846, 6.670731057793513, 6.670731057793513], time: 136.205
steps: 1199975, episodes: 48000, mean episode reward: -0.3066587625034806, agent episode reward: [-13.82671280275189, 6.760027020124204, 6.760027020124204], time: 136.946
steps: 1224975, episodes: 49000, mean episode reward: -0.6284743285868185, agent episode reward: [-13.355025236055502, 6.3632754537343414, 6.3632754537343414], time: 135.625
steps: 1249975, episodes: 50000, mean episode reward: -0.2994577546112977, agent episode reward: [-13.637216448768777, 6.6688793470787395, 6.6688793470787395], time: 135.623
steps: 1274975, episodes: 51000, mean episode reward: -1.074702094757101, agent episode reward: [-14.245767671110938, 6.585532788176918, 6.585532788176918], time: 137.343
steps: 1299975, episodes: 52000, mean episode reward: -0.2328908698003068, agent episode reward: [-14.05807385870594, 6.9125914944528155, 6.9125914944528155], time: 136.913
steps: 1324975, episodes: 53000, mean episode reward: -1.2093006942785578, agent episode reward: [-14.449532583694499, 6.62011594470797, 6.62011594470797], time: 135.693
steps: 1349975, episodes: 54000, mean episode reward: -1.1809657584284314, agent episode reward: [-13.310452153648814, 6.064743197610191, 6.064743197610191], time: 135.234
steps: 1374975, episodes: 55000, mean episode reward: -1.5294475094585431, agent episode reward: [-14.34228929212812, 6.406420891334788, 6.406420891334788], time: 134.877
steps: 1399975, episodes: 56000, mean episode reward: -1.4899902160252363, agent episode reward: [-14.56104076952862, 6.535525276751693, 6.535525276751693], time: 135.246
steps: 1424975, episodes: 57000, mean episode reward: -0.37825974711137705, agent episode reward: [-14.106354279714377, 6.864047266301501, 6.864047266301501], time: 134.318
steps: 1449975, episodes: 58000, mean episode reward: 0.35549447296045267, agent episode reward: [-13.768912647433364, 7.06220356019691, 7.06220356019691], time: 135.355
steps: 1474975, episodes: 59000, mean episode reward: 0.5250159161741785, agent episode reward: [-14.6538479161728, 7.589431916173489, 7.589431916173489], time: 136.811
steps: 1499975, episodes: 60000, mean episode reward: 0.498883303410354, agent episode reward: [-14.520600962178305, 7.509742132794329, 7.509742132794329], time: 135.856
...Finished total of 60001 episodes.
