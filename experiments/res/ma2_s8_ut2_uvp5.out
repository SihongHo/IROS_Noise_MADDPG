Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  0.5
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -24.1250943945771, agent episode reward: [0.9603989331873637, 0.833899745419433, 0.9137182132789853, 0.8944251379921716, -15.542422880230808, -12.185113544224246], time: 203.754
steps: 49975, episodes: 2000, mean episode reward: -14.269842711040832, agent episode reward: [2.3943956017922723, 2.0828248162307137, 2.268003190461716, 2.058366968368905, -10.106247173054923, -12.967186114839514], time: 258.127
steps: 74975, episodes: 3000, mean episode reward: 12.708275009264893, agent episode reward: [4.4115905075243464, 4.124098496394167, 4.613376171910817, 4.555124842534315, -2.566938765409129, -2.4289762436896254], time: 278.637
steps: 99975, episodes: 4000, mean episode reward: 14.119088101676327, agent episode reward: [4.727299792720023, 4.067299976578694, 4.955423540450923, 5.185384823992648, -2.6404245860934843, -2.1758954459724777], time: 287.619
steps: 124975, episodes: 5000, mean episode reward: 15.040855995232318, agent episode reward: [5.009546364240441, 4.489564221610621, 5.327656812783256, 5.435004442837368, -2.77744986202042, -2.443465984218948], time: 294.166
steps: 149975, episodes: 6000, mean episode reward: 20.018286889234048, agent episode reward: [6.824366028091704, 6.246931182995228, 6.777355450631222, 6.748678291561217, -2.9928142427869453, -3.5862298212583776], time: 297.136
steps: 174975, episodes: 7000, mean episode reward: 19.281676191025102, agent episode reward: [6.495318738171976, 6.173571186743319, 6.5139489092329095, 6.518075080999329, -3.1397461234459003, -3.279491600676532], time: 297.297
steps: 199975, episodes: 8000, mean episode reward: 23.51356416922546, agent episode reward: [7.765807466853053, 7.6816493161299055, 7.824753510675944, 7.888006114648828, -3.7938448188515013, -3.8528074202307647], time: 293.796
steps: 224975, episodes: 9000, mean episode reward: 26.131042223700554, agent episode reward: [8.60738613254055, 8.507775401174012, 8.486046789618152, 8.574904129376424, -3.5915748470309388, -4.453495381977644], time: 296.605
steps: 249975, episodes: 10000, mean episode reward: 27.292463347131015, agent episode reward: [9.143272143985035, 8.897458429522874, 9.05257036035365, 9.042801361680816, -4.466311146538261, -4.3773278018731], time: 296.094
steps: 274975, episodes: 11000, mean episode reward: 23.898391165563467, agent episode reward: [8.359224509743939, 8.03907370843922, 8.168088843084535, 8.257830550098442, -5.802015042395036, -3.123811403407635], time: 296.493
steps: 299975, episodes: 12000, mean episode reward: 25.22356313448652, agent episode reward: [8.807396032207151, 8.477386941223903, 8.619408201847826, 8.726538974302214, -5.181376210000539, -4.225790805094035], time: 298.603
steps: 324975, episodes: 13000, mean episode reward: 21.805889323615094, agent episode reward: [7.806217289355081, 7.641159014512836, 7.673687220701385, 7.7478910080729415, -4.417993517975426, -4.645071691051724], time: 296.727
steps: 349975, episodes: 14000, mean episode reward: 22.81343085821283, agent episode reward: [8.667710868602638, 8.475808134851881, 8.490364267281407, 8.607029855063846, -5.2671825470412506, -6.160299720545691], time: 295.184
steps: 374975, episodes: 15000, mean episode reward: 20.73677621051072, agent episode reward: [7.795811220238689, 7.588777265009456, 7.602877740045587, 7.677306873565804, -5.257542091064368, -4.670454797284449], time: 297.501
steps: 399975, episodes: 16000, mean episode reward: 25.75039642643886, agent episode reward: [9.07938586097767, 8.823898294914546, 8.903755542399733, 8.993010587605859, -5.287260533664712, -4.7623933257942355], time: 296.37
steps: 424975, episodes: 17000, mean episode reward: 24.957233681207477, agent episode reward: [8.718912377338079, 8.462441428195051, 8.576633501729265, 8.642946150902942, -5.205501197609355, -4.238198579348507], time: 295.848
steps: 449975, episodes: 18000, mean episode reward: 24.485714209826444, agent episode reward: [8.380021774285854, 8.157379725419558, 8.280289961848124, 8.349241240044, -4.360848856408464, -4.320369635362627], time: 297.72
steps: 474975, episodes: 19000, mean episode reward: 23.55814579931218, agent episode reward: [8.135827909715891, 7.95667380059841, 8.018055612835203, 8.119730897081755, -4.368242275250516, -4.303900145668561], time: 299.271
steps: 499975, episodes: 20000, mean episode reward: 26.438270824587345, agent episode reward: [9.161694013406162, 8.905490644635313, 9.049664695923358, 9.170203700575014, -4.844503552965969, -5.0042786769865355], time: 295.507
steps: 524975, episodes: 21000, mean episode reward: 21.730743381848285, agent episode reward: [7.778870768366875, 7.586086278714169, 7.7139843509220425, 7.754902422171112, -4.747579977632709, -4.355520460693202], time: 296.659
steps: 549975, episodes: 22000, mean episode reward: 23.04094724029526, agent episode reward: [7.771207956641207, 7.596655402155975, 7.654312908915137, 7.658429156738444, -3.5559987934300157, -4.083659390725486], time: 296.708
steps: 574975, episodes: 23000, mean episode reward: 18.521363096883295, agent episode reward: [6.358792504621842, 6.229724905899154, 6.266746449262055, 6.2230766715546215, -3.2315636982190012, -3.325413736235377], time: 294.394
steps: 599975, episodes: 24000, mean episode reward: 18.813026978982386, agent episode reward: [6.62784877717649, 6.583734645200473, 6.581690188771578, 6.607123574438034, -3.3509097965591863, -4.236460410045003], time: 298.08
steps: 624975, episodes: 25000, mean episode reward: 17.2722366690321, agent episode reward: [6.249620834748036, 6.110350279294371, 6.158315350792211, 6.1119695120608215, -3.731745430361877, -3.6262738775014633], time: 297.461
steps: 649975, episodes: 26000, mean episode reward: 20.791259043294747, agent episode reward: [7.237885696202724, 7.169021653544825, 7.129487250164355, 7.146546698570467, -4.0640826752424495, -3.8275995799451756], time: 296.161
steps: 674975, episodes: 27000, mean episode reward: 21.43097696365747, agent episode reward: [7.479209577769414, 7.45694878813911, 7.407373174490217, 7.486477055448476, -3.7954626976468053, -4.603568934542942], time: 297.182
steps: 699975, episodes: 28000, mean episode reward: 21.650199063377215, agent episode reward: [7.313640565090602, 7.331714155827735, 7.391388950593689, 7.31972994627842, -3.9757930945682762, -3.7304814598449565], time: 292.377
steps: 724975, episodes: 29000, mean episode reward: 20.254523954095866, agent episode reward: [7.450577473866923, 7.499341743798625, 7.538509103324956, 7.510845415098787, -4.976026608175107, -4.76872317381832], time: 293.506
steps: 749975, episodes: 30000, mean episode reward: 20.866350788977645, agent episode reward: [7.146235353520961, 7.296399741692229, 7.293693359053244, 7.30976971871088, -4.424311506125996, -3.7554358778736736], time: 294.645
steps: 774975, episodes: 31000, mean episode reward: 18.239624212753107, agent episode reward: [6.433736084330383, 6.5590012196161025, 6.59503432873996, 6.6139897723961365, -4.439575994356061, -3.5225611979734115], time: 289.659
steps: 799975, episodes: 32000, mean episode reward: 20.49227844143856, agent episode reward: [7.590271057732989, 7.751875530029027, 7.7629606698326805, 7.815620820925527, -5.892794201618963, -4.535655435462699], time: 285.712
steps: 824975, episodes: 33000, mean episode reward: 19.713002099260713, agent episode reward: [6.977882632502417, 7.024209039080677, 7.109909336752506, 7.205097087205797, -5.576371224613693, -3.0277247716669886], time: 279.884
steps: 849975, episodes: 34000, mean episode reward: 16.879594453430684, agent episode reward: [6.214808477115103, 6.396364029465247, 6.459762684776817, 6.420176990543845, -5.661183710473134, -2.9503340179971955], time: 280.806
steps: 874975, episodes: 35000, mean episode reward: 24.31055924286801, agent episode reward: [8.282799630684236, 8.305064458884724, 8.420148233894325, 8.319740315772076, -5.584107498531357, -3.433085897835998], time: 279.648
steps: 899975, episodes: 36000, mean episode reward: 25.211683628540197, agent episode reward: [8.513361695942496, 8.614423011537735, 8.73396711427363, 8.59245113986537, -5.913745838500687, -3.3287734945783467], time: 279.689
steps: 924975, episodes: 37000, mean episode reward: 25.044451864543117, agent episode reward: [8.622796268077215, 8.559818501686118, 8.657591902435405, 8.558457715121788, -5.442218488697201, -3.9119940340802066], time: 282.842
steps: 949975, episodes: 38000, mean episode reward: 24.22365327034601, agent episode reward: [8.08361482238075, 8.005587631226858, 8.14937088893082, 7.996875491261243, -4.746262478014172, -3.265533085439486], time: 280.481
steps: 974975, episodes: 39000, mean episode reward: 28.167511654033866, agent episode reward: [9.698693590863208, 9.404645289945107, 9.592683963771798, 9.507800971569512, -5.2038764353289695, -4.832435726786787], time: 278.853
steps: 999975, episodes: 40000, mean episode reward: 25.773871657647664, agent episode reward: [9.008147586577318, 8.79094255985358, 8.954096078336542, 8.822231003723354, -5.440143424027267, -4.3614021468158635], time: 280.725
steps: 1024975, episodes: 41000, mean episode reward: 31.697607818958215, agent episode reward: [11.111390687286589, 10.845403740161684, 10.98326641880912, 10.871935457432755, -6.5453033142179535, -5.569085170513976], time: 280.345
steps: 1049975, episodes: 42000, mean episode reward: 36.14642195003613, agent episode reward: [12.429494958857381, 12.149415501307375, 12.3951965622504, 12.341558510368381, -7.866576050603167, -5.302667532144242], time: 279.674
steps: 1074975, episodes: 43000, mean episode reward: 30.93017619246406, agent episode reward: [10.701147368159022, 10.403491335355262, 10.605896932053867, 10.52211055313723, -6.799764108591031, -4.502705887650291], time: 281.096
steps: 1099975, episodes: 44000, mean episode reward: 32.58883490042187, agent episode reward: [11.272360089253871, 10.803864299159068, 11.191098815682171, 11.163393254052467, -7.289949077490948, -4.551932480234763], time: 280.652
steps: 1124975, episodes: 45000, mean episode reward: 30.76652731496489, agent episode reward: [10.611791451788834, 10.185245308772231, 10.540955419751645, 10.525456213505272, -7.673651473404451, -3.423269605448644], time: 280.525
steps: 1149975, episodes: 46000, mean episode reward: 36.66047285435116, agent episode reward: [12.618092335414174, 12.214182844904357, 12.704339564287483, 12.651264753332256, -9.94698388502542, -3.5804227585616952], time: 279.476
steps: 1174975, episodes: 47000, mean episode reward: 38.578199606830964, agent episode reward: [13.046786815626646, 12.842741977668163, 13.108179035150533, 13.109500465129702, -9.916899512493833, -3.6121091742502487], time: 277.482
steps: 1199975, episodes: 48000, mean episode reward: 36.536903407715066, agent episode reward: [12.505020403215807, 12.221342030974139, 12.564068215757837, 12.451929461434444, -9.673802615263932, -3.5316540884032346], time: 274.781
steps: 1224975, episodes: 49000, mean episode reward: 39.463182666848176, agent episode reward: [13.392126639175826, 13.171786753471391, 13.448825230533018, 13.3418752937611, -10.466921157883894, -3.4245100922092706], time: 277.163
steps: 1249975, episodes: 50000, mean episode reward: 36.71547011408247, agent episode reward: [12.734678247630724, 12.415788969321635, 12.794648600216531, 12.639626082972681, -9.602438439724374, -4.266833346334728], time: 277.154
steps: 1274975, episodes: 51000, mean episode reward: 34.89049005696909, agent episode reward: [12.103932589452, 11.629559745399128, 12.120587535179808, 12.027022994244144, -9.936474568039095, -3.054138239266891], time: 275.875
steps: 1299975, episodes: 52000, mean episode reward: 33.12657309512652, agent episode reward: [11.70930412425251, 11.467805688173415, 11.885126066995632, 11.732282951408251, -9.723002002831203, -3.9449437328720913], time: 276.04
steps: 1324975, episodes: 53000, mean episode reward: 31.900355887222727, agent episode reward: [11.04537674522891, 10.789081087608297, 11.142614446799222, 10.97094825424757, -8.508227120891119, -3.5394375257701514], time: 276.543
steps: 1349975, episodes: 54000, mean episode reward: 34.85250210778091, agent episode reward: [11.991418132137929, 11.676840032705229, 12.015956743896131, 11.873493766717015, -8.752108107224569, -3.953098460450824], time: 275.851
steps: 1374975, episodes: 55000, mean episode reward: 39.6887129895849, agent episode reward: [13.630072898662394, 13.42768275914028, 13.776577042802895, 13.662842662743955, -10.617059042076955, -4.19140333168767], time: 275.657
steps: 1399975, episodes: 56000, mean episode reward: 38.682044258780834, agent episode reward: [13.384639246667833, 13.389324872081863, 13.68496012933251, 13.537153493070127, -11.490700491031077, -3.8233329913404193], time: 278.087
steps: 1424975, episodes: 57000, mean episode reward: 39.968155499585144, agent episode reward: [13.469574027848338, 13.706472086435017, 13.949842700563359, 13.839969721148085, -11.554470813297405, -3.443232223112246], time: 273.606
steps: 1449975, episodes: 58000, mean episode reward: 38.39615556697993, agent episode reward: [13.100040052826916, 13.060023217696179, 13.426406348107578, 13.292811193285392, -10.853019757839963, -3.630105487096177], time: 278.516
steps: 1474975, episodes: 59000, mean episode reward: 41.18362731661711, agent episode reward: [13.584092721194112, 13.90857102607736, 14.045597525954523, 14.006804006320799, -11.208111253989541, -3.1533267089401344], time: 275.62
steps: 1499975, episodes: 60000, mean episode reward: 38.47870188791157, agent episode reward: [12.79023415207675, 13.137876539623132, 13.208510124819657, 13.163397868277189, -10.29296058373264, -3.5283562131525184], time: 269.894
...Finished total of 60001 episodes.
