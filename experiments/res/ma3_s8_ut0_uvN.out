Using good policy maddpg and adv policy maddpg
Uncertainty type is:  None ; Uncertainty level is:  1.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -36.18209837165433, agent episode reward: [0.6442190843039491, 0.6491301012802172, 0.5955294425362557, 0.620947406128923, -21.921219548158955, -16.77070485774472], time: 148.146
steps: 49975, episodes: 2000, mean episode reward: -3.6398806765205975, agent episode reward: [2.5952925044187385, 2.2694662231661487, 2.7913872292211237, 2.5290416850426127, -4.589351226692039, -9.235717091677184], time: 258.283
steps: 74975, episodes: 3000, mean episode reward: 17.363554286102975, agent episode reward: [5.400836038559402, 5.8510777668495875, 5.909115632224981, 5.728200417864924, -2.595692443478899, -2.929983125917016], time: 273.897
steps: 99975, episodes: 4000, mean episode reward: 21.125613423132826, agent episode reward: [6.4089860489937385, 6.946472537150876, 7.171475006373668, 7.392179506215415, -3.0634133808557173, -3.7300862947451567], time: 274.747
steps: 124975, episodes: 5000, mean episode reward: 19.765994878401646, agent episode reward: [6.203009743026581, 6.554782195655649, 6.621697005686085, 6.8697523712698265, -3.0673274865139484, -3.4159189507225474], time: 273.74
steps: 149975, episodes: 6000, mean episode reward: 21.414232089097226, agent episode reward: [7.070517712691345, 7.011352718063001, 7.205685277350974, 7.259339429505541, -3.9620615669453247, -3.1706014815683146], time: 275.566
steps: 174975, episodes: 7000, mean episode reward: 22.60187915562171, agent episode reward: [7.613859338893261, 7.396361742341627, 7.727408632000963, 7.461134344354346, -4.554835890756757, -3.042049011211727], time: 274.216
steps: 199975, episodes: 8000, mean episode reward: 25.46031366047848, agent episode reward: [8.47371445076081, 8.383694880716265, 8.553266852797217, 8.240877571357068, -4.965405516841238, -3.22583457831164], time: 274.646
steps: 224975, episodes: 9000, mean episode reward: 27.990586047872497, agent episode reward: [9.233810943034435, 9.267686906870873, 9.28289194114419, 9.04414471867205, -4.774787328076939, -4.063161133772112], time: 274.262
steps: 249975, episodes: 10000, mean episode reward: 25.623080339373214, agent episode reward: [8.563488694416566, 8.476028975861531, 8.466919693984893, 8.310462633671992, -4.7274356149615775, -3.466384043600193], time: 273.423
steps: 274975, episodes: 11000, mean episode reward: 19.654033102873104, agent episode reward: [6.885693774322348, 6.830414033859064, 6.794294986432686, 6.758214357292501, -3.6507054733418998, -3.963878575691596], time: 274.172
steps: 299975, episodes: 12000, mean episode reward: 19.68035122276335, agent episode reward: [6.964106324468499, 6.862418793639922, 6.929888425219697, 6.809489995301148, -3.258987240163868, -4.62656507570205], time: 273.514
steps: 324975, episodes: 13000, mean episode reward: 20.416204857994916, agent episode reward: [6.961201244768155, 6.827392915180252, 6.917320775556996, 6.784938387913062, -3.2944586808937535, -3.780189784529798], time: 273.561
steps: 349975, episodes: 14000, mean episode reward: 19.21885248117639, agent episode reward: [6.479133974898418, 6.413404459367955, 6.51099931190071, 6.332669378620869, -3.190799551159465, -3.3265550924520952], time: 273.991
steps: 374975, episodes: 15000, mean episode reward: 18.91737551556843, agent episode reward: [6.61437034260932, 6.580052822840005, 6.620300799570806, 6.321124305391772, -2.769663337657079, -4.448809417186397], time: 274.86
steps: 399975, episodes: 16000, mean episode reward: 19.42895678168412, agent episode reward: [6.850682166155762, 6.894545555797463, 6.929561861200218, 6.663391865216641, -3.0665019709746018, -4.842722695711365], time: 273.731
steps: 424975, episodes: 17000, mean episode reward: 16.84788791525134, agent episode reward: [6.030069355057387, 6.130779432480893, 6.091869976488557, 5.850274568864199, -3.0896703136260775, -4.165435104013618], time: 275.673
steps: 449975, episodes: 18000, mean episode reward: 17.06110120548823, agent episode reward: [6.045952535242519, 6.075681413258258, 6.049375385528934, 5.726815710725534, -2.87057121962148, -3.966152619645536], time: 274.299
steps: 474975, episodes: 19000, mean episode reward: 18.533043012223164, agent episode reward: [6.33672290230874, 6.496249898894477, 6.383782982506705, 6.097171802949657, -3.0590186874544005, -3.7218658869820134], time: 275.302
steps: 499975, episodes: 20000, mean episode reward: 18.818350536888808, agent episode reward: [6.323463444432146, 6.533816213315401, 6.530836046566682, 6.13405684764306, -3.297257893553939, -3.4065641215145415], time: 272.706
steps: 524975, episodes: 21000, mean episode reward: 21.204761335898954, agent episode reward: [7.08463966912384, 7.255408340425759, 7.271055293419231, 6.928137541362878, -2.830491144011643, -4.50398836442111], time: 274.387
steps: 549975, episodes: 22000, mean episode reward: 22.32429939372764, agent episode reward: [7.43094902561508, 7.551076876455065, 7.621745260761972, 7.269323986853953, -3.6637567102407105, -3.88503904571772], time: 272.186
steps: 574975, episodes: 23000, mean episode reward: 18.831684922455068, agent episode reward: [6.217761156549877, 6.331038030339347, 6.425469019620841, 6.141302475084429, -3.3434066274209844, -2.940479131718438], time: 274.072
steps: 599975, episodes: 24000, mean episode reward: 22.755521661909313, agent episode reward: [7.470366691434734, 7.474350083177049, 7.596937467307562, 7.345310070031171, -3.557716838020712, -3.573725812020489], time: 272.721
steps: 624975, episodes: 25000, mean episode reward: 22.293389959940423, agent episode reward: [7.383952701132031, 7.420724029270981, 7.4735724737941, 7.236280934053091, -3.7941775206350403, -3.4269626576747374], time: 274.221
steps: 649975, episodes: 26000, mean episode reward: 22.072811012300043, agent episode reward: [7.322379468784757, 7.410580162966155, 7.426925288461116, 7.177417251514637, -3.828204979647915, -3.4362861797787025], time: 272.709
steps: 674975, episodes: 27000, mean episode reward: 25.596189493936553, agent episode reward: [8.481448466458781, 8.620204029832875, 8.544573946716094, 8.325138603274645, -3.8371601217917632, -4.538015430554081], time: 273.813
steps: 699975, episodes: 28000, mean episode reward: 26.431190420913257, agent episode reward: [8.767562797898954, 8.99140741452924, 8.88690839808358, 8.643615777622148, -3.4642471490789215, -5.394056818141744], time: 273.559
steps: 724975, episodes: 29000, mean episode reward: 24.78543897444515, agent episode reward: [8.3338794388823, 8.535957902072678, 8.425617609497506, 8.188215008559451, -3.9089969436738627, -4.78923404089292], time: 271.932
steps: 749975, episodes: 30000, mean episode reward: 27.642542761747208, agent episode reward: [9.182307452963668, 9.308886161666901, 9.23258756339613, 8.988365707638389, -4.594473191843204, -4.4751309320746735], time: 269.864
steps: 774975, episodes: 31000, mean episode reward: 29.218322846298626, agent episode reward: [9.61790242097188, 9.771640998541363, 9.776265982456739, 9.383796370779685, -4.8048072948086595, -4.526475631642378], time: 268.112
steps: 799975, episodes: 32000, mean episode reward: 26.836530738644665, agent episode reward: [8.819140278204229, 9.00334687149079, 9.037073826665637, 8.689566008337403, -4.918113636473774, -3.7944826095796116], time: 267.551
steps: 824975, episodes: 33000, mean episode reward: 27.139107912742066, agent episode reward: [8.813013608016787, 9.128910189647723, 9.120453453276383, 8.775444265319628, -4.440749793257768, -4.257963810260689], time: 268.421
steps: 849975, episodes: 34000, mean episode reward: 27.406321771004652, agent episode reward: [9.067305052920318, 9.353743481784324, 9.275649778772147, 8.98680526657238, -4.746093535667244, -4.531088273377273], time: 266.966
steps: 874975, episodes: 35000, mean episode reward: 29.231893679617773, agent episode reward: [9.765197373423478, 10.064962173089116, 9.84656399238002, 9.661861551942865, -4.040994374173943, -6.065697037043763], time: 264.513
steps: 899975, episodes: 36000, mean episode reward: 30.186488731312718, agent episode reward: [9.977205278446256, 10.369640475254522, 10.096910434809846, 10.086609986222046, -4.2954994042936745, -6.048378039126273], time: 267.55
steps: 924975, episodes: 37000, mean episode reward: 30.888832897725624, agent episode reward: [10.316560196435624, 10.644648172638222, 10.333789511990394, 10.379548300138334, -3.795708639839582, -6.990004643637364], time: 264.24
steps: 949975, episodes: 38000, mean episode reward: 31.488010098595424, agent episode reward: [10.485760145012984, 10.796932530793269, 10.55452476795805, 10.644511419765088, -4.284644015010254, -6.709074749923717], time: 265.862
steps: 974975, episodes: 39000, mean episode reward: 29.32831511918102, agent episode reward: [9.83780816627263, 10.172729493036485, 9.841008083735066, 9.970682737575908, -4.114059211267681, -6.379854150171383], time: 265.395
steps: 999975, episodes: 40000, mean episode reward: 28.278860684003337, agent episode reward: [9.332921314558298, 9.776371608579186, 9.496748823305966, 9.624110515313046, -3.8194421405979946, -6.131849437155165], time: 265.504
steps: 1024975, episodes: 41000, mean episode reward: 36.69699733499448, agent episode reward: [12.209697266386662, 12.65220676409997, 12.455824059249876, 12.468048961728247, -4.0664512339342505, -9.022328482536027], time: 264.962
steps: 1049975, episodes: 42000, mean episode reward: 34.78309642365993, agent episode reward: [11.739982249030975, 12.18960344811893, 12.007165726867381, 12.070494208181499, -4.197503826144408, -9.026645382394458], time: 263.738
steps: 1074975, episodes: 43000, mean episode reward: 34.15797629947283, agent episode reward: [11.73303436714879, 12.158768796864825, 11.96147713249319, 11.968051911879119, -4.435942208104869, -9.227413700808222], time: 261.136
steps: 1099975, episodes: 44000, mean episode reward: 33.33775590169795, agent episode reward: [12.031755940252227, 12.366669054166898, 12.317902439031771, 12.297792498827818, -5.504185591441071, -10.172178439139689], time: 264.94
steps: 1124975, episodes: 45000, mean episode reward: 34.354120636730144, agent episode reward: [12.145916647681299, 12.412211142741642, 12.419391710234885, 12.442416126128563, -4.691807033738732, -10.374007956317516], time: 260.734
steps: 1149975, episodes: 46000, mean episode reward: 28.18330897431184, agent episode reward: [9.856844989836087, 9.930306951167653, 10.085143245871071, 10.049312590991017, -4.754009140730935, -6.984289662823052], time: 268.765
steps: 1174975, episodes: 47000, mean episode reward: 22.963514805809233, agent episode reward: [8.268371544820642, 8.36569998291098, 8.485883813730414, 8.443082973391691, -4.250015077644759, -6.349508431399738], time: 260.758
steps: 1199975, episodes: 48000, mean episode reward: 22.203450981865306, agent episode reward: [8.429839619574597, 8.388362050717559, 8.549827016428234, 8.494206983642151, -5.294369458011139, -6.3644152304861], time: 263.911
steps: 1224975, episodes: 49000, mean episode reward: 21.0877812226013, agent episode reward: [7.855531716234428, 7.848130724072896, 7.992454026886048, 7.880871881434307, -4.847013078912358, -5.642194047114017], time: 263.296
steps: 1249975, episodes: 50000, mean episode reward: 21.31872151487638, agent episode reward: [7.820509892350887, 7.755524041664585, 7.8978454471842054, 7.771984243295958, -4.634809324091873, -5.292332785527384], time: 261.586
steps: 1274975, episodes: 51000, mean episode reward: 22.35865192557406, agent episode reward: [8.009785844267206, 7.922309281080258, 8.075707523678169, 7.953796904404002, -4.5602730797107744, -5.042674548144806], time: 261.561
steps: 1299975, episodes: 52000, mean episode reward: 19.509796606221375, agent episode reward: [7.0749875844492625, 7.032957805197577, 7.148694314883047, 7.049037323467062, -3.8809718310381562, -4.914908590737415], time: 263.862
steps: 1324975, episodes: 53000, mean episode reward: 20.10057373753057, agent episode reward: [7.523409185077477, 7.425977621757832, 7.571986190979076, 7.428194258507441, -4.196125388776905, -5.652868130014355], time: 262.002
steps: 1349975, episodes: 54000, mean episode reward: 21.472751566263533, agent episode reward: [8.066502936351323, 8.061543380937207, 8.111526971415625, 8.020279517556261, -5.043175909080547, -5.7439253309163405], time: 264.832
steps: 1374975, episodes: 55000, mean episode reward: 18.9698056077204, agent episode reward: [7.079055343508555, 6.974425746753556, 7.050281875398268, 6.9546542250846235, -4.398157344427723, -4.6904542385968835], time: 263.734
steps: 1399975, episodes: 56000, mean episode reward: 20.394513436369685, agent episode reward: [7.382069606949526, 7.310612773593304, 7.313265759546424, 7.286265940467004, -4.263532806970683, -4.634167837215889], time: 265.434
steps: 1424975, episodes: 57000, mean episode reward: 17.83663720628396, agent episode reward: [6.65567094190171, 6.637601668929347, 6.660877783647027, 6.5458237363607505, -3.888544051355109, -4.774792873199764], time: 265.778
steps: 1449975, episodes: 58000, mean episode reward: 18.945189817227412, agent episode reward: [7.038699192604008, 6.965019419250119, 7.072485764711452, 6.939217823739109, -4.544606437238919, -4.525625945838358], time: 264.653
steps: 1474975, episodes: 59000, mean episode reward: 16.65843485245294, agent episode reward: [6.212581300845226, 6.117365408087547, 6.256860396191896, 6.219724174292751, -3.7360312080447975, -4.412065218919684], time: 261.798
steps: 1499975, episodes: 60000, mean episode reward: 20.178431370927587, agent episode reward: [7.358449970336289, 7.311950775003832, 7.415593947958532, 7.338455352145911, -4.460779994570561, -4.785238679946413], time: 243.975
...Finished total of 60001 episodes.
