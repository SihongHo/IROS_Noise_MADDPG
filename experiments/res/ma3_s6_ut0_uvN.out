Using good policy maddpg and adv policy maddpg
Uncertainty type is:  None ; Uncertainty level is:  1.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -25.032693242895462, agent episode reward: [-24.165705177278312, -0.4334940328085719, -0.4334940328085719], time: 47.801
steps: 49975, episodes: 2000, mean episode reward: -11.704118621105062, agent episode reward: [-10.514874494343676, -0.5946220633806937, -0.5946220633806937], time: 102.084
steps: 74975, episodes: 3000, mean episode reward: -5.729569184704149, agent episode reward: [-13.622751014140936, 3.946590914718393, 3.946590914718393], time: 127.863
steps: 99975, episodes: 4000, mean episode reward: 10.124191784902443, agent episode reward: [-21.008188866822685, 15.566190325862564, 15.566190325862564], time: 127.387
steps: 124975, episodes: 5000, mean episode reward: 15.703977778093183, agent episode reward: [-18.515533717286168, 17.109755747689675, 17.109755747689675], time: 128.025
steps: 149975, episodes: 6000, mean episode reward: 14.897224053010891, agent episode reward: [-17.144912928782393, 16.021068490896642, 16.021068490896642], time: 127.917
steps: 174975, episodes: 7000, mean episode reward: 14.807780438162283, agent episode reward: [-16.88198728624391, 15.844883862203092, 15.844883862203092], time: 128.157
steps: 199975, episodes: 8000, mean episode reward: 17.340115555095533, agent episode reward: [-21.438504783998567, 19.389310169547052, 19.389310169547052], time: 127.248
steps: 224975, episodes: 9000, mean episode reward: 15.881286226679785, agent episode reward: [-18.948251252293044, 17.414768739486416, 17.414768739486416], time: 127.416
steps: 249975, episodes: 10000, mean episode reward: 15.1295788425005, agent episode reward: [-16.787372005870445, 15.958475424185474, 15.958475424185474], time: 127.299
steps: 274975, episodes: 11000, mean episode reward: 14.749035199976815, agent episode reward: [-16.286665078991422, 15.51785013948412, 15.51785013948412], time: 127.944
steps: 299975, episodes: 12000, mean episode reward: 15.925210738157558, agent episode reward: [-17.41618450341629, 16.670697620786928, 16.670697620786928], time: 127.386
steps: 324975, episodes: 13000, mean episode reward: 11.40368036649194, agent episode reward: [-19.28898789275587, 15.346334129623907, 15.346334129623907], time: 126.872
steps: 349975, episodes: 14000, mean episode reward: 13.962849155856683, agent episode reward: [-18.988157334592852, 16.475503245224765, 16.475503245224765], time: 127.339
steps: 374975, episodes: 15000, mean episode reward: 14.035625506481175, agent episode reward: [-16.058024838509414, 15.046825172495293, 15.046825172495293], time: 127.401
steps: 399975, episodes: 16000, mean episode reward: 15.631087726811803, agent episode reward: [-17.246812483930285, 16.438950105371045, 16.438950105371045], time: 127.421
steps: 424975, episodes: 17000, mean episode reward: 15.395632430764973, agent episode reward: [-17.276074216575385, 16.33585332367018, 16.33585332367018], time: 127.762
steps: 449975, episodes: 18000, mean episode reward: 15.412729734239365, agent episode reward: [-17.160226915352737, 16.286478324796054, 16.286478324796054], time: 127.11
steps: 474975, episodes: 19000, mean episode reward: 15.490809812034048, agent episode reward: [-17.560534987504607, 16.525672399769327, 16.525672399769327], time: 127.023
steps: 499975, episodes: 20000, mean episode reward: 15.43418261668833, agent episode reward: [-17.950302204908244, 16.692242410798286, 16.692242410798286], time: 128.187
steps: 524975, episodes: 21000, mean episode reward: 14.963011602465743, agent episode reward: [-17.048260229787182, 16.00563591612646, 16.00563591612646], time: 127.222
steps: 549975, episodes: 22000, mean episode reward: 15.415009491609187, agent episode reward: [-17.073038683322018, 16.244024087465604, 16.244024087465604], time: 127.43
steps: 574975, episodes: 23000, mean episode reward: 15.191947306252889, agent episode reward: [-17.092658540941645, 16.142302923597267, 16.142302923597267], time: 127.472
steps: 599975, episodes: 24000, mean episode reward: 15.188485460818262, agent episode reward: [-16.850817370585716, 16.01965141570199, 16.01965141570199], time: 127.792
steps: 624975, episodes: 25000, mean episode reward: 15.173096108272023, agent episode reward: [-16.712645097741508, 15.942870603006766, 15.942870603006766], time: 127.747
steps: 649975, episodes: 26000, mean episode reward: 15.369185249261733, agent episode reward: [-16.89972504213804, 16.13445514569989, 16.13445514569989], time: 127.898
steps: 674975, episodes: 27000, mean episode reward: 15.1288380218708, agent episode reward: [-16.674881296935993, 15.901859659403396, 15.901859659403396], time: 127.279
steps: 699975, episodes: 28000, mean episode reward: 15.278657154608537, agent episode reward: [-16.736406034227667, 16.0075315944181, 16.0075315944181], time: 127.273
steps: 724975, episodes: 29000, mean episode reward: 15.125168222278337, agent episode reward: [-16.63405058272226, 15.879609402500297, 15.879609402500297], time: 127.639
steps: 749975, episodes: 30000, mean episode reward: 15.148387745097224, agent episode reward: [-16.726357570975065, 15.937372658036146, 15.937372658036146], time: 127.229
steps: 774975, episodes: 31000, mean episode reward: 15.167791273243143, agent episode reward: [-16.661469891453518, 15.91463058234833, 15.91463058234833], time: 127.127
steps: 799975, episodes: 32000, mean episode reward: 16.83090520823442, agent episode reward: [-18.340795288605293, 17.58585024841986, 17.58585024841986], time: 127.556
steps: 824975, episodes: 33000, mean episode reward: 17.125338106733377, agent episode reward: [-18.85967878525435, 17.992508445993863, 17.992508445993863], time: 127.554
steps: 849975, episodes: 34000, mean episode reward: 14.759267896373098, agent episode reward: [-16.832384962264783, 15.79582642931894, 15.79582642931894], time: 128.096
steps: 874975, episodes: 35000, mean episode reward: 14.722764737437286, agent episode reward: [-16.513034106848178, 15.617899422142735, 15.617899422142735], time: 127.745
steps: 899975, episodes: 36000, mean episode reward: 16.16794653648402, agent episode reward: [-17.568248214776183, 16.868097375630104, 16.868097375630104], time: 127.588
steps: 924975, episodes: 37000, mean episode reward: 14.626921156973278, agent episode reward: [-16.194717649579644, 15.410819403276463, 15.410819403276463], time: 127.493
steps: 949975, episodes: 38000, mean episode reward: 15.056238759678115, agent episode reward: [-17.018561292285554, 16.037400025981835, 16.037400025981835], time: 127.653
steps: 974975, episodes: 39000, mean episode reward: 15.325678986630663, agent episode reward: [-17.202300752470038, 16.26398986955035, 16.26398986955035], time: 127.448
steps: 999975, episodes: 40000, mean episode reward: 14.369216611507712, agent episode reward: [-16.282184697824388, 15.32570065466605, 15.32570065466605], time: 127.377
steps: 1024975, episodes: 41000, mean episode reward: 14.210042606329832, agent episode reward: [-16.30771190914932, 15.258877257739575, 15.258877257739575], time: 127.413
steps: 1049975, episodes: 42000, mean episode reward: 16.178159525908853, agent episode reward: [-17.54013137435914, 16.859145450133997, 16.859145450133997], time: 127.382
steps: 1074975, episodes: 43000, mean episode reward: 17.198724926527227, agent episode reward: [-18.592178660629536, 17.89545179357838, 17.89545179357838], time: 127.01
steps: 1099975, episodes: 44000, mean episode reward: 17.483194657278005, agent episode reward: [-18.83273842206833, 18.157966539673172, 18.157966539673172], time: 128.057
steps: 1124975, episodes: 45000, mean episode reward: 16.3814910170284, agent episode reward: [-17.888018997082433, 17.134755007055414, 17.134755007055414], time: 128.332
steps: 1149975, episodes: 46000, mean episode reward: 15.756653885612257, agent episode reward: [-17.205221764693427, 16.48093782515284, 16.48093782515284], time: 127.42
steps: 1174975, episodes: 47000, mean episode reward: 15.120438986560721, agent episode reward: [-16.638677767490183, 15.879558377025452, 15.879558377025452], time: 127.93
steps: 1199975, episodes: 48000, mean episode reward: 15.249136146839307, agent episode reward: [-16.72776025537698, 15.988448201108145, 15.988448201108145], time: 127.603
steps: 1224975, episodes: 49000, mean episode reward: 16.124512949255895, agent episode reward: [-17.62346717735789, 16.87399006330689, 16.87399006330689], time: 127.363
steps: 1249975, episodes: 50000, mean episode reward: 14.68315467269954, agent episode reward: [-16.115373492345274, 15.399264082522407, 15.399264082522407], time: 127.462
steps: 1274975, episodes: 51000, mean episode reward: 15.323556123239406, agent episode reward: [-16.812643866735538, 16.06809999498747, 16.06809999498747], time: 128.109
steps: 1299975, episodes: 52000, mean episode reward: 15.920648764542916, agent episode reward: [-17.397987114607407, 16.65931793957516, 16.65931793957516], time: 127.817
steps: 1324975, episodes: 53000, mean episode reward: 16.160954856040576, agent episode reward: [-17.575370892847246, 16.86816287444391, 16.86816287444391], time: 127.437
steps: 1349975, episodes: 54000, mean episode reward: 16.332150040890408, agent episode reward: [-17.75199737310834, 17.042073706999375, 17.042073706999375], time: 128.193
steps: 1374975, episodes: 55000, mean episode reward: 16.269097413735278, agent episode reward: [-17.743398269852065, 17.006247841793673, 17.006247841793673], time: 127.689
steps: 1399975, episodes: 56000, mean episode reward: 16.16331226463364, agent episode reward: [-17.606631696101626, 16.88497198036763, 16.88497198036763], time: 126.86
steps: 1424975, episodes: 57000, mean episode reward: 14.290303030666813, agent episode reward: [-15.99808542918786, 15.144194229927338, 15.144194229927338], time: 128.344
steps: 1449975, episodes: 58000, mean episode reward: 16.05121749083533, agent episode reward: [-17.635299236151784, 16.843258363493554, 16.843258363493554], time: 127.744
steps: 1474975, episodes: 59000, mean episode reward: 16.04545161205187, agent episode reward: [-17.717905853375804, 16.881678732713837, 16.881678732713837], time: 127.995
steps: 1499975, episodes: 60000, mean episode reward: 15.287550003269, agent episode reward: [-16.812689658525343, 16.05011983089717, 16.05011983089717], time: 118.567
...Finished total of 60001 episodes.
