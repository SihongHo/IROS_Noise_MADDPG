Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  1.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -29.83720587906168, agent episode reward: [1.1766625146576273, 1.2008255472900151, 1.148569530197387, 1.1511477875608715, -18.212114743296638, -16.302296515470942], time: 183.31
steps: 49975, episodes: 2000, mean episode reward: -10.033536311045705, agent episode reward: [2.6945195796057804, 2.897025684301504, 3.1291243005782072, 2.736320034309104, -7.00502616277589, -14.485499747064413], time: 250.006
steps: 74975, episodes: 3000, mean episode reward: 11.631360974314212, agent episode reward: [3.9374585136395006, 4.35534380868589, 4.503300101135068, 4.39143973186222, -2.914525352678672, -2.641655828329796], time: 253.266
steps: 99975, episodes: 4000, mean episode reward: 14.561392834111793, agent episode reward: [4.318897195224841, 5.0768325052287455, 4.7513136090111034, 4.748935500191774, -2.0634594303778533, -2.2711265451668154], time: 256.262
steps: 124975, episodes: 5000, mean episode reward: 14.837177541201982, agent episode reward: [4.538983302635085, 5.292565396177748, 4.835071870003292, 5.052620274513254, -1.7219939662378583, -3.160069335889537], time: 256.597
steps: 149975, episodes: 6000, mean episode reward: 22.42264165979426, agent episode reward: [7.294371149913088, 7.555787032104317, 7.115187734901514, 7.425561851398705, -2.9299468627745378, -4.038319245748828], time: 255.244
steps: 174975, episodes: 7000, mean episode reward: 24.812592193084296, agent episode reward: [8.12098677892288, 8.34814626934169, 7.896089455434984, 8.145170549268203, -3.5730595778491994, -4.124741282034259], time: 250.96
steps: 199975, episodes: 8000, mean episode reward: 28.15331386242172, agent episode reward: [9.352332310007721, 9.493997054342541, 8.948294138205943, 9.301818701131914, -4.256084274148474, -4.687044067117931], time: 256.537
steps: 224975, episodes: 9000, mean episode reward: 33.19569997618617, agent episode reward: [11.006623488062681, 11.247203960623862, 10.75056998639808, 11.022479663388554, -4.902748901819188, -5.9284282204678185], time: 256.905
steps: 249975, episodes: 10000, mean episode reward: 39.514617893978404, agent episode reward: [12.909179029720194, 13.135396030256898, 12.647226712496455, 12.979185505103404, -5.423666841757123, -6.732702541841421], time: 248.39
steps: 274975, episodes: 11000, mean episode reward: 39.701253999571676, agent episode reward: [13.052562288203353, 13.258835952028312, 12.801803235184416, 13.080191253117166, -6.0215279688753744, -6.470610760086192], time: 253.374
steps: 299975, episodes: 12000, mean episode reward: 37.19674304008644, agent episode reward: [12.252899273716228, 12.248785010415617, 11.97188701659569, 12.190333880192027, -6.215032349653624, -5.2521297911794935], time: 256.181
steps: 324975, episodes: 13000, mean episode reward: 42.5146969878284, agent episode reward: [14.015193369932444, 14.117107427924166, 13.905591223027205, 13.964090526580122, -6.975706439923236, -6.511579119712298], time: 254.994
steps: 349975, episodes: 14000, mean episode reward: 43.09794216996735, agent episode reward: [14.23526878606906, 14.222055939846486, 13.94929987646777, 14.071666450757697, -6.228689622864303, -7.151659260309361], time: 255.867
steps: 374975, episodes: 15000, mean episode reward: 36.13849398452131, agent episode reward: [11.974277963342134, 11.979421602435501, 11.84319062622078, 11.787201157720872, -5.905471223501531, -5.540126141696441], time: 256.292
steps: 399975, episodes: 16000, mean episode reward: 35.23779996044727, agent episode reward: [11.78395850451233, 11.71335448611201, 11.761190013235257, 11.59872364308692, -6.5694898707344, -5.049936815764843], time: 254.976
steps: 424975, episodes: 17000, mean episode reward: 26.63974343114585, agent episode reward: [8.99840083562825, 8.923371307354788, 8.99650824197615, 8.879272515708186, -4.627911076192124, -4.5298983933294], time: 256.139
steps: 449975, episodes: 18000, mean episode reward: 26.228286248974328, agent episode reward: [8.87030717968203, 8.83832983104409, 8.801515010639672, 8.751725125270815, -4.028186987219804, -5.00540391044247], time: 257.6
steps: 474975, episodes: 19000, mean episode reward: 22.47026832043108, agent episode reward: [7.99460647127796, 7.9308535733833665, 7.912262182512086, 7.861700690348023, -4.385239014683602, -4.843915582406751], time: 260.572
steps: 499975, episodes: 20000, mean episode reward: 26.359306140625886, agent episode reward: [9.199440395016325, 9.212492000446076, 9.08953999066367, 9.170788664360632, -4.558044395782495, -5.754910514078324], time: 257.617
steps: 524975, episodes: 21000, mean episode reward: 26.63805842024533, agent episode reward: [9.400377288798369, 9.392471075091994, 9.270251413195444, 9.362861986355538, -4.257322078560712, -6.530581264635303], time: 259.868
steps: 549975, episodes: 22000, mean episode reward: 22.061962066390976, agent episode reward: [8.050560783055909, 8.031113039588465, 8.00004388320413, 7.995790851586718, -4.423527907948732, -5.592018583095513], time: 259.118
steps: 574975, episodes: 23000, mean episode reward: 20.96203881256068, agent episode reward: [8.100938973504622, 8.020220702863503, 7.9803073235921875, 7.940721371987504, -4.982427226107582, -6.097722333279555], time: 255.267
steps: 599975, episodes: 24000, mean episode reward: 20.324474920830536, agent episode reward: [7.825321349938737, 7.731837741275886, 7.76063590445595, 7.734445021294547, -4.802641704349548, -5.925123391785035], time: 257.755
steps: 624975, episodes: 25000, mean episode reward: 21.10597536672652, agent episode reward: [7.725508652129467, 7.66686542193531, 7.579224385430808, 7.604839344630646, -3.5818956447828696, -5.888566792616844], time: 254.734
steps: 649975, episodes: 26000, mean episode reward: 15.618178900033941, agent episode reward: [6.745833611337779, 6.733094045294977, 6.608121093947329, 6.692508328302266, -5.612646191626293, -5.548731987222115], time: 258.262
steps: 674975, episodes: 27000, mean episode reward: 20.511697262088568, agent episode reward: [7.977587176649125, 7.949648464183419, 7.792269307295694, 7.970510166553557, -5.786298914732166, -5.392018937861062], time: 249.627
steps: 699975, episodes: 28000, mean episode reward: 16.94159585851127, agent episode reward: [7.493193925179872, 7.457245168639418, 7.3392313430582075, 7.437568090030692, -7.01350478573173, -5.772137882665189], time: 253.993
steps: 724975, episodes: 29000, mean episode reward: 16.195714762671034, agent episode reward: [7.060997306047975, 7.018368812899062, 6.919689166468696, 6.92991471476063, -5.00578628312734, -6.7274689543779855], time: 246.658
steps: 749975, episodes: 30000, mean episode reward: 14.682495635503681, agent episode reward: [5.8520533426972765, 5.914923861153656, 5.791398903796835, 5.889866587363778, -4.592027041260319, -4.173720018247542], time: 254.381
steps: 774975, episodes: 31000, mean episode reward: 24.275759871377712, agent episode reward: [8.213655993281924, 8.268368632855509, 8.228616898573941, 8.2668211740124, -3.809763688074909, -4.891939139271153], time: 249.458
steps: 799975, episodes: 32000, mean episode reward: 22.584716495137908, agent episode reward: [7.664718143007393, 7.738781010692686, 7.661974580856501, 7.669171075475135, -2.9851597853483307, -5.164768529545474], time: 254.93
steps: 824975, episodes: 33000, mean episode reward: 22.535957707234914, agent episode reward: [7.647087456886789, 7.748578128744107, 7.709773182368135, 7.638410793370378, -3.980299454915018, -4.2275923992194775], time: 251.395
steps: 849975, episodes: 34000, mean episode reward: 20.365941481094907, agent episode reward: [7.331401901765779, 7.370842812270612, 7.317098909660685, 7.3737067253799635, -3.0815872431675317, -5.9455216248146066], time: 255.711
steps: 874975, episodes: 35000, mean episode reward: 24.05850461398045, agent episode reward: [8.358781575284624, 8.31718430632361, 8.284951353213373, 8.276171379185634, -3.787962313890047, -5.3906216861367415], time: 259.042
steps: 899975, episodes: 36000, mean episode reward: 21.472914063764794, agent episode reward: [7.413747464541437, 7.43340676697673, 7.366587297384749, 7.338237702431695, -3.89971635807402, -4.179348809495798], time: 254.755
steps: 924975, episodes: 37000, mean episode reward: 22.844170893157628, agent episode reward: [8.310610534125304, 8.307405333576964, 8.204247773960324, 8.310878086122997, -5.293611317267534, -4.995359517360427], time: 259.402
steps: 949975, episodes: 38000, mean episode reward: 21.807171584684752, agent episode reward: [7.913686786950994, 7.853898475298856, 7.725212273889156, 7.761207287687283, -4.18033608730436, -5.266497151837176], time: 248.325
steps: 974975, episodes: 39000, mean episode reward: 23.805011588561328, agent episode reward: [8.618102509098753, 8.591911906833019, 8.514981387897182, 8.534651653427945, -4.269983510006989, -6.184652358688584], time: 254.725
steps: 999975, episodes: 40000, mean episode reward: 23.777362649330698, agent episode reward: [8.366376922903761, 8.40534465528369, 8.3699689474888, 8.321559421932644, -3.730903217440864, -5.954984080837334], time: 257.774
steps: 1024975, episodes: 41000, mean episode reward: 24.25359755004896, agent episode reward: [8.4549104234221, 8.564197048747902, 8.48194836233249, 8.437135525916945, -3.271464189212299, -6.413129621158181], time: 250.387
steps: 1049975, episodes: 42000, mean episode reward: 22.66480041022123, agent episode reward: [8.25204970888331, 8.488661828422934, 8.301216909913544, 8.25040343119412, -4.178427953742267, -6.449103514450415], time: 257.651
steps: 1074975, episodes: 43000, mean episode reward: 19.436457557980017, agent episode reward: [7.3656437148124745, 7.526177632498242, 7.3997864977736265, 7.40305307004124, -3.897274021835682, -6.360929335309883], time: 261.055
steps: 1099975, episodes: 44000, mean episode reward: 18.4990209010518, agent episode reward: [7.334108930497523, 7.598545136905796, 7.431817272136944, 7.377280503214958, -4.209374731484539, -7.033356210218881], time: 255.593
steps: 1124975, episodes: 45000, mean episode reward: 22.141434967144132, agent episode reward: [8.291114514131461, 8.502256127323603, 8.33362426807261, 8.349627299245064, -3.8936925022513615, -7.441494739377241], time: 258.747
steps: 1149975, episodes: 46000, mean episode reward: 22.44917384173799, agent episode reward: [8.106600957018516, 8.322368028796197, 8.15358148051228, 8.114119658505595, -3.4655536469529276, -6.781942636141665], time: 257.082
steps: 1174975, episodes: 47000, mean episode reward: 28.867023114291733, agent episode reward: [9.641360898723976, 10.01413608419134, 9.864610529313866, 9.823865171914075, -4.048739421933231, -6.428210147918291], time: 260.706
steps: 1199975, episodes: 48000, mean episode reward: 28.649875518890738, agent episode reward: [9.84360930523934, 10.17712881273151, 10.000384606657143, 9.990356556263944, -3.8221282563940737, -7.539475505607125], time: 250.44
steps: 1224975, episodes: 49000, mean episode reward: 28.283745631560546, agent episode reward: [9.74339237610932, 10.003097826542259, 9.81110622252131, 9.875457091525265, -4.18738945266959, -6.961918432468018], time: 249.959
steps: 1249975, episodes: 50000, mean episode reward: 25.485489429779633, agent episode reward: [9.005630900020849, 9.355442062103368, 9.199692060192708, 9.144369303337186, -3.7601964278260565, -7.459448468048422], time: 252.946
steps: 1274975, episodes: 51000, mean episode reward: 29.259990583638785, agent episode reward: [10.10792358445673, 10.32742333736668, 10.254598672194962, 10.14596928333997, -4.368493948060108, -7.207430345659452], time: 251.132
steps: 1299975, episodes: 52000, mean episode reward: 31.00735856193252, agent episode reward: [10.781173067874928, 11.17433595933618, 10.999506390667179, 10.86306499356559, -3.82040396899616, -8.990317880515196], time: 255.441
steps: 1324975, episodes: 53000, mean episode reward: 36.25042116799888, agent episode reward: [12.482656384581885, 12.916628306602913, 12.61156615882814, 12.39106954001333, -3.4950066197659244, -10.656492602261457], time: 252.173
steps: 1349975, episodes: 54000, mean episode reward: 35.96647170235671, agent episode reward: [12.046380873551087, 12.38272755181107, 12.104851689098421, 11.979503335833162, -3.558034923544371, -8.988956824392655], time: 255.428
steps: 1374975, episodes: 55000, mean episode reward: 38.49280384109599, agent episode reward: [12.959701349391336, 13.24461119745997, 13.027690031294574, 12.788223876448003, -3.614630861676741, -9.912791751821151], time: 256.777
steps: 1399975, episodes: 56000, mean episode reward: 38.940617111233834, agent episode reward: [12.939055348831824, 13.2899923679681, 12.988288490708888, 12.767842159674476, -3.1062934133255995, -9.938267842623853], time: 251.408
steps: 1424975, episodes: 57000, mean episode reward: 38.965570207297134, agent episode reward: [13.20223865078633, 13.519027684868645, 13.097888556056615, 12.78503633844741, -3.3326773974186716, -10.30594362544319], time: 256.269
steps: 1449975, episodes: 58000, mean episode reward: 42.264643377366426, agent episode reward: [14.511890370665917, 14.825615868508992, 14.409521507241735, 14.166124627358395, -3.164336747408043, -12.484172249000567], time: 261.999
steps: 1474975, episodes: 59000, mean episode reward: 39.093515022410806, agent episode reward: [13.838938974764224, 14.106190926162766, 13.721059639166254, 13.442138245004069, -3.2072211665370025, -12.807591596149505], time: 255.183
steps: 1499975, episodes: 60000, mean episode reward: 37.02172153723726, agent episode reward: [12.702460649324188, 13.008460193093013, 12.629976884834399, 12.270637975961245, -3.1549397213625223, -10.434874444613069], time: 252.702
...Finished total of 60001 episodes.
