Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  2.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -23.59859694465227, agent episode reward: [1.0429852190936295, 0.9956505657357361, 0.927682688609077, 1.0246606501574687, -19.093708585365704, -8.49586748288248], time: 186.712
steps: 49975, episodes: 2000, mean episode reward: -32.516207628740226, agent episode reward: [2.3045388646590563, 2.741474919906018, 2.411476970429057, 2.668685918961337, -9.453693489408973, -33.188690813286726], time: 257.22
steps: 74975, episodes: 3000, mean episode reward: 9.437848121457591, agent episode reward: [3.996539148796287, 4.1961739588491325, 3.6613094794053533, 4.019469932063772, -3.539251162550181, -2.8963932351067734], time: 261.181
steps: 99975, episodes: 4000, mean episode reward: 15.922625303556872, agent episode reward: [5.803386897838997, 5.343458036390102, 5.376888154712716, 5.584632154154517, -2.8551683847915608, -3.3305715547478956], time: 253.539
steps: 124975, episodes: 5000, mean episode reward: 18.04464258897641, agent episode reward: [6.142756555475644, 6.015523645231106, 5.876196938025192, 6.225946351620145, -2.5519979463690716, -3.663782955006607], time: 250.68
steps: 149975, episodes: 6000, mean episode reward: 22.476084861102947, agent episode reward: [7.518391639235633, 7.196125765681749, 7.3474748867280955, 7.4287771018956175, -3.2366056564069092, -3.7780788760312407], time: 253.269
steps: 174975, episodes: 7000, mean episode reward: 25.00498166114335, agent episode reward: [8.424808457423945, 7.821194063472482, 8.378181529193958, 8.235266012728305, -3.546633994970504, -4.307834406704837], time: 259.319
steps: 199975, episodes: 8000, mean episode reward: 31.552247763774446, agent episode reward: [10.644370570054818, 10.115190430706905, 10.510053863633383, 10.3052713401117, -4.837880960151223, -5.184757480581136], time: 259.495
steps: 224975, episodes: 9000, mean episode reward: 35.15727567838872, agent episode reward: [11.978134548073776, 11.502505725154364, 11.727595559459335, 11.60884823047017, -5.487443458696484, -6.172364926072435], time: 261.961
steps: 249975, episodes: 10000, mean episode reward: 32.96067182844436, agent episode reward: [11.40996419346552, 11.084424999670741, 11.259759261655612, 11.127176928892082, -4.618960374264306, -7.301693180975282], time: 251.562
steps: 274975, episodes: 11000, mean episode reward: 32.305729310954014, agent episode reward: [10.782736452735481, 10.455048453792548, 10.703968233649135, 10.552349286323771, -4.244886011266348, -5.9434871042805755], time: 258.075
steps: 299975, episodes: 12000, mean episode reward: 36.98386123320747, agent episode reward: [12.366330198981359, 12.139752511397969, 12.314566296554982, 12.233425973409735, -5.306980891701537, -6.763232855435035], time: 259.052
steps: 324975, episodes: 13000, mean episode reward: 33.06639439850527, agent episode reward: [11.218264784731343, 10.883107753260756, 11.093277634624412, 11.066670264085168, -4.077055254584934, -7.117870783611478], time: 258.387
steps: 349975, episodes: 14000, mean episode reward: 31.240140427573067, agent episode reward: [10.583911799172936, 10.40672160291989, 10.452581306518276, 10.442620771254372, -2.6527044168665372, -7.992990635425869], time: 260.151
steps: 374975, episodes: 15000, mean episode reward: 33.384487753939894, agent episode reward: [11.209260816017919, 11.00621871601646, 11.067166342682246, 11.12027843343924, -2.7588810914372437, -8.25955546277872], time: 261.592
steps: 399975, episodes: 16000, mean episode reward: 33.56518996795232, agent episode reward: [11.19983048034686, 10.973956521261215, 11.095341095406047, 11.151148409512762, -2.7292867923509765, -8.125799746223587], time: 254.938
steps: 424975, episodes: 17000, mean episode reward: 32.34432821230736, agent episode reward: [10.782526092944996, 10.604620278712334, 10.567211065888023, 10.70760459879231, -2.6128566631908745, -7.7047771608394235], time: 249.143
steps: 449975, episodes: 18000, mean episode reward: 28.21820487580404, agent episode reward: [9.638122551986973, 9.50429414471667, 9.4845593000341, 9.551892167873675, -2.7082411455999096, -7.25242214320747], time: 253.796
steps: 474975, episodes: 19000, mean episode reward: 23.20643352909672, agent episode reward: [8.624088651321575, 8.484451694478004, 8.491679268832906, 8.500111266162044, -3.081712560336768, -7.812184791361044], time: 255.652
steps: 499975, episodes: 20000, mean episode reward: 25.751215617145615, agent episode reward: [9.507450481967691, 9.370141692662886, 9.369164860265958, 9.374079422586604, -3.4027265601738734, -8.466894280163645], time: 258.056
steps: 524975, episodes: 21000, mean episode reward: 23.142841082276377, agent episode reward: [8.608247770745667, 8.5589531173176, 8.56929848695468, 8.584471999254239, -4.435221572870798, -6.74290871912502], time: 251.107
steps: 549975, episodes: 22000, mean episode reward: 15.681111878114722, agent episode reward: [7.83829747705165, 7.737486326076002, 7.732540140289431, 7.743072818401996, -8.113106543063875, -7.25717834064048], time: 253.225
steps: 574975, episodes: 23000, mean episode reward: 23.283616814347717, agent episode reward: [8.833749068619358, 8.752472296510856, 8.666241885400389, 8.68197766012896, -3.305977800475197, -8.344846295836648], time: 260.013
steps: 599975, episodes: 24000, mean episode reward: 25.55043939869942, agent episode reward: [9.244505752637712, 9.199822659165854, 9.109649173784218, 9.150723862002861, -2.7421060259444126, -8.412156022946808], time: 263.454
steps: 624975, episodes: 25000, mean episode reward: 22.187646468698762, agent episode reward: [8.56119743632621, 8.509802203705798, 8.47157502518206, 8.404711274247198, -2.7425398047358187, -9.017099666026688], time: 257.576
steps: 649975, episodes: 26000, mean episode reward: 25.514972925478347, agent episode reward: [9.30324260893657, 9.214660832383311, 9.224025776664488, 9.161267098534122, -3.103731168571297, -8.28449222246885], time: 259.902
steps: 674975, episodes: 27000, mean episode reward: 28.678313761924226, agent episode reward: [10.25888482696858, 10.158533148309907, 10.108782761456816, 10.003515112713544, -2.5336429576177846, -9.317759129906838], time: 257.944
steps: 699975, episodes: 28000, mean episode reward: 27.490661109561284, agent episode reward: [9.990382302509557, 9.930990187687915, 9.941995437227913, 9.678770127514229, -3.3975748209938117, -8.653902124384516], time: 257.982
steps: 724975, episodes: 29000, mean episode reward: 25.85677231110692, agent episode reward: [9.977671399744974, 9.85599210863686, 9.865892291375754, 9.716035375340832, -3.699658261637342, -9.859160602354157], time: 260.252
steps: 749975, episodes: 30000, mean episode reward: 24.291303659302844, agent episode reward: [10.32935300252026, 10.059182686135, 10.009065626529068, 9.915858974018407, -4.6657283447455535, -11.356428285154335], time: 262.713
steps: 774975, episodes: 31000, mean episode reward: 40.42158802438679, agent episode reward: [14.24993089023948, 14.2075231529666, 14.206654616635616, 14.209247845749205, -2.167269705144902, -14.284498776059209], time: 261.687
steps: 799975, episodes: 32000, mean episode reward: 38.45374671698696, agent episode reward: [13.63580706347699, 13.537336052156263, 13.500458379560001, 13.334396607646854, -2.5153350776491323, -13.038916308204014], time: 261.34
steps: 824975, episodes: 33000, mean episode reward: 40.85361045802799, agent episode reward: [14.470388994230753, 14.438148411143008, 14.375377071165635, 14.243246859686247, -2.800652838906733, -13.872898039290925], time: 253.761
steps: 849975, episodes: 34000, mean episode reward: 41.85616975487232, agent episode reward: [15.008891471037087, 14.96043563022753, 14.896545424742175, 14.753425607031913, -3.4940542356235555, -14.269074142542829], time: 254.734
steps: 874975, episodes: 35000, mean episode reward: 29.01448525703934, agent episode reward: [12.919907717003767, 12.883431984882145, 12.806723330034187, 12.625134783337135, -5.515757466301142, -16.704955091916755], time: 262.708
steps: 899975, episodes: 36000, mean episode reward: 21.904843833310995, agent episode reward: [8.861499037781849, 8.583515551374479, 8.822677752064877, 8.600897735972431, -3.158715050066539, -9.805031193816099], time: 261.309
steps: 924975, episodes: 37000, mean episode reward: 45.24846539668499, agent episode reward: [16.978290145471977, 16.942553193878794, 16.9684480593455, 16.84002667124023, -3.4875028426603714, -18.993349830591143], time: 261.646
steps: 949975, episodes: 38000, mean episode reward: 45.755093541757645, agent episode reward: [16.528406533050443, 16.37486846134744, 16.44285875405495, 16.202617932421404, -2.7561589234637576, -17.037499215652822], time: 261.544
steps: 974975, episodes: 39000, mean episode reward: 54.376413140136705, agent episode reward: [18.876370595990387, 18.665512806796336, 18.803910978625378, 18.59415788660363, -3.3606752240168807, -17.20286390386215], time: 262.319
steps: 999975, episodes: 40000, mean episode reward: 72.21590632665544, agent episode reward: [24.55224453512911, 24.477918244870672, 24.574066308928128, 24.480747395065606, -3.0919237662209236, -22.77714639111716], time: 263.636
steps: 1024975, episodes: 41000, mean episode reward: 98.17951332037669, agent episode reward: [32.925948552021175, 32.951623611474695, 32.98533810551102, 32.9419825684703, -4.136719603169942, -29.488659913930547], time: 259.316
steps: 1049975, episodes: 42000, mean episode reward: 104.60689407570558, agent episode reward: [35.17543340415828, 35.21342440399432, 35.27322407726196, 35.23252365176624, -5.248881365705387, -31.038830095769814], time: 257.657
steps: 1074975, episodes: 43000, mean episode reward: 107.21833281633957, agent episode reward: [35.69264595033695, 35.770633498871945, 35.7370956442607, 35.68807151802181, -5.840544236959961, -29.82956955819189], time: 259.508
steps: 1099975, episodes: 44000, mean episode reward: 96.64251893153592, agent episode reward: [32.278280161083835, 32.37803810110175, 32.35229765447106, 32.23982038861416, -6.18177446183736, -26.42414291189753], time: 261.369
steps: 1124975, episodes: 45000, mean episode reward: 95.68871414186195, agent episode reward: [31.707193873332663, 31.751521417737116, 31.751471196317986, 31.67365848991998, -6.1373078351569745, -25.05782300028881], time: 258.256
steps: 1149975, episodes: 46000, mean episode reward: 70.66600932194326, agent episode reward: [23.595343762172227, 23.679343873366175, 23.590354499085773, 23.573445259926512, -4.393695454839679, -19.378782617767747], time: 263.334
steps: 1174975, episodes: 47000, mean episode reward: 53.49530365091945, agent episode reward: [18.791957908422606, 18.860115000680015, 18.717506472652786, 18.798254329410398, -3.9593421339322195, -17.713187926314138], time: 259.878
steps: 1199975, episodes: 48000, mean episode reward: 56.189007979357065, agent episode reward: [18.964424623710794, 18.943082378345473, 18.855186369962667, 18.93469891763471, -4.236841405349093, -15.271542904947482], time: 263.352
steps: 1224975, episodes: 49000, mean episode reward: 59.19430296956823, agent episode reward: [19.639527332003308, 19.636772252609386, 19.6196573263787, 19.684955240163617, -3.447948126274892, -15.938661055311893], time: 260.026
steps: 1249975, episodes: 50000, mean episode reward: 56.95090715167072, agent episode reward: [19.077979503175893, 19.166045446893847, 19.092159319928705, 19.123229577748337, -2.9829433208243428, -16.52556337525171], time: 261.353
steps: 1274975, episodes: 51000, mean episode reward: 62.299696725307506, agent episode reward: [20.713273546925965, 20.797366560976, 20.756493621880367, 20.78864556264682, -2.3511442014380592, -18.404938365683584], time: 261.57
steps: 1299975, episodes: 52000, mean episode reward: 60.434302780645595, agent episode reward: [20.09878074752394, 20.11292159263934, 20.10506501241962, 20.15112569736234, -1.7604177615142285, -18.273172507785414], time: 259.742
steps: 1324975, episodes: 53000, mean episode reward: 58.27303501716356, agent episode reward: [19.59669829766805, 19.62414091439065, 19.68361039497443, 19.60971568068237, -1.7616818498224258, -18.479448420729504], time: 259.84
steps: 1349975, episodes: 54000, mean episode reward: 55.02985445075718, agent episode reward: [18.507281657134474, 18.530464386227234, 18.543334367040696, 18.550856436476792, -1.1986975165248994, -17.903384879597112], time: 262.987
steps: 1374975, episodes: 55000, mean episode reward: 61.10781954942375, agent episode reward: [21.041059539832727, 21.204558279064827, 21.21611301012518, 21.12118311207268, -2.1841606076214046, -21.29093378405026], time: 262.192
steps: 1399975, episodes: 56000, mean episode reward: 59.11328624211125, agent episode reward: [20.22664697124344, 20.352233501740216, 20.359594890015504, 20.28404809413929, -2.0854256919769534, -20.023811523050238], time: 260.516
steps: 1424975, episodes: 57000, mean episode reward: 59.17135820695687, agent episode reward: [20.239062407853353, 20.4231226375366, 20.39043670517998, 20.33489571662223, -2.358402960600271, -19.857756299635025], time: 262.1
steps: 1449975, episodes: 58000, mean episode reward: 59.59657883715717, agent episode reward: [20.212915646441274, 20.42527455869897, 20.443764577783885, 20.34383524856483, -1.555840959187025, -20.273370235144764], time: 265.093
steps: 1474975, episodes: 59000, mean episode reward: 61.106294320637765, agent episode reward: [20.69452730021756, 20.906693054237767, 20.92751999741906, 20.91073248324379, -1.785849554499664, -20.54732895998074], time: 257.871
steps: 1499975, episodes: 60000, mean episode reward: 65.12936849484579, agent episode reward: [21.84108729935494, 21.940146847786636, 21.971006288986747, 21.929892648728256, -1.378685460571074, -21.174079129439722], time: 231.916
...Finished total of 60001 episodes.
