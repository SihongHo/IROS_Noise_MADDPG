Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  0.5
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -28.20866052500563, agent episode reward: [0.7347626864234974, 0.6652158958890872, 0.7308082635973933, 0.6484353515075375, -13.08851941350952, -17.899363308913628], time: 171.755
steps: 49975, episodes: 2000, mean episode reward: -12.387101254498292, agent episode reward: [2.999096167967583, 3.0298847890109175, 3.186023101145463, 3.1751423708742466, -6.787268901547934, -17.989978781948572], time: 262.798
steps: 74975, episodes: 3000, mean episode reward: 15.480756689107242, agent episode reward: [5.257910143964946, 5.3799168144617475, 5.266491903864468, 4.999355353678114, -2.7992865517542254, -2.623630975107807], time: 258.907
steps: 99975, episodes: 4000, mean episode reward: 15.795505818338993, agent episode reward: [5.325836166865727, 5.451387284239589, 5.276074337082933, 4.9495909478827755, -2.3301291727609965, -2.8772537449710343], time: 251.843
steps: 124975, episodes: 5000, mean episode reward: 20.400000273859924, agent episode reward: [6.4963704162014695, 6.911878052845777, 6.97193000298528, 6.454697434934842, -3.028721287621187, -3.406154345486254], time: 256.121
steps: 149975, episodes: 6000, mean episode reward: 24.569434588537764, agent episode reward: [8.038525792913445, 8.391684726148371, 8.36851774734376, 7.752184551787984, -4.544188003863775, -3.4372902257920277], time: 256.672
steps: 174975, episodes: 7000, mean episode reward: 22.337061150172232, agent episode reward: [7.398547491245774, 7.70376123541853, 7.714691830620932, 7.095712155364621, -3.761168434465233, -3.8144831280123936], time: 258.658
steps: 199975, episodes: 8000, mean episode reward: 28.53366692997527, agent episode reward: [9.611267861530399, 9.588323822960174, 9.573883006994507, 9.26396451836882, -4.834245240470015, -4.669527039408618], time: 253.421
steps: 224975, episodes: 9000, mean episode reward: 33.10542947340774, agent episode reward: [10.931448179335002, 10.818631040424854, 10.78580238910411, 10.602911536900407, -5.0113514802612436, -5.022012192095386], time: 256.857
steps: 249975, episodes: 10000, mean episode reward: 38.05772887341039, agent episode reward: [12.625159070297663, 12.51265508284101, 12.507788529255613, 12.321642108367149, -5.530678634525759, -6.378837282825282], time: 252.345
steps: 274975, episodes: 11000, mean episode reward: 33.0100956883017, agent episode reward: [10.924535605758294, 10.891444963238309, 10.909543510203218, 10.737065623065057, -4.953695784287065, -5.498798229676107], time: 257.264
steps: 299975, episodes: 12000, mean episode reward: 35.759058984910354, agent episode reward: [12.044888181220056, 11.959502388221122, 12.111547954809637, 11.855446193102528, -5.601251141098679, -6.611074591344301], time: 259.747
steps: 324975, episodes: 13000, mean episode reward: 38.45627513447489, agent episode reward: [12.894317260783257, 12.722138508823695, 12.934797521572564, 12.64327018300895, -5.788665867940479, -6.9495824717730965], time: 260.633
steps: 349975, episodes: 14000, mean episode reward: 39.492300683616634, agent episode reward: [13.2624895566139, 13.187815186029939, 13.340881653248406, 13.160221012718038, -5.984294729412369, -7.474811995581291], time: 255.672
steps: 374975, episodes: 15000, mean episode reward: 44.56983303818109, agent episode reward: [15.14225014725156, 15.013370084645285, 15.214261576110125, 15.10532877152801, -6.9062630161205085, -8.999114525233386], time: 255.188
steps: 399975, episodes: 16000, mean episode reward: 40.28592923489599, agent episode reward: [13.798155003188498, 13.68370858104093, 13.841562178419789, 13.7688162445849, -6.472781771325726, -8.33353100101241], time: 258.688
steps: 424975, episodes: 17000, mean episode reward: 30.95230608318303, agent episode reward: [10.742025704037532, 10.618536644765976, 10.765763136824932, 10.714983284509966, -5.052377242802685, -6.836625444152693], time: 257.294
steps: 449975, episodes: 18000, mean episode reward: 28.281945927299304, agent episode reward: [9.787729413300028, 9.711132601806177, 9.82715288274596, 9.776625704823674, -4.522156821242108, -6.298537854134425], time: 253.778
steps: 474975, episodes: 19000, mean episode reward: 21.31077576554913, agent episode reward: [7.530970907307287, 7.4162910349306, 7.544884427988069, 7.47033094814143, -3.9369494961597518, -4.714752056658502], time: 252.281
steps: 499975, episodes: 20000, mean episode reward: 16.840125961102526, agent episode reward: [6.475074353411503, 6.34843313236563, 6.519853008721867, 6.444076965743755, -4.586002291614045, -4.361309207526184], time: 260.733
steps: 524975, episodes: 21000, mean episode reward: 13.300276850293303, agent episode reward: [5.357135026500724, 5.187546732494694, 5.314088176588972, 5.280175425177735, -3.804560355921219, -4.034108154547602], time: 259.538
steps: 549975, episodes: 22000, mean episode reward: 13.024739336360529, agent episode reward: [5.649837083670263, 5.471166836681756, 5.574620631759186, 5.548321132255511, -4.747810479584212, -4.471395868421974], time: 255.572
steps: 574975, episodes: 23000, mean episode reward: 11.693470133329003, agent episode reward: [5.006824491778163, 4.891376371560762, 4.928210023771547, 4.916081794241121, -4.512715488731912, -3.5363070592906802], time: 254.383
steps: 599975, episodes: 24000, mean episode reward: 11.146096584559821, agent episode reward: [5.094068287949936, 4.923513968094651, 4.949851931760301, 4.954321716619449, -4.494258188102163, -4.281401131762354], time: 254.152
steps: 624975, episodes: 25000, mean episode reward: 13.200344324548713, agent episode reward: [5.672543838806144, 5.512145870330119, 5.556871435411549, 5.517137721341894, -4.626215452470193, -4.4321390888708], time: 252.421
steps: 649975, episodes: 26000, mean episode reward: 14.870291589278938, agent episode reward: [5.8212122947950045, 5.646862843792683, 5.6456358571849785, 5.617897143812694, -4.562770908369795, -3.29854564193663], time: 258.305
steps: 674975, episodes: 27000, mean episode reward: 16.886208255926007, agent episode reward: [6.280184123257328, 6.121249666341815, 6.168532069423434, 6.084662165701587, -4.012111494426989, -3.7563082743711673], time: 261.967
steps: 699975, episodes: 28000, mean episode reward: 19.37243571096684, agent episode reward: [7.0810258501633765, 6.945858441230597, 7.001503187395644, 6.963884709244552, -4.684106126768584, -3.9357303502987397], time: 260.404
steps: 724975, episodes: 29000, mean episode reward: 20.930074277292146, agent episode reward: [7.264193172585459, 7.126663842798823, 7.071535432548206, 7.0602221984358895, -4.227379492403139, -3.3651608766730936], time: 256.68
steps: 749975, episodes: 30000, mean episode reward: 21.018422001650634, agent episode reward: [7.272985603560251, 7.106441973677534, 7.070734168852242, 7.0886505913340745, -4.23999399169251, -3.2803963440809603], time: 260.323
steps: 774975, episodes: 31000, mean episode reward: 20.263295047988155, agent episode reward: [7.0725254686728025, 6.871921056895168, 6.931335080369506, 6.878856342630401, -4.149894751718568, -3.3414481488611583], time: 260.499
steps: 799975, episodes: 32000, mean episode reward: 15.35892735069622, agent episode reward: [5.5210855146063835, 5.410437762260959, 5.398714630646862, 5.288765355589915, -2.7237906260756306, -3.53628528633227], time: 255.426
steps: 824975, episodes: 33000, mean episode reward: 17.89798236322104, agent episode reward: [6.5036920062676655, 6.366230697845878, 6.324892476059761, 6.330217458505689, -3.7906218144941994, -3.836428460963757], time: 261.017
steps: 849975, episodes: 34000, mean episode reward: 18.536572642495436, agent episode reward: [6.860037887504071, 6.672880959286051, 6.721601581204153, 6.6225381609824865, -4.174163174911583, -4.166322771569743], time: 260.099
steps: 874975, episodes: 35000, mean episode reward: 22.126813927991876, agent episode reward: [7.886629530233563, 7.700230310613579, 7.821757343414521, 7.68408275496359, -4.4155593646452544, -4.550326646588121], time: 255.709
steps: 899975, episodes: 36000, mean episode reward: 18.204930078907942, agent episode reward: [6.748462175777855, 6.594740052475461, 6.669405807085564, 6.530303910175069, -4.073139113315279, -4.2648427532907265], time: 260.352
steps: 924975, episodes: 37000, mean episode reward: 16.754909409806213, agent episode reward: [6.421816220996026, 6.191703421523571, 6.296801253813121, 6.244442145529914, -3.459749739233083, -4.940103892823335], time: 257.995
steps: 949975, episodes: 38000, mean episode reward: 17.327692342369826, agent episode reward: [6.474747316070963, 6.255305606614951, 6.264541409765959, 6.2325652864841805, -3.682044048737341, -4.2174232278288875], time: 258.002
steps: 974975, episodes: 39000, mean episode reward: 18.413110004617515, agent episode reward: [6.8109560017775905, 6.646275464294303, 6.605989747102108, 6.644534977187006, -3.5766982234947093, -4.717947962248779], time: 255.828
steps: 999975, episodes: 40000, mean episode reward: 17.48246331338724, agent episode reward: [6.57693372133915, 6.3775165300409205, 6.383166750299505, 6.372212949709903, -3.1932013084346424, -5.034165329567598], time: 258.511
steps: 1024975, episodes: 41000, mean episode reward: 22.25291828247605, agent episode reward: [7.885577579454026, 7.703370011581621, 7.805780490212834, 7.767623572155389, -3.6613283689625025, -5.248105001965316], time: 259.453
steps: 1049975, episodes: 42000, mean episode reward: 18.2732442347366, agent episode reward: [7.370521755338188, 7.185210996324416, 7.329707748433739, 7.201289303929647, -4.925031903151088, -5.888453666138303], time: 255.399
steps: 1074975, episodes: 43000, mean episode reward: 16.241178504577544, agent episode reward: [6.594521219594263, 6.524150103683502, 6.547018172052047, 6.505323468071336, -4.48660655407429, -5.443227904749314], time: 255.299
steps: 1099975, episodes: 44000, mean episode reward: 19.011937929871902, agent episode reward: [7.160192579688357, 7.086132059498553, 7.073319659681708, 6.974457293108314, -4.1624962847290385, -5.119667377375987], time: 254.505
steps: 1124975, episodes: 45000, mean episode reward: 18.989270530520567, agent episode reward: [7.112373447143071, 7.055632398081473, 7.055305389695316, 6.970601021248787, -4.3589545786317085, -4.845687147016371], time: 254.514
steps: 1149975, episodes: 46000, mean episode reward: 21.364956638994553, agent episode reward: [8.097930028020189, 7.999365557362389, 8.051895214263418, 7.967132876379617, -5.354500170610335, -5.396866866420725], time: 251.634
steps: 1174975, episodes: 47000, mean episode reward: 18.748390362708612, agent episode reward: [7.361659380693026, 7.270878823644088, 7.192046954076157, 7.180016251081113, -4.901766070865167, -5.354444975920607], time: 259.706
steps: 1199975, episodes: 48000, mean episode reward: 19.714294784858648, agent episode reward: [6.995891012279213, 6.987174635765815, 6.977039425321129, 6.981309472869519, -4.039561836659783, -4.187557924717242], time: 261.028
steps: 1224975, episodes: 49000, mean episode reward: 20.90684317156837, agent episode reward: [7.326259333198229, 7.3633770322925525, 7.271789956371913, 7.264824949598645, -4.2230643711103415, -4.096343728782625], time: 259.741
steps: 1249975, episodes: 50000, mean episode reward: 23.11000183939023, agent episode reward: [8.118160998331286, 8.070941442449127, 8.075212274998758, 8.04704890654784, -5.015195499383845, -4.186166283552942], time: 258.234
steps: 1274975, episodes: 51000, mean episode reward: 22.14682500293794, agent episode reward: [7.861199845247211, 7.806107742699867, 7.724219932193246, 7.767761419674043, -4.589263449949242, -4.423200486927183], time: 253.263
steps: 1299975, episodes: 52000, mean episode reward: 24.537785188041518, agent episode reward: [8.50170685315465, 8.421674872325267, 8.447496659836114, 8.433169196722417, -4.5833608830272015, -4.682901510969732], time: 255.709
steps: 1324975, episodes: 53000, mean episode reward: 22.999676361743695, agent episode reward: [8.302553693456655, 8.288959585363642, 8.297976484767416, 8.281741087573574, -5.184985817610504, -4.986568671807087], time: 256.176
steps: 1349975, episodes: 54000, mean episode reward: 20.333297220358602, agent episode reward: [7.54137222281313, 7.438467481534691, 7.506143854999971, 7.401206258026661, -4.984006512710803, -4.5698860843050495], time: 260.59
steps: 1374975, episodes: 55000, mean episode reward: 24.381379964062642, agent episode reward: [8.478864764726742, 8.314615138783747, 8.385882308930979, 8.291018446466861, -3.7532257192014624, -5.3357749756442265], time: 257.53
steps: 1399975, episodes: 56000, mean episode reward: 26.49868816604337, agent episode reward: [9.301961347888348, 9.164836400718974, 9.262037852143946, 9.150647952218453, -4.262458959874028, -6.118336427052325], time: 258.474
steps: 1424975, episodes: 57000, mean episode reward: 24.811945513758054, agent episode reward: [8.76518431115109, 8.634129629028916, 8.797691995564604, 8.617576715175343, -4.378250374259124, -5.624386762902773], time: 256.989
steps: 1449975, episodes: 58000, mean episode reward: 27.673110291783097, agent episode reward: [9.510991401199353, 9.335551993340642, 9.483371198217506, 9.353065798438568, -3.8379785344051323, -6.17189156500784], time: 263.747
steps: 1474975, episodes: 59000, mean episode reward: 26.88986933954966, agent episode reward: [9.26602823676283, 9.196516014859514, 9.391712128285585, 9.2359727119407, -3.8563849951541, -6.343974757144868], time: 262.265
steps: 1499975, episodes: 60000, mean episode reward: 30.492137891983504, agent episode reward: [10.544135985316798, 10.455270439828675, 10.549794486126572, 10.276556111030912, -4.779544469322629, -6.554074660996824], time: 254.425
...Finished total of 60001 episodes.
