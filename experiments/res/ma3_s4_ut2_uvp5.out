Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  0.5
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -23.546931204022297, agent episode reward: [-40.59869488084717, 8.525881838412435, 8.525881838412435], time: 81.35
steps: 49975, episodes: 2000, mean episode reward: -17.83936217153953, agent episode reward: [-28.145247395600915, 5.152942612030692, 5.152942612030692], time: 105.998
steps: 74975, episodes: 3000, mean episode reward: 2.4044876640668336, agent episode reward: [-12.811255733461119, 7.607871698763976, 7.607871698763976], time: 104.964
steps: 99975, episodes: 4000, mean episode reward: 4.060044572114052, agent episode reward: [-9.755389777469606, 6.907717174791829, 6.907717174791829], time: 105.45
steps: 124975, episodes: 5000, mean episode reward: 3.222711745118132, agent episode reward: [-9.584607762409115, 6.403659753763624, 6.403659753763624], time: 104.829
steps: 149975, episodes: 6000, mean episode reward: 2.8487243771395883, agent episode reward: [-9.0295914875462, 5.939157932342894, 5.939157932342894], time: 105.501
steps: 174975, episodes: 7000, mean episode reward: 2.9998368443296624, agent episode reward: [-9.9609142556236, 6.480375549976631, 6.480375549976631], time: 105.586
steps: 199975, episodes: 8000, mean episode reward: 2.926106357574524, agent episode reward: [-10.211697995024515, 6.5689021762995194, 6.5689021762995194], time: 104.897
steps: 224975, episodes: 9000, mean episode reward: 2.2826198708501115, agent episode reward: [-10.224080723253174, 6.253350297051642, 6.253350297051642], time: 105.659
steps: 249975, episodes: 10000, mean episode reward: 1.6929852154286174, agent episode reward: [-10.062506479401543, 5.877745847415081, 5.877745847415081], time: 105.63
steps: 274975, episodes: 11000, mean episode reward: 1.1404727780869057, agent episode reward: [-11.113515408677424, 6.126994093382163, 6.126994093382163], time: 104.971
steps: 299975, episodes: 12000, mean episode reward: 1.124415457492678, agent episode reward: [-10.296458261137772, 5.710436859315225, 5.710436859315225], time: 106.023
steps: 324975, episodes: 13000, mean episode reward: 0.19441490751200102, agent episode reward: [-10.46448498320689, 5.329449945359445, 5.329449945359445], time: 105.101
steps: 349975, episodes: 14000, mean episode reward: 0.26031339507368173, agent episode reward: [-11.100892210246789, 5.680602802660236, 5.680602802660236], time: 105.552
steps: 374975, episodes: 15000, mean episode reward: 0.17788315563633111, agent episode reward: [-10.315344841245688, 5.246613998441009, 5.246613998441009], time: 105.248
steps: 399975, episodes: 16000, mean episode reward: -0.25698624933841324, agent episode reward: [-10.463484510933963, 5.103249130797774, 5.103249130797774], time: 105.039
steps: 424975, episodes: 17000, mean episode reward: 0.9129236209142663, agent episode reward: [-10.580961759685737, 5.746942690300002, 5.746942690300002], time: 105.228
steps: 449975, episodes: 18000, mean episode reward: 0.8282168990194197, agent episode reward: [-10.61274863939994, 5.7204827692096805, 5.7204827692096805], time: 105.191
steps: 474975, episodes: 19000, mean episode reward: 0.6897282086684507, agent episode reward: [-10.408349304567487, 5.5490387566179695, 5.5490387566179695], time: 105.272
steps: 499975, episodes: 20000, mean episode reward: 0.4762713912013579, agent episode reward: [-10.531320239696251, 5.503795815448805, 5.503795815448805], time: 105.425
steps: 524975, episodes: 21000, mean episode reward: 0.12467463985675767, agent episode reward: [-10.635573841658656, 5.380124240757707, 5.380124240757707], time: 104.315
steps: 549975, episodes: 22000, mean episode reward: 0.7454193081386014, agent episode reward: [-11.225406592255121, 5.985412950196862, 5.985412950196862], time: 104.84
steps: 574975, episodes: 23000, mean episode reward: 1.493818317544324, agent episode reward: [-12.233525214423931, 6.863671765984127, 6.863671765984127], time: 104.404
steps: 599975, episodes: 24000, mean episode reward: 0.25976345101684784, agent episode reward: [-11.62142775849376, 5.940595604755305, 5.940595604755305], time: 104.35
steps: 624975, episodes: 25000, mean episode reward: 1.285350920949254, agent episode reward: [-11.645982697018047, 6.465666808983651, 6.465666808983651], time: 100.812
steps: 649975, episodes: 26000, mean episode reward: 1.1193712543843704, agent episode reward: [-11.658060003345513, 6.388715628864942, 6.388715628864942], time: 98.879
steps: 674975, episodes: 27000, mean episode reward: 1.1980426681555756, agent episode reward: [-11.719975809449622, 6.459009238802599, 6.459009238802599], time: 99.427
steps: 699975, episodes: 28000, mean episode reward: 0.6567745948899696, agent episode reward: [-11.435654395492227, 6.0462144951911, 6.0462144951911], time: 99.716
steps: 724975, episodes: 29000, mean episode reward: 0.7325602732570813, agent episode reward: [-12.48860929603532, 6.6105847846462, 6.6105847846462], time: 97.497
steps: 749975, episodes: 30000, mean episode reward: 1.5053879036011155, agent episode reward: [-12.665031120323325, 7.085209511962221, 7.085209511962221], time: 100.14
steps: 774975, episodes: 31000, mean episode reward: 1.3251914930852877, agent episode reward: [-11.999017770500016, 6.662104631792651, 6.662104631792651], time: 99.174
steps: 799975, episodes: 32000, mean episode reward: 1.0940763769137671, agent episode reward: [-12.56886631883408, 6.831471347873925, 6.831471347873925], time: 98.444
steps: 824975, episodes: 33000, mean episode reward: 0.8425829610166296, agent episode reward: [-12.709140205778068, 6.775861583397349, 6.775861583397349], time: 98.656
steps: 849975, episodes: 34000, mean episode reward: 1.2107106642176928, agent episode reward: [-12.718975801282927, 6.96484323275031, 6.96484323275031], time: 100.172
steps: 874975, episodes: 35000, mean episode reward: 1.068971058124937, agent episode reward: [-12.822860003207454, 6.945915530666195, 6.945915530666195], time: 99.638
steps: 899975, episodes: 36000, mean episode reward: 1.2261641095207736, agent episode reward: [-12.432565223733052, 6.829364666626914, 6.829364666626914], time: 98.712
steps: 924975, episodes: 37000, mean episode reward: 0.9176349675319698, agent episode reward: [-12.844107955115946, 6.880871461323957, 6.880871461323957], time: 97.799
steps: 949975, episodes: 38000, mean episode reward: 0.19041171429805853, agent episode reward: [-12.618299684233515, 6.404355699265786, 6.404355699265786], time: 100.55
steps: 974975, episodes: 39000, mean episode reward: 0.3046081036108425, agent episode reward: [-11.989081193119896, 6.146844648365368, 6.146844648365368], time: 99.227
steps: 999975, episodes: 40000, mean episode reward: 0.4308678118091189, agent episode reward: [-12.28695600971354, 6.3589119107613294, 6.3589119107613294], time: 99.629
steps: 1024975, episodes: 41000, mean episode reward: 0.3590008688796039, agent episode reward: [-11.96198005958265, 6.1604904642311284, 6.1604904642311284], time: 99.576
steps: 1049975, episodes: 42000, mean episode reward: -0.0047478393767920015, agent episode reward: [-12.851938977005473, 6.42359556881434, 6.42359556881434], time: 98.807
steps: 1074975, episodes: 43000, mean episode reward: -0.21917483874955968, agent episode reward: [-12.651193765802216, 6.216009463526328, 6.216009463526328], time: 99.405
steps: 1099975, episodes: 44000, mean episode reward: -0.2175305737273749, agent episode reward: [-13.110243843034887, 6.446356634653755, 6.446356634653755], time: 100.149
steps: 1124975, episodes: 45000, mean episode reward: -0.6130480284425163, agent episode reward: [-13.06136291078167, 6.224157441169576, 6.224157441169576], time: 99.146
steps: 1149975, episodes: 46000, mean episode reward: -0.3053792945317947, agent episode reward: [-12.868573945479389, 6.281597325473796, 6.281597325473796], time: 98.489
steps: 1174975, episodes: 47000, mean episode reward: -0.6662451510741346, agent episode reward: [-12.509933522726003, 5.921844185825934, 5.921844185825934], time: 99.745
steps: 1199975, episodes: 48000, mean episode reward: -0.2280257789186046, agent episode reward: [-13.518183167358172, 6.645078694219785, 6.645078694219785], time: 99.484
steps: 1224975, episodes: 49000, mean episode reward: -1.5757246235651734, agent episode reward: [-13.133494109167014, 5.778884742800919, 5.778884742800919], time: 99.091
steps: 1249975, episodes: 50000, mean episode reward: -1.4328137747557534, agent episode reward: [-12.84478512821287, 5.7059856767285595, 5.7059856767285595], time: 99.617
steps: 1274975, episodes: 51000, mean episode reward: -0.579005176332884, agent episode reward: [-13.061933666175829, 6.241464244921473, 6.241464244921473], time: 99.862
steps: 1299975, episodes: 52000, mean episode reward: -1.5615972163144924, agent episode reward: [-12.872380554115502, 5.655391668900505, 5.655391668900505], time: 99.551
steps: 1324975, episodes: 53000, mean episode reward: -0.8018283560539803, agent episode reward: [-13.072575631947803, 6.13537363794691, 6.13537363794691], time: 99.993
steps: 1349975, episodes: 54000, mean episode reward: -1.6477491940410696, agent episode reward: [-13.199558637407772, 5.775904721683353, 5.775904721683353], time: 99.159
steps: 1374975, episodes: 55000, mean episode reward: -1.3400425894300576, agent episode reward: [-13.661491760881471, 6.160724585725705, 6.160724585725705], time: 99.347
steps: 1399975, episodes: 56000, mean episode reward: -1.2040016559329023, agent episode reward: [-13.632051162431445, 6.21402475324927, 6.21402475324927], time: 99.252
steps: 1424975, episodes: 57000, mean episode reward: -0.7652881107159286, agent episode reward: [-14.32091700821897, 6.777814448751521, 6.777814448751521], time: 99.036
steps: 1449975, episodes: 58000, mean episode reward: -1.4347057194601531, agent episode reward: [-13.835988471488342, 6.200641376014095, 6.200641376014095], time: 99.286
steps: 1474975, episodes: 59000, mean episode reward: -1.4853435146411038, agent episode reward: [-14.107825470097564, 6.311240977728231, 6.311240977728231], time: 101.654
steps: 1499975, episodes: 60000, mean episode reward: -1.5000822868428922, agent episode reward: [-13.576409050124042, 6.038163381640575, 6.038163381640575], time: 85.991
...Finished total of 60001 episodes.
