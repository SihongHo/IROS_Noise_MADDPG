Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  0.5
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -23.45895332532482, agent episode reward: [-35.79554369827433, 6.168295186474757, 6.168295186474757], time: 66.611
steps: 49975, episodes: 2000, mean episode reward: -16.557674171495336, agent episode reward: [-24.143607398294705, 3.7929666133996864, 3.7929666133996864], time: 86.116
steps: 74975, episodes: 3000, mean episode reward: 0.15632955419768904, agent episode reward: [-15.701768994456916, 7.929049274327302, 7.929049274327302], time: 96.614
steps: 99975, episodes: 4000, mean episode reward: 3.166740114381565, agent episode reward: [-11.401130897597133, 7.283935505989349, 7.283935505989349], time: 99.938
steps: 124975, episodes: 5000, mean episode reward: 2.5125645491741895, agent episode reward: [-9.861573667519158, 6.187069108346674, 6.187069108346674], time: 100.459
steps: 149975, episodes: 6000, mean episode reward: 1.408064982080053, agent episode reward: [-9.23865404718657, 5.323359514633312, 5.323359514633312], time: 100.887
steps: 174975, episodes: 7000, mean episode reward: 2.024938154934724, agent episode reward: [-9.531783037671314, 5.77836059630302, 5.77836059630302], time: 101.318
steps: 199975, episodes: 8000, mean episode reward: 2.0037872485115154, agent episode reward: [-9.749922323302677, 5.876854785907095, 5.876854785907095], time: 101.379
steps: 224975, episodes: 9000, mean episode reward: 1.9244294395188493, agent episode reward: [-10.61195212625592, 6.268190782887385, 6.268190782887385], time: 101.103
steps: 249975, episodes: 10000, mean episode reward: 1.8939924287670364, agent episode reward: [-10.739180726818347, 6.316586577792692, 6.316586577792692], time: 101.299
steps: 274975, episodes: 11000, mean episode reward: 0.9487422554293439, agent episode reward: [-10.98443474052948, 5.966588497979412, 5.966588497979412], time: 100.826
steps: 299975, episodes: 12000, mean episode reward: -0.20898805218857083, agent episode reward: [-10.64928739492094, 5.220149671366183, 5.220149671366183], time: 101.687
steps: 324975, episodes: 13000, mean episode reward: 0.5598731836533929, agent episode reward: [-10.63237731029699, 5.59612524697519, 5.59612524697519], time: 100.936
steps: 349975, episodes: 14000, mean episode reward: 1.428883294126099, agent episode reward: [-11.140221464469874, 6.2845523792979865, 6.2845523792979865], time: 100.76
steps: 374975, episodes: 15000, mean episode reward: 0.22304057218760573, agent episode reward: [-10.287173327757282, 5.255106949972443, 5.255106949972443], time: 101.72
steps: 399975, episodes: 16000, mean episode reward: 0.20570960273375913, agent episode reward: [-10.938360480813337, 5.572035041773548, 5.572035041773548], time: 100.053
steps: 424975, episodes: 17000, mean episode reward: 0.07114050316807058, agent episode reward: [-10.724048562398591, 5.397594532783331, 5.397594532783331], time: 101.179
steps: 449975, episodes: 18000, mean episode reward: -0.0014003492028654137, agent episode reward: [-10.759720808638846, 5.379160229717991, 5.379160229717991], time: 101.306
steps: 474975, episodes: 19000, mean episode reward: -0.40511173207867845, agent episode reward: [-11.086695106043914, 5.340791686982619, 5.340791686982619], time: 101.411
steps: 499975, episodes: 20000, mean episode reward: -0.03858461217606499, agent episode reward: [-10.931074756731142, 5.44624507227754, 5.44624507227754], time: 100.424
steps: 524975, episodes: 21000, mean episode reward: -0.5087226463578254, agent episode reward: [-10.733833896029195, 5.112555624835684, 5.112555624835684], time: 100.448
steps: 549975, episodes: 22000, mean episode reward: -0.4077996002202549, agent episode reward: [-11.150348603927817, 5.37127450185378, 5.37127450185378], time: 100.763
steps: 574975, episodes: 23000, mean episode reward: -0.3423078428094236, agent episode reward: [-11.478996904491272, 5.568344530840925, 5.568344530840925], time: 100.76
steps: 599975, episodes: 24000, mean episode reward: -0.6070699316601459, agent episode reward: [-11.248021336977244, 5.320475702658549, 5.320475702658549], time: 101.429
steps: 624975, episodes: 25000, mean episode reward: -0.6754098925199712, agent episode reward: [-11.197034815637668, 5.260812461558848, 5.260812461558848], time: 101.446
steps: 649975, episodes: 26000, mean episode reward: -0.9111538565396208, agent episode reward: [-11.076497606699865, 5.0826718750801225, 5.0826718750801225], time: 100.896
steps: 674975, episodes: 27000, mean episode reward: -1.2936638795546562, agent episode reward: [-11.641496279342077, 5.17391619989371, 5.17391619989371], time: 100.599
steps: 699975, episodes: 28000, mean episode reward: -1.5400650122409956, agent episode reward: [-11.538315512678226, 4.999125250218615, 4.999125250218615], time: 100.542
steps: 724975, episodes: 29000, mean episode reward: -0.14798529572987854, agent episode reward: [-11.448173613975863, 5.650094159122991, 5.650094159122991], time: 100.829
steps: 749975, episodes: 30000, mean episode reward: -1.1586475061619554, agent episode reward: [-11.7496111731003, 5.295481833469172, 5.295481833469172], time: 101.612
steps: 774975, episodes: 31000, mean episode reward: -0.8417425266392493, agent episode reward: [-11.23886831566118, 5.198562894510966, 5.198562894510966], time: 101.091
steps: 799975, episodes: 32000, mean episode reward: -0.9608018599751623, agent episode reward: [-11.517074572415003, 5.27813635621992, 5.27813635621992], time: 99.448
steps: 824975, episodes: 33000, mean episode reward: -0.34243004610168815, agent episode reward: [-12.25845242151018, 5.958011187704246, 5.958011187704246], time: 99.376
steps: 849975, episodes: 34000, mean episode reward: -2.252688708227459, agent episode reward: [-12.423321275787195, 5.085316283779868, 5.085316283779868], time: 99.509
steps: 874975, episodes: 35000, mean episode reward: -1.496802898156984, agent episode reward: [-11.858079136651703, 5.180638119247359, 5.180638119247359], time: 98.592
steps: 899975, episodes: 36000, mean episode reward: -1.475830367206475, agent episode reward: [-12.53704689032755, 5.530608261560538, 5.530608261560538], time: 99.212
steps: 924975, episodes: 37000, mean episode reward: -1.9536938984846424, agent episode reward: [-12.228612033003927, 5.137459067259642, 5.137459067259642], time: 98.564
steps: 949975, episodes: 38000, mean episode reward: -1.9250033247872802, agent episode reward: [-12.637714946732789, 5.3563558109727545, 5.3563558109727545], time: 100.801
steps: 974975, episodes: 39000, mean episode reward: -1.7297693986516913, agent episode reward: [-12.209107652016801, 5.239669126682554, 5.239669126682554], time: 98.853
steps: 999975, episodes: 40000, mean episode reward: -2.4215347570498036, agent episode reward: [-12.980552107440351, 5.279508675195273, 5.279508675195273], time: 98.216
steps: 1024975, episodes: 41000, mean episode reward: -2.4761774865730333, agent episode reward: [-13.137084757496629, 5.330453635461797, 5.330453635461797], time: 99.636
steps: 1049975, episodes: 42000, mean episode reward: -2.5072714648898007, agent episode reward: [-12.904749579020002, 5.198739057065101, 5.198739057065101], time: 99.363
steps: 1074975, episodes: 43000, mean episode reward: -3.589461433678555, agent episode reward: [-12.798009195807012, 4.604273881064228, 4.604273881064228], time: 99.376
steps: 1099975, episodes: 44000, mean episode reward: -3.1409392555716367, agent episode reward: [-12.397247478593076, 4.628154111510719, 4.628154111510719], time: 98.908
steps: 1124975, episodes: 45000, mean episode reward: -4.075238824921136, agent episode reward: [-13.089274709059334, 4.507017942069099, 4.507017942069099], time: 97.765
steps: 1149975, episodes: 46000, mean episode reward: -3.6450996597550467, agent episode reward: [-12.727397652116583, 4.541148996180768, 4.541148996180768], time: 89.809
steps: 1174975, episodes: 47000, mean episode reward: -3.4214072818921477, agent episode reward: [-12.490866114749984, 4.5347294164289185, 4.5347294164289185], time: 90.551
steps: 1199975, episodes: 48000, mean episode reward: -2.8754173664898492, agent episode reward: [-12.16492047608641, 4.6447515547982805, 4.6447515547982805], time: 85.856
steps: 1224975, episodes: 49000, mean episode reward: -3.759353366599469, agent episode reward: [-12.080775428374665, 4.160711030887598, 4.160711030887598], time: 81.186
steps: 1249975, episodes: 50000, mean episode reward: -4.179357846340182, agent episode reward: [-11.334016359734255, 3.577329256697036, 3.577329256697036], time: 80.744
steps: 1274975, episodes: 51000, mean episode reward: -2.718459761263311, agent episode reward: [-11.561814684998497, 4.421677461867594, 4.421677461867594], time: 79.478
steps: 1299975, episodes: 52000, mean episode reward: -2.8461727062024904, agent episode reward: [-11.672902715491935, 4.413365004644723, 4.413365004644723], time: 82.737
steps: 1324975, episodes: 53000, mean episode reward: -1.5570874063955042, agent episode reward: [-11.802909409284343, 5.12291100144442, 5.12291100144442], time: 83.157
steps: 1349975, episodes: 54000, mean episode reward: -1.202556471486322, agent episode reward: [-12.078160833798243, 5.437802181155962, 5.437802181155962], time: 83.015
steps: 1374975, episodes: 55000, mean episode reward: -1.6115046149151022, agent episode reward: [-12.017235395971099, 5.202865390527997, 5.202865390527997], time: 82.603
steps: 1399975, episodes: 56000, mean episode reward: -1.1473464881582114, agent episode reward: [-12.57191572311093, 5.712284617476359, 5.712284617476359], time: 82.48
steps: 1424975, episodes: 57000, mean episode reward: -2.488362378832512, agent episode reward: [-12.139753117122014, 4.825695369144751, 4.825695369144751], time: 83.543
steps: 1449975, episodes: 58000, mean episode reward: -1.6718333412894417, agent episode reward: [-12.133937237918797, 5.231051948314677, 5.231051948314677], time: 83.902
steps: 1474975, episodes: 59000, mean episode reward: -1.2105691888647263, agent episode reward: [-11.655665919232536, 5.222548365183905, 5.222548365183905], time: 80.926
steps: 1499975, episodes: 60000, mean episode reward: -0.28884866128850706, agent episode reward: [-11.898159909092502, 5.804655623901998, 5.804655623901998], time: 82.863
...Finished total of 60001 episodes.
