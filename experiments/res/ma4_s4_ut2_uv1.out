Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  1.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -21.499539285393283, agent episode reward: [-36.433513789318255, 7.466987251962487, 7.466987251962487], time: 88.601
steps: 49975, episodes: 2000, mean episode reward: -23.64734169524676, agent episode reward: [-31.82612449357308, 4.089391399163161, 4.089391399163161], time: 113.554
steps: 74975, episodes: 3000, mean episode reward: -1.3549323252987782, agent episode reward: [-16.730683657212403, 7.687875665956812, 7.687875665956812], time: 113.595
steps: 99975, episodes: 4000, mean episode reward: 5.371624988631349, agent episode reward: [-15.470303462262379, 10.420964225446866, 10.420964225446866], time: 114.318
steps: 124975, episodes: 5000, mean episode reward: 6.035945659096921, agent episode reward: [-14.41639157456296, 10.226168616829941, 10.226168616829941], time: 113.233
steps: 149975, episodes: 6000, mean episode reward: 5.67305358770376, agent episode reward: [-13.378023831361547, 9.525538709532654, 9.525538709532654], time: 114.324
steps: 174975, episodes: 7000, mean episode reward: 3.7543375929696396, agent episode reward: [-10.52126291528395, 7.137800254126795, 7.137800254126795], time: 114.422
steps: 199975, episodes: 8000, mean episode reward: 3.668152758300159, agent episode reward: [-10.34516579038665, 7.006659274343405, 7.006659274343405], time: 113.922
steps: 224975, episodes: 9000, mean episode reward: 3.6050652406828085, agent episode reward: [-9.900703647058428, 6.752884443870618, 6.752884443870618], time: 114.779
steps: 249975, episodes: 10000, mean episode reward: 3.3656356129704887, agent episode reward: [-11.01263502074745, 7.189135316858969, 7.189135316858969], time: 114.241
steps: 274975, episodes: 11000, mean episode reward: 2.575390496069308, agent episode reward: [-11.15399291320686, 6.8646917046380835, 6.8646917046380835], time: 114.712
steps: 299975, episodes: 12000, mean episode reward: 2.805241523203483, agent episode reward: [-12.809874634079094, 7.8075580786412875, 7.8075580786412875], time: 115.295
steps: 324975, episodes: 13000, mean episode reward: 2.0369632107982256, agent episode reward: [-11.59114024564659, 6.814051728222408, 6.814051728222408], time: 114.193
steps: 349975, episodes: 14000, mean episode reward: 2.1122347923515408, agent episode reward: [-12.49122521630581, 7.301730004328676, 7.301730004328676], time: 113.7
steps: 374975, episodes: 15000, mean episode reward: 1.6087801052845847, agent episode reward: [-12.546940299488616, 7.0778602023866, 7.0778602023866], time: 114.826
steps: 399975, episodes: 16000, mean episode reward: 0.9280156594811856, agent episode reward: [-13.063672704521235, 6.99584418200121, 6.99584418200121], time: 112.875
steps: 424975, episodes: 17000, mean episode reward: 1.0362520377660758, agent episode reward: [-12.965085700292144, 7.00066886902911, 7.00066886902911], time: 113.304
steps: 449975, episodes: 18000, mean episode reward: 0.6303372349378301, agent episode reward: [-12.867304252505441, 6.748820743721635, 6.748820743721635], time: 113.925
steps: 474975, episodes: 19000, mean episode reward: -0.10293545058053483, agent episode reward: [-13.320224776387672, 6.608644662903569, 6.608644662903569], time: 114.274
steps: 499975, episodes: 20000, mean episode reward: 1.610149526662914, agent episode reward: [-13.208136055738272, 7.409142791200594, 7.409142791200594], time: 113.549
steps: 524975, episodes: 21000, mean episode reward: 1.4662806157980977, agent episode reward: [-13.607170850252624, 7.536725733025361, 7.536725733025361], time: 112.983
steps: 549975, episodes: 22000, mean episode reward: 1.6259169410923533, agent episode reward: [-14.211964758745717, 7.918940849919034, 7.918940849919034], time: 113.528
steps: 574975, episodes: 23000, mean episode reward: 1.9993658607877003, agent episode reward: [-13.414183491574324, 7.706774676181012, 7.706774676181012], time: 114.477
steps: 599975, episodes: 24000, mean episode reward: 0.3357473201509816, agent episode reward: [-14.922949025082017, 7.629348172616499, 7.629348172616499], time: 114.536
steps: 624975, episodes: 25000, mean episode reward: 1.3606202673868548, agent episode reward: [-15.285780978994753, 8.323200623190804, 8.323200623190804], time: 114.648
steps: 649975, episodes: 26000, mean episode reward: 0.7037964305322848, agent episode reward: [-15.74737813672336, 8.225587283627823, 8.225587283627823], time: 114.99
steps: 674975, episodes: 27000, mean episode reward: 1.7205778656436228, agent episode reward: [-15.247394621991877, 8.483986243817752, 8.483986243817752], time: 114.489
steps: 699975, episodes: 28000, mean episode reward: 0.9827015068534317, agent episode reward: [-14.486824297829422, 7.734762902341426, 7.734762902341426], time: 114.155
steps: 724975, episodes: 29000, mean episode reward: 0.9315948540162613, agent episode reward: [-14.585345495578826, 7.7584701747975435, 7.7584701747975435], time: 114.48
steps: 749975, episodes: 30000, mean episode reward: 0.015437450280555936, agent episode reward: [-16.19565833282599, 8.105547891553272, 8.105547891553272], time: 115.898
steps: 774975, episodes: 31000, mean episode reward: 0.3432732978608634, agent episode reward: [-14.338262101529633, 7.34076769969525, 7.34076769969525], time: 113.832
steps: 799975, episodes: 32000, mean episode reward: 0.6729331347551343, agent episode reward: [-14.82957988041106, 7.751256507583097, 7.751256507583097], time: 113.62
steps: 824975, episodes: 33000, mean episode reward: 0.4319912525370227, agent episode reward: [-13.67983848615353, 7.055914869345276, 7.055914869345276], time: 113.6
steps: 849975, episodes: 34000, mean episode reward: -0.1711532449027664, agent episode reward: [-13.405042751095639, 6.616944753096436, 6.616944753096436], time: 113.956
steps: 874975, episodes: 35000, mean episode reward: -0.47864013886567647, agent episode reward: [-13.889765418406535, 6.705562639770429, 6.705562639770429], time: 113.162
steps: 899975, episodes: 36000, mean episode reward: -1.1954854082512467, agent episode reward: [-16.410362418662764, 7.6074385052057565, 7.6074385052057565], time: 113.943
steps: 924975, episodes: 37000, mean episode reward: -1.416962381708517, agent episode reward: [-14.358264813771498, 6.470651216031491, 6.470651216031491], time: 114.178
steps: 949975, episodes: 38000, mean episode reward: 0.07411358936313019, agent episode reward: [-13.424551284322247, 6.749332436842688, 6.749332436842688], time: 115.3
steps: 974975, episodes: 39000, mean episode reward: -0.9068589489570155, agent episode reward: [-13.716506434147545, 6.404823742595264, 6.404823742595264], time: 113.556
steps: 999975, episodes: 40000, mean episode reward: -1.1847819616378783, agent episode reward: [-13.19230792437723, 6.0037629813696745, 6.0037629813696745], time: 114.156
steps: 1024975, episodes: 41000, mean episode reward: -1.1787364233572168, agent episode reward: [-14.081171153027775, 6.45121736483528, 6.45121736483528], time: 114.378
steps: 1049975, episodes: 42000, mean episode reward: -0.8631432523172508, agent episode reward: [-13.73364770567507, 6.435252226678911, 6.435252226678911], time: 114.173
steps: 1074975, episodes: 43000, mean episode reward: -0.6811666813485349, agent episode reward: [-12.135147935147401, 5.726990626899433, 5.726990626899433], time: 114.887
steps: 1099975, episodes: 44000, mean episode reward: -1.0139985993156826, agent episode reward: [-12.119110458667965, 5.552555929676141, 5.552555929676141], time: 113.482
steps: 1124975, episodes: 45000, mean episode reward: -1.5989759629733606, agent episode reward: [-11.833354917164511, 5.117189477095576, 5.117189477095576], time: 114.083
steps: 1149975, episodes: 46000, mean episode reward: -1.5081519847336662, agent episode reward: [-11.43934263848052, 4.965595326873427, 4.965595326873427], time: 114.252
steps: 1174975, episodes: 47000, mean episode reward: -1.2787200837539552, agent episode reward: [-12.207067226734212, 5.46417357149013, 5.46417357149013], time: 113.821
steps: 1199975, episodes: 48000, mean episode reward: -1.7262272667334557, agent episode reward: [-11.720440913614743, 4.997106823440643, 4.997106823440643], time: 116.173
steps: 1224975, episodes: 49000, mean episode reward: -1.5564271152047469, agent episode reward: [-12.319072484438209, 5.381322684616731, 5.381322684616731], time: 115.055
steps: 1249975, episodes: 50000, mean episode reward: -1.6395484189177787, agent episode reward: [-12.5617857868597, 5.46111868397096, 5.46111868397096], time: 114.282
steps: 1274975, episodes: 51000, mean episode reward: -2.2721053423633295, agent episode reward: [-12.928379457349209, 5.328137057492939, 5.328137057492939], time: 114.49
steps: 1299975, episodes: 52000, mean episode reward: -2.117101118837121, agent episode reward: [-12.797257937568265, 5.340078409365573, 5.340078409365573], time: 113.86
steps: 1324975, episodes: 53000, mean episode reward: -2.8821889985048292, agent episode reward: [-12.08780750774225, 4.602809254618709, 4.602809254618709], time: 114.322
steps: 1349975, episodes: 54000, mean episode reward: -2.7327023973266753, agent episode reward: [-12.401929306854777, 4.834613454764051, 4.834613454764051], time: 113.935
steps: 1374975, episodes: 55000, mean episode reward: -3.25048238093089, agent episode reward: [-12.838441497014006, 4.793979558041557, 4.793979558041557], time: 114.44
steps: 1399975, episodes: 56000, mean episode reward: -3.56463657024364, agent episode reward: [-11.951484566498618, 4.1934239981274875, 4.1934239981274875], time: 113.225
steps: 1424975, episodes: 57000, mean episode reward: -2.7466641907897436, agent episode reward: [-11.926663353646113, 4.589999581428184, 4.589999581428184], time: 114.521
steps: 1449975, episodes: 58000, mean episode reward: -2.1415835391924243, agent episode reward: [-12.109408792768171, 4.983912626787875, 4.983912626787875], time: 114.282
steps: 1474975, episodes: 59000, mean episode reward: -2.5930111661380106, agent episode reward: [-12.652832211669638, 5.029910522765813, 5.029910522765813], time: 115.821
steps: 1499975, episodes: 60000, mean episode reward: -2.515372984687478, agent episode reward: [-12.111384877328339, 4.798005946320431, 4.798005946320431], time: 114.539
...Finished total of 60001 episodes.
