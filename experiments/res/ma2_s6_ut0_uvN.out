Using good policy maddpg and adv policy maddpg
Uncertainty type is:  None ; Uncertainty level is:  1.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -23.310835578732604, agent episode reward: [-24.75244602643564, 0.7208052238515168, 0.7208052238515168], time: 48.006
steps: 49975, episodes: 2000, mean episode reward: -16.63155328218177, agent episode reward: [-16.87937323695126, 0.12390997738474471, 0.12390997738474471], time: 96.285
steps: 74975, episodes: 3000, mean episode reward: -9.178697324516477, agent episode reward: [-10.575639680659863, 0.6984711780716939, 0.6984711780716939], time: 128.514
steps: 99975, episodes: 4000, mean episode reward: -2.0537525269929757, agent episode reward: [-17.618813885732393, 7.782530679369711, 7.782530679369711], time: 127.785
steps: 124975, episodes: 5000, mean episode reward: 14.613164325199786, agent episode reward: [-17.32205116846793, 15.967607746833858, 15.967607746833858], time: 127.069
steps: 149975, episodes: 6000, mean episode reward: 15.33212111954465, agent episode reward: [-17.100895113897185, 16.216508116720917, 16.216508116720917], time: 127.009
steps: 174975, episodes: 7000, mean episode reward: 15.307807421595486, agent episode reward: [-16.883372435435582, 16.095589928515533, 16.095589928515533], time: 127.6
steps: 199975, episodes: 8000, mean episode reward: 15.256008246241596, agent episode reward: [-16.772498733181056, 16.014253489711322, 16.014253489711322], time: 127.672
steps: 224975, episodes: 9000, mean episode reward: 15.131941877417482, agent episode reward: [-16.65043791398954, 15.89118989570351, 15.89118989570351], time: 126.84
steps: 249975, episodes: 10000, mean episode reward: 15.325690790189084, agent episode reward: [-16.792400904209913, 16.0590458471995, 16.0590458471995], time: 126.916
steps: 274975, episodes: 11000, mean episode reward: 15.14630256784684, agent episode reward: [-16.639644433257214, 15.892973500552024, 15.892973500552024], time: 127.396
steps: 299975, episodes: 12000, mean episode reward: 15.056654514093895, agent episode reward: [-16.56742957208104, 15.81204204308747, 15.81204204308747], time: 126.954
steps: 324975, episodes: 13000, mean episode reward: 15.085195015357098, agent episode reward: [-16.56541860672732, 15.825306811042207, 15.825306811042207], time: 127.116
steps: 349975, episodes: 14000, mean episode reward: 15.128238653129886, agent episode reward: [-16.62777539287268, 15.878007023001285, 15.878007023001285], time: 127.472
steps: 374975, episodes: 15000, mean episode reward: 15.348662091677419, agent episode reward: [-16.855767447111052, 16.102214769394234, 16.102214769394234], time: 126.929
steps: 399975, episodes: 16000, mean episode reward: 14.961635057440963, agent episode reward: [-16.46854525943262, 15.71509015843679, 15.71509015843679], time: 127.485
steps: 424975, episodes: 17000, mean episode reward: 15.234320853830914, agent episode reward: [-16.76101595986027, 15.997668406845593, 15.997668406845593], time: 126.953
steps: 449975, episodes: 18000, mean episode reward: 15.391882148208872, agent episode reward: [-16.828251157094833, 16.110066652651852, 16.110066652651852], time: 127.044
steps: 474975, episodes: 19000, mean episode reward: 15.122875600142752, agent episode reward: [-16.5733112598029, 15.848093429972826, 15.848093429972826], time: 126.868
steps: 499975, episodes: 20000, mean episode reward: 15.11356460829101, agent episode reward: [-16.562606781483233, 15.83808569488712, 15.83808569488712], time: 127.06
steps: 524975, episodes: 21000, mean episode reward: 15.083864981123348, agent episode reward: [-16.596590629556893, 15.84022780534012, 15.84022780534012], time: 127.277
steps: 549975, episodes: 22000, mean episode reward: 15.337097174870458, agent episode reward: [-16.825945682170804, 16.08152142852063, 16.08152142852063], time: 127.267
steps: 574975, episodes: 23000, mean episode reward: 15.32015919003474, agent episode reward: [-16.76416674271281, 16.042162966373773, 16.042162966373773], time: 127.362
steps: 599975, episodes: 24000, mean episode reward: 15.184399312015021, agent episode reward: [-16.649978405759416, 15.917188858887217, 15.917188858887217], time: 127.011
steps: 624975, episodes: 25000, mean episode reward: 15.282396016809708, agent episode reward: [-16.726173148773363, 16.004284582791538, 16.004284582791538], time: 126.751
steps: 649975, episodes: 26000, mean episode reward: 15.19047598497368, agent episode reward: [-16.738300005241996, 15.964387995107836, 15.964387995107836], time: 126.552
steps: 674975, episodes: 27000, mean episode reward: 15.194834469977694, agent episode reward: [-16.61978621191821, 15.907310340947951, 15.907310340947951], time: 127.152
steps: 699975, episodes: 28000, mean episode reward: 15.181369009893666, agent episode reward: [-16.657866518859223, 15.919617764376445, 15.919617764376445], time: 127.479
steps: 724975, episodes: 29000, mean episode reward: 15.166778544054367, agent episode reward: [-16.652056631736464, 15.909417587895415, 15.909417587895415], time: 127.006
steps: 749975, episodes: 30000, mean episode reward: 14.933022583292775, agent episode reward: [-16.423241392338802, 15.678131987815787, 15.678131987815787], time: 127.264
steps: 774975, episodes: 31000, mean episode reward: 15.367348041302769, agent episode reward: [-16.83054329065803, 16.0989456659804, 16.0989456659804], time: 127.398
steps: 799975, episodes: 32000, mean episode reward: 15.168678041510203, agent episode reward: [-16.60103997184563, 15.884859006677914, 15.884859006677914], time: 127.31
steps: 824975, episodes: 33000, mean episode reward: 15.168231238849415, agent episode reward: [-16.655552507516084, 15.911891873182748, 15.911891873182748], time: 127.612
steps: 849975, episodes: 34000, mean episode reward: 15.211817867620534, agent episode reward: [-16.681255156935016, 15.946536512277774, 15.946536512277774], time: 126.962
steps: 874975, episodes: 35000, mean episode reward: 15.31415223817213, agent episode reward: [-16.780457485865043, 16.04730486201859, 16.04730486201859], time: 127.572
steps: 899975, episodes: 36000, mean episode reward: 14.966940656396538, agent episode reward: [-16.418691488903193, 15.692816072649867, 15.692816072649867], time: 127.12
steps: 924975, episodes: 37000, mean episode reward: 15.118290626289154, agent episode reward: [-16.564537649683988, 15.841414137986572, 15.841414137986572], time: 127.072
steps: 949975, episodes: 38000, mean episode reward: 15.07096023597909, agent episode reward: [-16.533276948901953, 15.802118592440522, 15.802118592440522], time: 127.071
steps: 974975, episodes: 39000, mean episode reward: 15.165784083681666, agent episode reward: [-16.598823474258612, 15.882303778970142, 15.882303778970142], time: 126.985
steps: 999975, episodes: 40000, mean episode reward: 15.149312476415615, agent episode reward: [-16.605733493064122, 15.877522984739867, 15.877522984739867], time: 127.161
steps: 1024975, episodes: 41000, mean episode reward: 15.70851257085265, agent episode reward: [-17.15624698937784, 16.432379780115248, 16.432379780115248], time: 127.123
steps: 1049975, episodes: 42000, mean episode reward: 15.799326857806752, agent episode reward: [-17.26374289282633, 16.531534875316538, 16.531534875316538], time: 127.026
steps: 1074975, episodes: 43000, mean episode reward: 16.619910760013823, agent episode reward: [-18.058376345273906, 17.339143552643865, 17.339143552643865], time: 127.349
steps: 1099975, episodes: 44000, mean episode reward: 17.543247823391283, agent episode reward: [-19.89529470150148, 18.719271262446384, 18.719271262446384], time: 127.159
steps: 1124975, episodes: 45000, mean episode reward: 15.327045640326146, agent episode reward: [-17.62534156322475, 16.47619360177545, 16.47619360177545], time: 127.139
steps: 1149975, episodes: 46000, mean episode reward: 15.08161125607628, agent episode reward: [-17.2740463617839, 16.17782880893009, 16.17782880893009], time: 127.144
steps: 1174975, episodes: 47000, mean episode reward: 13.621860152479133, agent episode reward: [-18.463499355784325, 16.042679754131733, 16.042679754131733], time: 127.727
steps: 1199975, episodes: 48000, mean episode reward: 13.574447907606187, agent episode reward: [-15.250318408394623, 14.412383158000404, 14.412383158000404], time: 127.723
steps: 1224975, episodes: 49000, mean episode reward: 15.796527336931536, agent episode reward: [-17.318748378079064, 16.557637857505302, 16.557637857505302], time: 127.187
steps: 1249975, episodes: 50000, mean episode reward: 14.947143839333986, agent episode reward: [-17.78065851063662, 16.363901174985305, 16.363901174985305], time: 127.353
steps: 1274975, episodes: 51000, mean episode reward: 12.764084702565826, agent episode reward: [-16.013162018543024, 14.388623360554426, 14.388623360554426], time: 128.092
steps: 1299975, episodes: 52000, mean episode reward: 18.300897755331718, agent episode reward: [-23.813072745991093, 21.05698525066141, 21.05698525066141], time: 127.279
steps: 1324975, episodes: 53000, mean episode reward: 12.012041710668615, agent episode reward: [-15.377128020880923, 13.694584865774768, 13.694584865774768], time: 127.488
steps: 1349975, episodes: 54000, mean episode reward: 13.98571744158427, agent episode reward: [-16.036414192130312, 15.011065816857291, 15.011065816857291], time: 127.52
steps: 1374975, episodes: 55000, mean episode reward: 16.539271593732614, agent episode reward: [-18.275749367172835, 17.40751048045273, 17.40751048045273], time: 127.708
steps: 1399975, episodes: 56000, mean episode reward: 0.9114134093558018, agent episode reward: [-17.697492698912093, 9.304453054133948, 9.304453054133948], time: 127.715
steps: 1424975, episodes: 57000, mean episode reward: 12.939515492985242, agent episode reward: [-18.54104849593423, 15.740281994459735, 15.740281994459735], time: 127.081
steps: 1449975, episodes: 58000, mean episode reward: 16.34673738629143, agent episode reward: [-18.163706299232334, 17.25522184276188, 17.25522184276188], time: 127.344
steps: 1474975, episodes: 59000, mean episode reward: 9.851208420584287, agent episode reward: [-20.33297402509938, 15.092091222841834, 15.092091222841834], time: 128.059
steps: 1499975, episodes: 60000, mean episode reward: 15.45977627975374, agent episode reward: [-16.996195319860714, 16.22798579980723, 16.22798579980723], time: 124.755
...Finished total of 60001 episodes.
