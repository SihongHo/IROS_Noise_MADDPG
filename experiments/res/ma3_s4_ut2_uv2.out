Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  2.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -23.51548448909215, agent episode reward: [-35.27803669564832, 5.881276103278087, 5.881276103278087], time: 84.674
steps: 49975, episodes: 2000, mean episode reward: -21.900145567277935, agent episode reward: [-32.48400872440027, 5.291931578561169, 5.291931578561169], time: 106.253
steps: 74975, episodes: 3000, mean episode reward: -3.839018687233364, agent episode reward: [-12.754235296349087, 4.457608304557862, 4.457608304557862], time: 105.638
steps: 99975, episodes: 4000, mean episode reward: 1.6477482169860322, agent episode reward: [-11.705834747652833, 6.676791482319433, 6.676791482319433], time: 104.906
steps: 124975, episodes: 5000, mean episode reward: 3.441990726310454, agent episode reward: [-10.43979692672393, 6.9408938265171924, 6.9408938265171924], time: 105.803
steps: 149975, episodes: 6000, mean episode reward: 4.232399890745715, agent episode reward: [-10.325534220966766, 7.278967055856241, 7.278967055856241], time: 105.241
steps: 174975, episodes: 7000, mean episode reward: 3.5321088406542276, agent episode reward: [-10.268166758693095, 6.900137799673661, 6.900137799673661], time: 105.749
steps: 199975, episodes: 8000, mean episode reward: 3.7347483675085447, agent episode reward: [-10.79047783527074, 7.262613101389643, 7.262613101389643], time: 105.693
steps: 224975, episodes: 9000, mean episode reward: 3.975306666389122, agent episode reward: [-10.867261973196005, 7.421284319792563, 7.421284319792563], time: 106.176
steps: 249975, episodes: 10000, mean episode reward: 4.0011042997116455, agent episode reward: [-11.648132274505436, 7.824618287108541, 7.824618287108541], time: 105.87
steps: 274975, episodes: 11000, mean episode reward: 3.454294289418892, agent episode reward: [-10.898130344001132, 7.176212316710012, 7.176212316710012], time: 105.506
steps: 299975, episodes: 12000, mean episode reward: 4.301837051845847, agent episode reward: [-12.782864888600008, 8.542350970222927, 8.542350970222927], time: 106.382
steps: 324975, episodes: 13000, mean episode reward: 3.736483112666629, agent episode reward: [-12.132164211892258, 7.934323662279443, 7.934323662279443], time: 105.69
steps: 349975, episodes: 14000, mean episode reward: 2.2255746600178017, agent episode reward: [-12.64049511930619, 7.433034889661995, 7.433034889661995], time: 105.606
steps: 374975, episodes: 15000, mean episode reward: 1.3571836056851814, agent episode reward: [-13.790177058976635, 7.573680332330908, 7.573680332330908], time: 105.934
steps: 399975, episodes: 16000, mean episode reward: 2.3946152528998192, agent episode reward: [-12.902822725368173, 7.648718989133995, 7.648718989133995], time: 105.196
steps: 424975, episodes: 17000, mean episode reward: 1.915642372478876, agent episode reward: [-13.572881104846456, 7.744261738662664, 7.744261738662664], time: 105.941
steps: 449975, episodes: 18000, mean episode reward: 1.2344435092586, agent episode reward: [-13.980619236710245, 7.607531372984424, 7.607531372984424], time: 104.302
steps: 474975, episodes: 19000, mean episode reward: 1.6458611149357534, agent episode reward: [-13.711925199188402, 7.678893157062077, 7.678893157062077], time: 105.708
steps: 499975, episodes: 20000, mean episode reward: 0.7964052114607647, agent episode reward: [-13.6973724991903, 7.246888855325533, 7.246888855325533], time: 105.25
steps: 524975, episodes: 21000, mean episode reward: 0.40403695300277576, agent episode reward: [-12.590606441475934, 6.497321697239355, 6.497321697239355], time: 104.841
steps: 549975, episodes: 22000, mean episode reward: 1.1459677629920157, agent episode reward: [-13.216315154565638, 7.181141458778827, 7.181141458778827], time: 105.189
steps: 574975, episodes: 23000, mean episode reward: 0.8374234724299374, agent episode reward: [-13.530327097646415, 7.183875285038176, 7.183875285038176], time: 104.581
steps: 599975, episodes: 24000, mean episode reward: 0.4455484503178539, agent episode reward: [-15.114971777728956, 7.780260114023403, 7.780260114023403], time: 103.778
steps: 624975, episodes: 25000, mean episode reward: 0.4950948621372389, agent episode reward: [-12.608962429265718, 6.552028645701479, 6.552028645701479], time: 101.914
steps: 649975, episodes: 26000, mean episode reward: 0.2930033521388197, agent episode reward: [-15.142547054074903, 7.717775203106862, 7.717775203106862], time: 100.074
steps: 674975, episodes: 27000, mean episode reward: 0.26112155830566725, agent episode reward: [-14.655233211822829, 7.458177385064248, 7.458177385064248], time: 98.465
steps: 699975, episodes: 28000, mean episode reward: 0.2811284856429311, agent episode reward: [-15.729667129845328, 8.005397807744128, 8.005397807744128], time: 100.21
steps: 724975, episodes: 29000, mean episode reward: -0.8326079361415601, agent episode reward: [-18.203952502353516, 8.685672283105978, 8.685672283105978], time: 99.08
steps: 749975, episodes: 30000, mean episode reward: 0.01935757532348258, agent episode reward: [-15.45878103989468, 7.739069307609082, 7.739069307609082], time: 99.855
steps: 774975, episodes: 31000, mean episode reward: 0.31199212583323604, agent episode reward: [-15.14655359789581, 7.729272861864524, 7.729272861864524], time: 99.701
steps: 799975, episodes: 32000, mean episode reward: -0.11585262414802679, agent episode reward: [-16.06745319202741, 7.9758002839396935, 7.9758002839396935], time: 99.585
steps: 824975, episodes: 33000, mean episode reward: -0.4602766579713725, agent episode reward: [-15.643713119676322, 7.591718230852475, 7.591718230852475], time: 100.17
steps: 849975, episodes: 34000, mean episode reward: -1.977672349393443, agent episode reward: [-13.030192984691938, 5.526260317649249, 5.526260317649249], time: 99.185
steps: 874975, episodes: 35000, mean episode reward: -2.6115986192202936, agent episode reward: [-13.318463060257152, 5.353432220518429, 5.353432220518429], time: 99.098
steps: 899975, episodes: 36000, mean episode reward: -1.9154503612330795, agent episode reward: [-13.516395987628716, 5.8004728131978185, 5.8004728131978185], time: 99.359
steps: 924975, episodes: 37000, mean episode reward: -1.3707374789232192, agent episode reward: [-12.929893928609271, 5.779578224843027, 5.779578224843027], time: 99.055
steps: 949975, episodes: 38000, mean episode reward: -1.9377281191556162, agent episode reward: [-12.828032957800948, 5.445152419322665, 5.445152419322665], time: 99.568
steps: 974975, episodes: 39000, mean episode reward: -1.5700164499703637, agent episode reward: [-14.175165357665904, 6.302574453847769, 6.302574453847769], time: 99.818
steps: 999975, episodes: 40000, mean episode reward: -0.059229004713249794, agent episode reward: [-16.250745998636134, 8.095758496961443, 8.095758496961443], time: 99.073
steps: 1024975, episodes: 41000, mean episode reward: -0.9205430435335707, agent episode reward: [-13.757617147388709, 6.41853705192757, 6.41853705192757], time: 99.983
steps: 1049975, episodes: 42000, mean episode reward: -0.766128416101444, agent episode reward: [-13.289333758272798, 6.261602671085677, 6.261602671085677], time: 100.328
steps: 1074975, episodes: 43000, mean episode reward: 0.0446257938231377, agent episode reward: [-13.138363026747054, 6.591494410285095, 6.591494410285095], time: 100.133
steps: 1099975, episodes: 44000, mean episode reward: -0.3640627267338941, agent episode reward: [-12.021450917175997, 5.828694095221052, 5.828694095221052], time: 100.239
steps: 1124975, episodes: 45000, mean episode reward: -0.5377242107728553, agent episode reward: [-13.078633340183789, 6.270454564705466, 6.270454564705466], time: 100.571
steps: 1149975, episodes: 46000, mean episode reward: -0.2622904106406008, agent episode reward: [-12.455816541675889, 6.096763065517645, 6.096763065517645], time: 99.635
steps: 1174975, episodes: 47000, mean episode reward: -0.4020596174378416, agent episode reward: [-13.354806327710433, 6.476373355136297, 6.476373355136297], time: 99.862
steps: 1199975, episodes: 48000, mean episode reward: -0.4522486176949616, agent episode reward: [-13.28653354989814, 6.417142466101589, 6.417142466101589], time: 101.172
steps: 1224975, episodes: 49000, mean episode reward: 0.5234977591710943, agent episode reward: [-12.576183846607806, 6.54984080288945, 6.54984080288945], time: 99.234
steps: 1249975, episodes: 50000, mean episode reward: 0.5307992312610413, agent episode reward: [-12.932138922586494, 6.7314690769237675, 6.7314690769237675], time: 100.648
steps: 1274975, episodes: 51000, mean episode reward: 0.5099517240772852, agent episode reward: [-13.362352888497634, 6.93615230628746, 6.93615230628746], time: 100.323
steps: 1299975, episodes: 52000, mean episode reward: 1.1918265357401916, agent episode reward: [-12.522591876696744, 6.857209206218466, 6.857209206218466], time: 99.389
steps: 1324975, episodes: 53000, mean episode reward: 1.345560483966217, agent episode reward: [-14.011093717743787, 7.678327100855002, 7.678327100855002], time: 100.735
steps: 1349975, episodes: 54000, mean episode reward: 2.086193087941889, agent episode reward: [-14.121117328294456, 8.103655208118173, 8.103655208118173], time: 99.191
steps: 1374975, episodes: 55000, mean episode reward: 2.5378713770575194, agent episode reward: [-14.144337924297266, 8.341104650677392, 8.341104650677392], time: 99.792
steps: 1399975, episodes: 56000, mean episode reward: 2.1627577755291596, agent episode reward: [-13.730647392944375, 7.946702584236768, 7.946702584236768], time: 99.306
steps: 1424975, episodes: 57000, mean episode reward: 1.9564863037006786, agent episode reward: [-14.211941840340044, 8.084214072020362, 8.084214072020362], time: 100.662
steps: 1449975, episodes: 58000, mean episode reward: 2.4229547022675932, agent episode reward: [-13.07985366743303, 7.751404184850311, 7.751404184850311], time: 98.498
steps: 1474975, episodes: 59000, mean episode reward: 2.2928568185291933, agent episode reward: [-13.080187663575666, 7.686522241052429, 7.686522241052429], time: 96.697
steps: 1499975, episodes: 60000, mean episode reward: 2.2650064056490784, agent episode reward: [-12.577597794756706, 7.421302100202893, 7.421302100202893], time: 74.105
...Finished total of 60001 episodes.
