Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  0.5
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -22.190683106921227, agent episode reward: [-25.021501951324257, 1.4154094222015179, 1.4154094222015179], time: 24.346
steps: 49975, episodes: 2000, mean episode reward: -9.095862510541272, agent episode reward: [-23.615937477347238, 7.260037483402984, 7.260037483402984], time: 44.181
steps: 74975, episodes: 3000, mean episode reward: -2.0879440902300224, agent episode reward: [-1.3621019774604997, -0.3629210563847614, -0.3629210563847614], time: 43.625
steps: 99975, episodes: 4000, mean episode reward: -12.649018370844153, agent episode reward: [-14.853609349034127, 1.1022954890949863, 1.1022954890949863], time: 44.533
steps: 124975, episodes: 5000, mean episode reward: -22.95838479392183, agent episode reward: [-24.823539684420545, 0.9325774452493593, 0.9325774452493593], time: 43.781
steps: 149975, episodes: 6000, mean episode reward: -23.169390891878365, agent episode reward: [-26.027637561410657, 1.4291233347661465, 1.4291233347661465], time: 43.69
steps: 174975, episodes: 7000, mean episode reward: -22.38029763195397, agent episode reward: [-25.720306243956635, 1.6700043060013319, 1.6700043060013319], time: 44.415
steps: 199975, episodes: 8000, mean episode reward: -17.23914088292063, agent episode reward: [-23.82251059867927, 3.2916848578793187, 3.2916848578793187], time: 43.835
steps: 224975, episodes: 9000, mean episode reward: -7.383789332655391, agent episode reward: [-25.25303108422348, 8.934620875784045, 8.934620875784045], time: 44.991
steps: 249975, episodes: 10000, mean episode reward: 11.758957402242363, agent episode reward: [-39.7684838941559, 25.76372064819913, 25.76372064819913], time: 43.999
steps: 274975, episodes: 11000, mean episode reward: 13.454917215929967, agent episode reward: [-21.969901609982504, 17.712409412956234, 17.712409412956234], time: 42.928
steps: 299975, episodes: 12000, mean episode reward: 15.4333293068538, agent episode reward: [-19.461721650951056, 17.447525478902424, 17.447525478902424], time: 43.569
steps: 324975, episodes: 13000, mean episode reward: 14.760077491175064, agent episode reward: [-18.95065000950019, 16.85536375033763, 16.85536375033763], time: 44.123
steps: 349975, episodes: 14000, mean episode reward: 15.555346320374086, agent episode reward: [-20.106145836300367, 17.830746078337228, 17.830746078337228], time: 42.534
steps: 374975, episodes: 15000, mean episode reward: 14.495368482458792, agent episode reward: [-19.877982152273834, 17.186675317366312, 17.186675317366312], time: 42.844
steps: 399975, episodes: 16000, mean episode reward: 15.11666952139257, agent episode reward: [-19.921327395582374, 17.518998458487477, 17.518998458487477], time: 43.226
steps: 424975, episodes: 17000, mean episode reward: 14.288891448859028, agent episode reward: [-19.308897653861976, 16.7988945513605, 16.7988945513605], time: 42.508
steps: 449975, episodes: 18000, mean episode reward: 14.55447175191312, agent episode reward: [-19.594905431405287, 17.0746885916592, 17.0746885916592], time: 42.797
steps: 474975, episodes: 19000, mean episode reward: 14.186487439599503, agent episode reward: [-19.669404778447692, 16.9279461090236, 16.9279461090236], time: 42.873
steps: 499975, episodes: 20000, mean episode reward: 14.049465332318494, agent episode reward: [-19.27792556500868, 16.66369544866359, 16.66369544866359], time: 42.688
steps: 524975, episodes: 21000, mean episode reward: 13.329884411856415, agent episode reward: [-18.371799266772758, 15.850841839314587, 15.850841839314587], time: 43.721
steps: 549975, episodes: 22000, mean episode reward: 14.888282617408688, agent episode reward: [-20.28951509311552, 17.5888988552621, 17.5888988552621], time: 43.887
steps: 574975, episodes: 23000, mean episode reward: 13.646261942219652, agent episode reward: [-19.205614307290876, 16.425938124755262, 16.425938124755262], time: 43.54
steps: 599975, episodes: 24000, mean episode reward: 14.117840748291382, agent episode reward: [-18.983009177762185, 16.550424963026785, 16.550424963026785], time: 44.724
steps: 624975, episodes: 25000, mean episode reward: 14.032286603795804, agent episode reward: [-19.234890160759605, 16.633588382277704, 16.633588382277704], time: 42.811
steps: 649975, episodes: 26000, mean episode reward: 14.176284714387613, agent episode reward: [-19.13362312627759, 16.654953920332602, 16.654953920332602], time: 42.605
steps: 674975, episodes: 27000, mean episode reward: 14.201377588084808, agent episode reward: [-19.031778600097933, 16.616578094091373, 16.616578094091373], time: 42.492
steps: 699975, episodes: 28000, mean episode reward: 14.922946882426158, agent episode reward: [-19.701779558871614, 17.312363220648887, 17.312363220648887], time: 43.721
steps: 724975, episodes: 29000, mean episode reward: 13.778774145280028, agent episode reward: [-18.43919635035753, 16.108985247818783, 16.108985247818783], time: 43.784
steps: 749975, episodes: 30000, mean episode reward: 11.287627647123577, agent episode reward: [-16.9624567724489, 14.125042209786239, 14.125042209786239], time: 43.434
steps: 774975, episodes: 31000, mean episode reward: -2.24820658074773, agent episode reward: [-3.5959343554384446, 0.6738638873453571, 0.6738638873453571], time: 42.721
steps: 799975, episodes: 32000, mean episode reward: -2.6373361715495878, agent episode reward: [-4.754316614889144, 1.058490221669778, 1.058490221669778], time: 43.077
steps: 824975, episodes: 33000, mean episode reward: -2.719729631264501, agent episode reward: [-6.187832732250063, 1.7340515504927807, 1.7340515504927807], time: 42.82
steps: 849975, episodes: 34000, mean episode reward: -5.224182204200648, agent episode reward: [-7.896581968806209, 1.336199882302781, 1.336199882302781], time: 43.298
steps: 874975, episodes: 35000, mean episode reward: -6.124971088443271, agent episode reward: [-9.951422276455995, 1.9132255940063616, 1.9132255940063616], time: 43.237
steps: 899975, episodes: 36000, mean episode reward: -18.179102315579026, agent episode reward: [-22.739249308918232, 2.2800734966696026, 2.2800734966696026], time: 44.129
steps: 924975, episodes: 37000, mean episode reward: -18.89423972926107, agent episode reward: [-29.79775991856637, 5.451760094652651, 5.451760094652651], time: 43.08
steps: 949975, episodes: 38000, mean episode reward: -13.893980590119336, agent episode reward: [-39.34705410254541, 12.726536756213036, 12.726536756213036], time: 43.91
steps: 974975, episodes: 39000, mean episode reward: -9.447659121879742, agent episode reward: [-32.70984004190311, 11.63109046001168, 11.63109046001168], time: 43.182
steps: 999975, episodes: 40000, mean episode reward: -20.25752863808808, agent episode reward: [-24.573845274296378, 2.1581583181041526, 2.1581583181041526], time: 42.7
steps: 1024975, episodes: 41000, mean episode reward: -21.751559484709208, agent episode reward: [-20.207882107593456, -0.7718386885578786, -0.7718386885578786], time: 44.009
steps: 1049975, episodes: 42000, mean episode reward: -19.46383217981623, agent episode reward: [-23.60662414942539, 2.0713959848045786, 2.0713959848045786], time: 45.349
steps: 1074975, episodes: 43000, mean episode reward: -20.37779758177167, agent episode reward: [-23.661109673642468, 1.6416560459353986, 1.6416560459353986], time: 43.933
steps: 1099975, episodes: 44000, mean episode reward: -19.180958951217203, agent episode reward: [-23.55923529246068, 2.1891381706217383, 2.1891381706217383], time: 43.383
steps: 1124975, episodes: 45000, mean episode reward: -22.6023279987921, agent episode reward: [-22.75199445856662, 0.07483322988726096, 0.07483322988726096], time: 43.025
steps: 1149975, episodes: 46000, mean episode reward: -22.56172159288823, agent episode reward: [-24.08259613427437, 0.7604372706930722, 0.7604372706930722], time: 43.117
steps: 1174975, episodes: 47000, mean episode reward: -21.898585221511347, agent episode reward: [-23.053681492534462, 0.5775481355115584, 0.5775481355115584], time: 42.078
steps: 1199975, episodes: 48000, mean episode reward: -21.908218547321916, agent episode reward: [-20.779471971864076, -0.5643732877289199, -0.5643732877289199], time: 43.703
steps: 1224975, episodes: 49000, mean episode reward: -21.989553880233107, agent episode reward: [-22.04548808271869, 0.027967101242792367, 0.027967101242792367], time: 43.169
steps: 1249975, episodes: 50000, mean episode reward: -21.510988314312275, agent episode reward: [-22.49835295104656, 0.4936823183671424, 0.4936823183671424], time: 43.163
steps: 1274975, episodes: 51000, mean episode reward: -21.434670782182344, agent episode reward: [-22.795291538297665, 0.6803103780576601, 0.6803103780576601], time: 42.901
steps: 1299975, episodes: 52000, mean episode reward: -20.685018286908683, agent episode reward: [-22.816294136759105, 1.06563792492521, 1.06563792492521], time: 42.763
steps: 1324975, episodes: 53000, mean episode reward: -20.823058830920456, agent episode reward: [-22.74892759721856, 0.9629343831490517, 0.9629343831490517], time: 43.007
steps: 1349975, episodes: 54000, mean episode reward: -22.353096077722796, agent episode reward: [-21.00873620290618, -0.6721799374083067, -0.6721799374083067], time: 43.528
steps: 1374975, episodes: 55000, mean episode reward: -19.9869227063129, agent episode reward: [-21.901005800614474, 0.9570415471507869, 0.9570415471507869], time: 43.412
steps: 1399975, episodes: 56000, mean episode reward: -20.43763869827155, agent episode reward: [-22.487521912201476, 1.0249416069649622, 1.0249416069649622], time: 42.452
steps: 1424975, episodes: 57000, mean episode reward: -19.908085095218176, agent episode reward: [-22.585689492685173, 1.338802198733501, 1.338802198733501], time: 43.094
steps: 1449975, episodes: 58000, mean episode reward: -19.469516457877862, agent episode reward: [-20.87812880673648, 0.7043061744293095, 0.7043061744293095], time: 43.666
steps: 1474975, episodes: 59000, mean episode reward: -18.190764119248755, agent episode reward: [-22.37319572829928, 2.091215804525266, 2.091215804525266], time: 44.09
steps: 1499975, episodes: 60000, mean episode reward: -19.03137067260742, agent episode reward: [-21.613484616240697, 1.2910569718166398, 1.2910569718166398], time: 42.923
...Finished total of 60001 episodes.
