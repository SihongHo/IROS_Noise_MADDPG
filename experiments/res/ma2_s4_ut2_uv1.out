Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  1.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -21.445061766417375, agent episode reward: [-34.93395371013574, 6.744445971859184, 6.744445971859184], time: 71.449
steps: 49975, episodes: 2000, mean episode reward: -23.597663849216943, agent episode reward: [-37.071346469309475, 6.736841310046264, 6.736841310046264], time: 105.882
steps: 74975, episodes: 3000, mean episode reward: -3.610697122072068, agent episode reward: [-19.30270257106821, 7.846002724498072, 7.846002724498072], time: 105.017
steps: 99975, episodes: 4000, mean episode reward: 3.1036860104652124, agent episode reward: [-17.85000500132985, 10.476845505897531, 10.476845505897531], time: 105.586
steps: 124975, episodes: 5000, mean episode reward: 4.767313528725279, agent episode reward: [-17.086307761641525, 10.926810645183403, 10.926810645183403], time: 104.956
steps: 149975, episodes: 6000, mean episode reward: 5.629170319940077, agent episode reward: [-16.70679769312036, 11.167984006530217, 11.167984006530217], time: 105.1
steps: 174975, episodes: 7000, mean episode reward: 5.156078789841778, agent episode reward: [-16.371699876680218, 10.763889333260998, 10.763889333260998], time: 105.229
steps: 199975, episodes: 8000, mean episode reward: 4.94879218818037, agent episode reward: [-16.524043787450033, 10.736417987815203, 10.736417987815203], time: 105.475
steps: 224975, episodes: 9000, mean episode reward: 4.6063164994571055, agent episode reward: [-16.167127986516583, 10.386722242986846, 10.386722242986846], time: 105.748
steps: 249975, episodes: 10000, mean episode reward: 2.691053794430505, agent episode reward: [-12.590343584181545, 7.640698689306025, 7.640698689306025], time: 105.481
steps: 274975, episodes: 11000, mean episode reward: 1.8692101685434854, agent episode reward: [-12.123089710193614, 6.996149939368551, 6.996149939368551], time: 105.399
steps: 299975, episodes: 12000, mean episode reward: 1.3807961785817793, agent episode reward: [-10.885136461185935, 6.132966319883857, 6.132966319883857], time: 105.875
steps: 324975, episodes: 13000, mean episode reward: 1.744054620747399, agent episode reward: [-10.820432505345106, 6.2822435630462525, 6.2822435630462525], time: 105.057
steps: 349975, episodes: 14000, mean episode reward: 0.9712020966858685, agent episode reward: [-11.15399793811616, 6.062600017401014, 6.062600017401014], time: 105.35
steps: 374975, episodes: 15000, mean episode reward: 1.555731859004311, agent episode reward: [-11.538701741034815, 6.547216800019563, 6.547216800019563], time: 105.885
steps: 399975, episodes: 16000, mean episode reward: 0.6851357983340771, agent episode reward: [-10.664759423129624, 5.67494761073185, 5.67494761073185], time: 105.946
steps: 424975, episodes: 17000, mean episode reward: 0.8828178994512361, agent episode reward: [-12.438119255899657, 6.660468577675447, 6.660468577675447], time: 105.26
steps: 449975, episodes: 18000, mean episode reward: 1.4867702368401035, agent episode reward: [-12.175528567952446, 6.831149402396275, 6.831149402396275], time: 105.567
steps: 474975, episodes: 19000, mean episode reward: 1.2039094284848857, agent episode reward: [-12.090419256164362, 6.647164342324623, 6.647164342324623], time: 105.987
steps: 499975, episodes: 20000, mean episode reward: 1.906069953606771, agent episode reward: [-13.10192691415538, 7.503998433881075, 7.503998433881075], time: 105.695
steps: 524975, episodes: 21000, mean episode reward: 1.8936648539205432, agent episode reward: [-12.892541715632799, 7.393103284776671, 7.393103284776671], time: 104.974
steps: 549975, episodes: 22000, mean episode reward: 1.304149468890139, agent episode reward: [-13.526201663354328, 7.415175566122234, 7.415175566122234], time: 104.599
steps: 574975, episodes: 23000, mean episode reward: 2.383490448932039, agent episode reward: [-13.542880456048227, 7.963185452490135, 7.963185452490135], time: 104.454
steps: 599975, episodes: 24000, mean episode reward: 2.1304107041657434, agent episode reward: [-14.173191204982093, 8.151800954573918, 8.151800954573918], time: 105.045
steps: 624975, episodes: 25000, mean episode reward: 1.3825060423251865, agent episode reward: [-15.476905896382043, 8.429705969353614, 8.429705969353614], time: 102.811
steps: 649975, episodes: 26000, mean episode reward: 0.6595484071693639, agent episode reward: [-13.625831545946722, 7.142689976558044, 7.142689976558044], time: 101.083
steps: 674975, episodes: 27000, mean episode reward: 0.7524554456996217, agent episode reward: [-14.333128383478076, 7.54279191458885, 7.54279191458885], time: 98.726
steps: 699975, episodes: 28000, mean episode reward: 0.41017689054320544, agent episode reward: [-13.649007740396057, 7.029592315469632, 7.029592315469632], time: 99.963
steps: 724975, episodes: 29000, mean episode reward: 0.8601244939572309, agent episode reward: [-14.82456464787753, 7.84234457091738, 7.84234457091738], time: 100.004
steps: 749975, episodes: 30000, mean episode reward: 0.41261595055938854, agent episode reward: [-15.579572639749342, 7.996094295154363, 7.996094295154363], time: 100.267
steps: 774975, episodes: 31000, mean episode reward: -0.42860334387024374, agent episode reward: [-15.825671630285884, 7.69853414320782, 7.69853414320782], time: 99.025
steps: 799975, episodes: 32000, mean episode reward: -0.6603108047646826, agent episode reward: [-14.63179417703344, 6.985741686134378, 6.985741686134378], time: 98.466
steps: 824975, episodes: 33000, mean episode reward: -1.6111317763094861, agent episode reward: [-12.191504301496549, 5.29018626259353, 5.29018626259353], time: 99.651
steps: 849975, episodes: 34000, mean episode reward: -1.4715804521523776, agent episode reward: [-12.795210881358374, 5.661815214602998, 5.661815214602998], time: 99.451
steps: 874975, episodes: 35000, mean episode reward: -2.10540822448149, agent episode reward: [-11.825881014888084, 4.860236395203296, 4.860236395203296], time: 99.233
steps: 899975, episodes: 36000, mean episode reward: -1.4699986399437066, agent episode reward: [-12.940507126763611, 5.735254243409951, 5.735254243409951], time: 99.491
steps: 924975, episodes: 37000, mean episode reward: -1.0796763490152865, agent episode reward: [-13.886637874415056, 6.403480762699885, 6.403480762699885], time: 99.007
steps: 949975, episodes: 38000, mean episode reward: -0.951186761423914, agent episode reward: [-13.632014128574866, 6.340413683575476, 6.340413683575476], time: 100.315
steps: 974975, episodes: 39000, mean episode reward: -2.7268679643328015, agent episode reward: [-13.052255415038843, 5.16269372535302, 5.16269372535302], time: 99.6
steps: 999975, episodes: 40000, mean episode reward: -1.7371341604694057, agent episode reward: [-16.370869921987104, 7.316867880758849, 7.316867880758849], time: 99.198
steps: 1024975, episodes: 41000, mean episode reward: -2.0633407242876207, agent episode reward: [-16.5999145558213, 7.268286915766837, 7.268286915766837], time: 98.823
steps: 1049975, episodes: 42000, mean episode reward: -1.8796451452041523, agent episode reward: [-11.727500496603364, 4.9239276756996055, 4.9239276756996055], time: 99.044
steps: 1074975, episodes: 43000, mean episode reward: -1.1446687747053366, agent episode reward: [-12.843743281777094, 5.849537253535878, 5.849537253535878], time: 99.849
steps: 1099975, episodes: 44000, mean episode reward: -0.8791846970596846, agent episode reward: [-11.732668525738438, 5.4267419143393765, 5.4267419143393765], time: 100.354
steps: 1124975, episodes: 45000, mean episode reward: -1.6854618492475024, agent episode reward: [-11.591250151678853, 4.952894151215675, 4.952894151215675], time: 99.739
steps: 1149975, episodes: 46000, mean episode reward: -1.941676819068851, agent episode reward: [-11.478264650071623, 4.768293915501385, 4.768293915501385], time: 99.573
steps: 1174975, episodes: 47000, mean episode reward: -2.040997198079959, agent episode reward: [-11.340239968025768, 4.649621384972905, 4.649621384972905], time: 98.999
steps: 1199975, episodes: 48000, mean episode reward: -1.2669765713782313, agent episode reward: [-11.76278214724832, 5.247902787935043, 5.247902787935043], time: 100.629
steps: 1224975, episodes: 49000, mean episode reward: -2.04866944985526, agent episode reward: [-11.859560529328737, 4.905445539736738, 4.905445539736738], time: 99.514
steps: 1249975, episodes: 50000, mean episode reward: -2.3627051417801757, agent episode reward: [-12.044408575892717, 4.84085171705627, 4.84085171705627], time: 97.437
steps: 1274975, episodes: 51000, mean episode reward: -1.1666333929224904, agent episode reward: [-11.982952415403728, 5.408159511240617, 5.408159511240617], time: 98.34
steps: 1299975, episodes: 52000, mean episode reward: -1.4115705422973395, agent episode reward: [-12.395272435462084, 5.491850946582373, 5.491850946582373], time: 97.851
steps: 1324975, episodes: 53000, mean episode reward: -2.1351037169950784, agent episode reward: [-11.168402878191182, 4.516649580598052, 4.516649580598052], time: 99.538
steps: 1349975, episodes: 54000, mean episode reward: -2.177967252635162, agent episode reward: [-12.396220691031683, 5.109126719198261, 5.109126719198261], time: 100.399
steps: 1374975, episodes: 55000, mean episode reward: -2.1754364998961657, agent episode reward: [-12.405058775431064, 5.114811137767449, 5.114811137767449], time: 99.029
steps: 1399975, episodes: 56000, mean episode reward: -2.6832301437832977, agent episode reward: [-12.494537447999777, 4.9056536521082394, 4.9056536521082394], time: 99.645
steps: 1424975, episodes: 57000, mean episode reward: -1.925477531620665, agent episode reward: [-12.274396138270644, 5.17445930332499, 5.17445930332499], time: 99.45
steps: 1449975, episodes: 58000, mean episode reward: -2.91747245840346, agent episode reward: [-12.271081754074817, 4.676804647835677, 4.676804647835677], time: 99.65
steps: 1474975, episodes: 59000, mean episode reward: -3.5571365568592603, agent episode reward: [-12.701778742041899, 4.57232109259132, 4.57232109259132], time: 100.389
steps: 1499975, episodes: 60000, mean episode reward: -2.280484830564174, agent episode reward: [-13.113255820887334, 5.416385495161581, 5.416385495161581], time: 97.386
...Finished total of 60001 episodes.
