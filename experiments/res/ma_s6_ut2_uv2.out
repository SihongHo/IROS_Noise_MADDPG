Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  2.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -24.43712423407659, agent episode reward: [-23.99695380065426, -0.22008521671116654, -0.22008521671116654], time: 64.161
steps: 49975, episodes: 2000, mean episode reward: -14.496107876281766, agent episode reward: [-8.70575103680553, -2.895178419738118, -2.895178419738118], time: 108.562
steps: 74975, episodes: 3000, mean episode reward: 0.049033817678204056, agent episode reward: [-3.678648565107432, 1.863841191392818, 1.863841191392818], time: 109.67
steps: 99975, episodes: 4000, mean episode reward: -3.253840900658698, agent episode reward: [-1.6051735318713602, -0.824333684393669, -0.824333684393669], time: 109.296
steps: 124975, episodes: 5000, mean episode reward: -3.731510286244036, agent episode reward: [-2.225454610425223, -0.7530278379094065, -0.7530278379094065], time: 108.813
steps: 149975, episodes: 6000, mean episode reward: -3.383037072697657, agent episode reward: [-2.8456356568715697, -0.2687007079130436, -0.2687007079130436], time: 109.448
steps: 174975, episodes: 7000, mean episode reward: -2.1965354795372654, agent episode reward: [-5.044775839950382, 1.4241201802065584, 1.4241201802065584], time: 109.878
steps: 199975, episodes: 8000, mean episode reward: -3.2853533093934266, agent episode reward: [-3.1800379095504, -0.052657699921513194, -0.052657699921513194], time: 109.566
steps: 224975, episodes: 9000, mean episode reward: -3.7967476219736698, agent episode reward: [-3.2369532103156744, -0.279897205828998, -0.279897205828998], time: 109.997
steps: 249975, episodes: 10000, mean episode reward: -7.249075840646831, agent episode reward: [-9.441759358268264, 1.0963417588107174, 1.0963417588107174], time: 109.649
steps: 274975, episodes: 11000, mean episode reward: -11.825768514835104, agent episode reward: [-13.173471405317901, 0.6738514452413978, 0.6738514452413978], time: 109.293
steps: 299975, episodes: 12000, mean episode reward: -11.491885894176045, agent episode reward: [-14.09317811853027, 1.3006461121771127, 1.3006461121771127], time: 109.605
steps: 324975, episodes: 13000, mean episode reward: -10.875535128466733, agent episode reward: [-13.836843090746992, 1.4806539811401291, 1.4806539811401291], time: 110.31
steps: 349975, episodes: 14000, mean episode reward: -11.102150245487493, agent episode reward: [-18.975047034252356, 3.9364483943824298, 3.9364483943824298], time: 109.816
steps: 374975, episodes: 15000, mean episode reward: -12.185021284708215, agent episode reward: [-19.02907142790338, 3.4220250715975835, 3.4220250715975835], time: 110.021
steps: 399975, episodes: 16000, mean episode reward: -13.056904800893033, agent episode reward: [-20.667906167731456, 3.805500683419211, 3.805500683419211], time: 110.277
steps: 424975, episodes: 17000, mean episode reward: -12.664791104722665, agent episode reward: [-23.03571207885915, 5.185460487068243, 5.185460487068243], time: 110.493
steps: 449975, episodes: 18000, mean episode reward: -9.251776381760767, agent episode reward: [-23.57494522637412, 7.161584422306675, 7.161584422306675], time: 110.805
steps: 474975, episodes: 19000, mean episode reward: -13.47852692326335, agent episode reward: [-24.384959041548584, 5.453216059142617, 5.453216059142617], time: 111.332
steps: 499975, episodes: 20000, mean episode reward: -17.024844384256422, agent episode reward: [-23.209203226180087, 3.0921794209618323, 3.0921794209618323], time: 110.045
steps: 524975, episodes: 21000, mean episode reward: -1.4857146318680945, agent episode reward: [-26.667447757054124, 12.590866562593014, 12.590866562593014], time: 110.158
steps: 549975, episodes: 22000, mean episode reward: 0.2919337309152251, agent episode reward: [-22.713798180323938, 11.502865955619583, 11.502865955619583], time: 111.128
steps: 574975, episodes: 23000, mean episode reward: 0.9150914670705325, agent episode reward: [-17.425243354773194, 9.170167410921861, 9.170167410921861], time: 110.904
steps: 599975, episodes: 24000, mean episode reward: 15.006062348160569, agent episode reward: [-21.382948994416477, 18.194505671288525, 18.194505671288525], time: 111.709
