Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  2.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -24.43712423407659, agent episode reward: [-23.99695380065426, -0.22008521671116654, -0.22008521671116654], time: 64.161
steps: 49975, episodes: 2000, mean episode reward: -14.496107876281766, agent episode reward: [-8.70575103680553, -2.895178419738118, -2.895178419738118], time: 108.562
steps: 74975, episodes: 3000, mean episode reward: 0.049033817678204056, agent episode reward: [-3.678648565107432, 1.863841191392818, 1.863841191392818], time: 109.67
steps: 99975, episodes: 4000, mean episode reward: -3.253840900658698, agent episode reward: [-1.6051735318713602, -0.824333684393669, -0.824333684393669], time: 109.296
steps: 124975, episodes: 5000, mean episode reward: -3.731510286244036, agent episode reward: [-2.225454610425223, -0.7530278379094065, -0.7530278379094065], time: 108.813
steps: 149975, episodes: 6000, mean episode reward: -3.383037072697657, agent episode reward: [-2.8456356568715697, -0.2687007079130436, -0.2687007079130436], time: 109.448
steps: 174975, episodes: 7000, mean episode reward: -2.1965354795372654, agent episode reward: [-5.044775839950382, 1.4241201802065584, 1.4241201802065584], time: 109.878
steps: 199975, episodes: 8000, mean episode reward: -3.2853533093934266, agent episode reward: [-3.1800379095504, -0.052657699921513194, -0.052657699921513194], time: 109.566
steps: 224975, episodes: 9000, mean episode reward: -3.7967476219736698, agent episode reward: [-3.2369532103156744, -0.279897205828998, -0.279897205828998], time: 109.997
steps: 249975, episodes: 10000, mean episode reward: -7.249075840646831, agent episode reward: [-9.441759358268264, 1.0963417588107174, 1.0963417588107174], time: 109.649
steps: 274975, episodes: 11000, mean episode reward: -11.825768514835104, agent episode reward: [-13.173471405317901, 0.6738514452413978, 0.6738514452413978], time: 109.293
steps: 299975, episodes: 12000, mean episode reward: -11.491885894176045, agent episode reward: [-14.09317811853027, 1.3006461121771127, 1.3006461121771127], time: 109.605
steps: 324975, episodes: 13000, mean episode reward: -10.875535128466733, agent episode reward: [-13.836843090746992, 1.4806539811401291, 1.4806539811401291], time: 110.31
steps: 349975, episodes: 14000, mean episode reward: -11.102150245487493, agent episode reward: [-18.975047034252356, 3.9364483943824298, 3.9364483943824298], time: 109.816
steps: 374975, episodes: 15000, mean episode reward: -12.185021284708215, agent episode reward: [-19.02907142790338, 3.4220250715975835, 3.4220250715975835], time: 110.021
steps: 399975, episodes: 16000, mean episode reward: -13.056904800893033, agent episode reward: [-20.667906167731456, 3.805500683419211, 3.805500683419211], time: 110.277
steps: 424975, episodes: 17000, mean episode reward: -12.664791104722665, agent episode reward: [-23.03571207885915, 5.185460487068243, 5.185460487068243], time: 110.493
steps: 449975, episodes: 18000, mean episode reward: -9.251776381760767, agent episode reward: [-23.57494522637412, 7.161584422306675, 7.161584422306675], time: 110.805
steps: 474975, episodes: 19000, mean episode reward: -13.47852692326335, agent episode reward: [-24.384959041548584, 5.453216059142617, 5.453216059142617], time: 111.332
steps: 499975, episodes: 20000, mean episode reward: -17.024844384256422, agent episode reward: [-23.209203226180087, 3.0921794209618323, 3.0921794209618323], time: 110.045
steps: 524975, episodes: 21000, mean episode reward: -1.4857146318680945, agent episode reward: [-26.667447757054124, 12.590866562593014, 12.590866562593014], time: 110.158
steps: 549975, episodes: 22000, mean episode reward: 0.2919337309152251, agent episode reward: [-22.713798180323938, 11.502865955619583, 11.502865955619583], time: 111.128
steps: 574975, episodes: 23000, mean episode reward: 0.9150914670705325, agent episode reward: [-17.425243354773194, 9.170167410921861, 9.170167410921861], time: 110.904
steps: 599975, episodes: 24000, mean episode reward: 15.006062348160569, agent episode reward: [-21.382948994416477, 18.194505671288525, 18.194505671288525], time: 111.709
steps: 624975, episodes: 25000, mean episode reward: 14.341259982454332, agent episode reward: [-19.75869661605708, 17.04997829925571, 17.04997829925571], time: 110.145
steps: 649975, episodes: 26000, mean episode reward: 16.715041535328304, agent episode reward: [-21.089742758203858, 18.902392146766083, 18.902392146766083], time: 110.938
steps: 674975, episodes: 27000, mean episode reward: 15.58533380456392, agent episode reward: [-20.34644103264189, 17.965887418602907, 17.965887418602907], time: 110.91
steps: 699975, episodes: 28000, mean episode reward: 15.291773894184363, agent episode reward: [-21.10639381126851, 18.199083852726435, 18.199083852726435], time: 110.776
steps: 724975, episodes: 29000, mean episode reward: 16.440644183363432, agent episode reward: [-23.77488840681161, 20.107766295087515, 20.107766295087515], time: 110.74
steps: 749975, episodes: 30000, mean episode reward: 14.598781422297337, agent episode reward: [-20.53677193586597, 17.567776679081653, 17.567776679081653], time: 111.186
steps: 774975, episodes: 31000, mean episode reward: 14.950102429225092, agent episode reward: [-21.699543090024093, 18.324822759624592, 18.324822759624592], time: 109.505
steps: 799975, episodes: 32000, mean episode reward: 15.664018983776986, agent episode reward: [-21.178422026412232, 18.421220505094606, 18.421220505094606], time: 109.781
steps: 824975, episodes: 33000, mean episode reward: 14.48356021526162, agent episode reward: [-20.007837401133, 17.24569880819731, 17.24569880819731], time: 109.328
steps: 849975, episodes: 34000, mean episode reward: 14.508369790384736, agent episode reward: [-19.906136532522872, 17.207253161453803, 17.207253161453803], time: 109.973
steps: 874975, episodes: 35000, mean episode reward: 11.910849093096095, agent episode reward: [-20.710278241079358, 16.310563667087727, 16.310563667087727], time: 109.365
steps: 899975, episodes: 36000, mean episode reward: 12.401882291710681, agent episode reward: [-21.116527676969927, 16.759204984340307, 16.759204984340307], time: 109.706
steps: 924975, episodes: 37000, mean episode reward: 9.620803023642427, agent episode reward: [-20.571924708073826, 15.096363865858125, 15.096363865858125], time: 110.375
steps: 949975, episodes: 38000, mean episode reward: 16.999682654048176, agent episode reward: [-23.35215629876987, 20.17591947640902, 20.17591947640902], time: 110.837
steps: 974975, episodes: 39000, mean episode reward: 13.093455724571378, agent episode reward: [-20.71861018628843, 16.906032955429904, 16.906032955429904], time: 109.552
steps: 999975, episodes: 40000, mean episode reward: 10.772176527898917, agent episode reward: [-23.277838980590115, 17.025007754244513, 17.025007754244513], time: 109.624
steps: 1024975, episodes: 41000, mean episode reward: 14.157508608348897, agent episode reward: [-22.04889997769254, 18.103204293020717, 18.103204293020717], time: 109.225
steps: 1049975, episodes: 42000, mean episode reward: 11.328430892547276, agent episode reward: [-23.890738956204544, 17.609584924375913, 17.609584924375913], time: 110.238
steps: 1074975, episodes: 43000, mean episode reward: 15.702304844521457, agent episode reward: [-23.23736030331758, 19.46983257391952, 19.46983257391952], time: 110.07
steps: 1099975, episodes: 44000, mean episode reward: 15.912577777040333, agent episode reward: [-21.91493565253791, 18.91375671478912, 18.91375671478912], time: 110.252
steps: 1124975, episodes: 45000, mean episode reward: 16.35351604267534, agent episode reward: [-24.133625548583883, 20.24357079562961, 20.24357079562961], time: 109.725
steps: 1149975, episodes: 46000, mean episode reward: 19.15772385791865, agent episode reward: [-27.520407645208056, 23.339065751563354, 23.339065751563354], time: 110.266
steps: 1174975, episodes: 47000, mean episode reward: 22.26512936887933, agent episode reward: [-27.235351493047386, 24.75024043096336, 24.75024043096336], time: 110.162
steps: 1199975, episodes: 48000, mean episode reward: 16.88236415247296, agent episode reward: [-23.637613228515278, 20.259988690494122, 20.259988690494122], time: 113.195
steps: 1224975, episodes: 49000, mean episode reward: 14.44209175000393, agent episode reward: [-23.91978142548915, 19.18093658774654, 19.18093658774654], time: 110.635
steps: 1249975, episodes: 50000, mean episode reward: 14.893448638208005, agent episode reward: [-25.0797313064985, 19.986589972353254, 19.986589972353254], time: 110.823
steps: 1274975, episodes: 51000, mean episode reward: 18.327841589024985, agent episode reward: [-24.53501169341773, 21.431426641221353, 21.431426641221353], time: 111.393
steps: 1299975, episodes: 52000, mean episode reward: 19.373972607199903, agent episode reward: [-25.23538309518387, 22.30467785119189, 22.30467785119189], time: 110.689
steps: 1324975, episodes: 53000, mean episode reward: 22.853045128463986, agent episode reward: [-27.839069366066838, 25.346057247265414, 25.346057247265414], time: 110.989
steps: 1349975, episodes: 54000, mean episode reward: 19.97088402132597, agent episode reward: [-26.64876886017594, 23.30982644075095, 23.30982644075095], time: 110.916
steps: 1374975, episodes: 55000, mean episode reward: 21.063048476873636, agent episode reward: [-25.540585752826104, 23.301817114849868, 23.301817114849868], time: 110.928
steps: 1399975, episodes: 56000, mean episode reward: 20.40404332616223, agent episode reward: [-25.31534580740013, 22.859694566781183, 22.859694566781183], time: 110.918
steps: 1424975, episodes: 57000, mean episode reward: 17.56507373063097, agent episode reward: [-22.404460540419628, 19.984767135525296, 19.984767135525296], time: 111.48
steps: 1449975, episodes: 58000, mean episode reward: 20.028147055068246, agent episode reward: [-24.39452252392206, 22.211334789495154, 22.211334789495154], time: 112.195
steps: 1474975, episodes: 59000, mean episode reward: 20.234522452316522, agent episode reward: [-24.7106807925433, 22.47260162242991, 22.47260162242991], time: 112.856
steps: 1499975, episodes: 60000, mean episode reward: 18.568026285806123, agent episode reward: [-22.911963045901736, 20.739994665853935, 20.739994665853935], time: 111.159
...Finished total of 60001 episodes.
