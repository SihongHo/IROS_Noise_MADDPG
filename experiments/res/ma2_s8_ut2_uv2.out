Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  2.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -40.95379486388536, agent episode reward: [0.8171907420967134, 0.8179959813112453, 0.89079135212906, 0.88919699877822, -16.05392187573928, -28.31504806246132], time: 204.296
steps: 49975, episodes: 2000, mean episode reward: -25.60128356259966, agent episode reward: [2.7309631640656487, 2.3734073577171326, 3.0939470927930106, 2.9396478317381196, -23.514444439219332, -13.224804569694244], time: 318.197
steps: 74975, episodes: 3000, mean episode reward: 15.822868791420472, agent episode reward: [5.618172605585021, 4.555723348830296, 6.074889731534959, 5.634074063291495, -3.4895762760168316, -2.5704146818044635], time: 321.242
steps: 99975, episodes: 4000, mean episode reward: 13.99966755428989, agent episode reward: [4.807581197542852, 4.290093344324117, 5.263376001112819, 4.953453605837762, -2.77877117171537, -2.536065422812294], time: 325.299
steps: 124975, episodes: 5000, mean episode reward: 16.49076242455846, agent episode reward: [5.279335094676568, 5.153311998012939, 5.678586455477027, 5.722035453417071, -2.4661314192902974, -2.876375157734843], time: 327.637
steps: 149975, episodes: 6000, mean episode reward: 21.195267936377252, agent episode reward: [6.992604213517763, 6.936511600842043, 7.20052112914476, 7.382441280371684, -3.9438861017027653, -3.3729241857962307], time: 327.239
steps: 174975, episodes: 7000, mean episode reward: 23.381520574669818, agent episode reward: [7.281518478409478, 7.6231014379024895, 7.755058544721125, 7.901576294221444, -3.3581324283936875, -3.8216017521910306], time: 329.338
steps: 199975, episodes: 8000, mean episode reward: 29.18159552920636, agent episode reward: [9.307955636930648, 9.409561053979765, 9.760834000680902, 9.80637803605169, -4.032042751491834, -5.071090446944811], time: 327.517
steps: 224975, episodes: 9000, mean episode reward: 35.81339493835579, agent episode reward: [11.669463957375, 11.618129961692546, 12.061318217234223, 12.067322165031594, -5.477528212853789, -6.125311150123784], time: 330.296
steps: 249975, episodes: 10000, mean episode reward: 39.38890411485564, agent episode reward: [12.687496747712855, 12.713283460647322, 13.174783057594324, 13.079639490828457, -6.226143561356397, -6.040155080570914], time: 326.45
steps: 274975, episodes: 11000, mean episode reward: 48.01825790653519, agent episode reward: [15.818997440298482, 15.651181147689819, 16.063469963874073, 15.940844861747914, -7.2322131230769395, -8.22402238399816], time: 326.092
steps: 299975, episodes: 12000, mean episode reward: 43.71027766112046, agent episode reward: [14.412237431293988, 14.230116227573232, 14.41376102230081, 14.259550039364244, -7.461675451212348, -6.143711608199465], time: 329.109
steps: 324975, episodes: 13000, mean episode reward: 46.623565067174326, agent episode reward: [15.407025668364527, 15.223754985721486, 15.298384357948315, 15.287520926899061, -7.635755491118282, -6.9573653806407805], time: 327.848
steps: 349975, episodes: 14000, mean episode reward: 40.34260887252367, agent episode reward: [13.41944729522186, 13.327100874226264, 13.39534936039974, 13.28255807748355, -7.108697847933488, -5.973148886874256], time: 326.156
steps: 374975, episodes: 15000, mean episode reward: 39.96918188309382, agent episode reward: [13.192941296187072, 13.129832278925399, 13.064753844339698, 13.156327622018656, -6.099494407345917, -6.475178751031083], time: 329.505
steps: 399975, episodes: 16000, mean episode reward: 37.08503524609154, agent episode reward: [12.46206279847715, 12.42246840670372, 12.412531429659703, 12.482374288040196, -5.802722274038397, -6.891679402750824], time: 330.538
steps: 424975, episodes: 17000, mean episode reward: 39.32210391791724, agent episode reward: [13.280509558140247, 13.317444957405508, 13.315687315162595, 13.247772622367211, -5.640444358457885, -8.198866176700434], time: 331.662
steps: 449975, episodes: 18000, mean episode reward: 36.81844621381927, agent episode reward: [12.91355890405569, 12.963631828909298, 13.006800630261301, 12.89596566876389, -5.831869567790688, -9.129641250380224], time: 327.716
steps: 474975, episodes: 19000, mean episode reward: 42.877040769861516, agent episode reward: [14.515753078872741, 14.520034551926935, 14.550013658426636, 14.499206938891653, -5.42732636183346, -9.780641096422992], time: 329.978
steps: 499975, episodes: 20000, mean episode reward: 37.019925381659064, agent episode reward: [12.285710734176888, 12.327777084381436, 12.400581769885688, 12.286326814556402, -4.209139993454661, -8.07133102788669], time: 328.306
steps: 524975, episodes: 21000, mean episode reward: 38.41501737347863, agent episode reward: [12.966198450108159, 12.96180584013489, 13.022638883047598, 12.966808066540016, -5.087197060119848, -8.415236806232173], time: 328.364
steps: 549975, episodes: 22000, mean episode reward: 34.46961365720117, agent episode reward: [11.703609849310464, 11.679895273612509, 11.730805485565817, 11.680973648584164, -3.700983776365604, -8.62468682350617], time: 329.833
steps: 574975, episodes: 23000, mean episode reward: 37.11979450482313, agent episode reward: [12.803839470054609, 12.748522621178623, 12.815947877833153, 12.763467695685955, -5.0379189378677, -8.974064222061502], time: 330.678
steps: 599975, episodes: 24000, mean episode reward: 34.4603368445538, agent episode reward: [12.374693829018987, 12.166240756179183, 12.346883923703663, 12.33718860589481, -5.315376003483764, -9.449294266759075], time: 331.504
steps: 624975, episodes: 25000, mean episode reward: 26.636695704820625, agent episode reward: [11.059730344595705, 10.82375617005845, 10.965380270414965, 11.001302696416289, -5.934284863729913, -11.27918891293487], time: 326.041
steps: 649975, episodes: 26000, mean episode reward: 30.76105608364792, agent episode reward: [11.487106284277845, 11.279586396335107, 11.43695200962468, 11.460227325953214, -6.026763531148748, -8.876052401394174], time: 326.524
steps: 674975, episodes: 27000, mean episode reward: 16.86372838626483, agent episode reward: [8.080479148975725, 7.889226605514932, 7.993479558936639, 7.974612813660155, -9.044796985389365, -6.029272755433254], time: 327.424
steps: 699975, episodes: 28000, mean episode reward: 19.113083085103913, agent episode reward: [8.103172868892825, 7.9598771845254195, 7.9866758706677485, 7.978019419116362, -6.307153018720779, -6.607509239377661], time: 326.0
steps: 724975, episodes: 29000, mean episode reward: 24.451114018349006, agent episode reward: [9.590098267444551, 9.44687539284947, 9.466089056192523, 9.47906566976562, -6.510445693037871, -7.020568674865286], time: 319.629
steps: 749975, episodes: 30000, mean episode reward: 33.504490973503884, agent episode reward: [12.295275616749871, 12.196358047183127, 12.184709484063317, 12.183078111643285, -6.703718025573101, -8.651212260562612], time: 318.676
steps: 774975, episodes: 31000, mean episode reward: 31.267399141304296, agent episode reward: [11.717009966050995, 11.661061014941021, 11.652163771004746, 11.617110954179141, -7.799603998928044, -7.580342565943566], time: 316.632
steps: 799975, episodes: 32000, mean episode reward: 30.41398315454932, agent episode reward: [11.431986568941257, 11.361254892638813, 11.348252724753172, 11.383345467378229, -7.585213159918355, -7.525643339243794], time: 317.236
steps: 824975, episodes: 33000, mean episode reward: 28.496924769182158, agent episode reward: [10.647967997928264, 10.644346876406173, 10.66156820217711, 10.634907333624792, -6.623071767197288, -7.468793873756895], time: 316.879
steps: 849975, episodes: 34000, mean episode reward: 35.66103398675948, agent episode reward: [12.93200030129174, 12.901359703456954, 12.904932255485033, 12.90703269861181, -7.402507532320118, -8.581783439765942], time: 318.271
steps: 874975, episodes: 35000, mean episode reward: 32.02207590275698, agent episode reward: [11.535509689620161, 11.496476938506563, 11.503817747614134, 11.547080671192893, -6.4499383805690345, -7.610870763607742], time: 317.084
steps: 899975, episodes: 36000, mean episode reward: 36.577066729647385, agent episode reward: [13.18453536145051, 13.219981114269135, 13.24511338133892, 13.233397602135959, -6.460310730223443, -9.845649999323703], time: 318.257
steps: 924975, episodes: 37000, mean episode reward: 41.652896611527915, agent episode reward: [14.422688395346384, 14.431568877340633, 14.382688222793197, 14.39664292295721, -6.491005971778429, -9.489685835131073], time: 318.907
steps: 949975, episodes: 38000, mean episode reward: 42.898363452810635, agent episode reward: [15.070903867098586, 15.098511033067007, 14.991283135742991, 15.091758203740687, -6.936129030710197, -10.417963756128431], time: 317.016
steps: 974975, episodes: 39000, mean episode reward: 41.390858538918955, agent episode reward: [14.333155577219717, 14.361329015884975, 14.160362143650971, 14.27393414749661, -6.088330027335334, -9.649592317997984], time: 316.585
steps: 999975, episodes: 40000, mean episode reward: 42.171437683660294, agent episode reward: [14.316569365955536, 14.571712308736545, 14.345876126900688, 14.526241659799801, -4.447544211381424, -11.141417566350858], time: 317.921
steps: 1024975, episodes: 41000, mean episode reward: 43.34791261446153, agent episode reward: [14.53961912678364, 14.792409075940169, 14.650609582926602, 14.803832310456412, -4.455041299499877, -10.98351618214542], time: 316.844
steps: 1049975, episodes: 42000, mean episode reward: 29.531135003890594, agent episode reward: [10.818724851374252, 10.98036694765939, 10.77383663472045, 11.008245280489716, -4.9723518131927715, -9.077686897160442], time: 315.844
steps: 1074975, episodes: 43000, mean episode reward: 24.291079619411814, agent episode reward: [9.679171524517223, 9.69016041541373, 9.325841115099, 9.78006068273732, -4.597730192906038, -9.586423925449424], time: 315.498
steps: 1099975, episodes: 44000, mean episode reward: 16.21172744068457, agent episode reward: [8.136038734441215, 7.983586902885874, 8.020932920284249, 7.988651261902425, -3.6183330621498624, -12.299149316679333], time: 318.085
steps: 1124975, episodes: 45000, mean episode reward: 15.384766301702816, agent episode reward: [8.312938068603952, 8.108458958318378, 8.122021735747476, 8.28553860568509, -4.483251707714851, -12.960939358937226], time: 316.508
steps: 1149975, episodes: 46000, mean episode reward: 14.340715270725621, agent episode reward: [7.439790387211529, 7.381206166092836, 7.3394176387385235, 7.358155168172791, -3.647510741649316, -11.530343347840743], time: 314.972
steps: 1174975, episodes: 47000, mean episode reward: 13.564631172795744, agent episode reward: [6.797843810384513, 6.649578321717136, 6.607764510839544, 6.676062037361664, -3.784652423187488, -9.381965084319624], time: 318.241
steps: 1199975, episodes: 48000, mean episode reward: 22.85444804424511, agent episode reward: [8.372622123792462, 8.159172120836015, 8.189346617572607, 8.038821567971953, -3.6723177502735247, -6.233196635654399], time: 315.334
steps: 1224975, episodes: 49000, mean episode reward: 20.947250917689445, agent episode reward: [7.782929842592084, 7.507889353029644, 7.563708905628408, 7.56052361614568, -3.196783836710551, -6.271016962995822], time: 315.753
steps: 1249975, episodes: 50000, mean episode reward: 23.190889508486215, agent episode reward: [8.512643896575941, 8.382313293033931, 8.325713338392125, 8.422913566716714, -3.5966693577514333, -6.8560252284810606], time: 314.197
steps: 1274975, episodes: 51000, mean episode reward: 23.354625474892718, agent episode reward: [8.38513226010089, 8.349287419592354, 8.2340825185502, 8.371658638537513, -3.5230033879009497, -6.462531973987289], time: 314.748
steps: 1299975, episodes: 52000, mean episode reward: 26.4940054500418, agent episode reward: [9.499182298578187, 9.486184565306301, 9.40734633469534, 9.489361489208534, -3.4967939166163378, -7.891275321130221], time: 314.03
steps: 1324975, episodes: 53000, mean episode reward: 26.134746811878532, agent episode reward: [9.427005443853112, 9.333566873709094, 9.216837712340824, 9.361390978938564, -2.994252979292244, -8.209801217670814], time: 315.895
steps: 1349975, episodes: 54000, mean episode reward: 29.888311439513235, agent episode reward: [10.435621068113601, 10.267754843834519, 10.258953827259225, 10.459667790063715, -3.5177003941571616, -8.015985695600664], time: 313.907
steps: 1374975, episodes: 55000, mean episode reward: 32.49906175236322, agent episode reward: [11.0288389236043, 10.96735366863872, 10.86611942826398, 11.101907509226471, -2.463483324024269, -9.001674453345986], time: 312.261
steps: 1399975, episodes: 56000, mean episode reward: 35.37235220519202, agent episode reward: [11.910731450209678, 11.934948163091217, 11.832430573457158, 12.076766509659123, -3.073752954722796, -9.308771536502357], time: 312.431
steps: 1424975, episodes: 57000, mean episode reward: 34.08556564882617, agent episode reward: [11.606739947142916, 11.631072866682237, 11.50938115697025, 11.74464186482805, -3.5294822478357664, -8.876787938961515], time: 312.892
steps: 1449975, episodes: 58000, mean episode reward: 38.06019143261807, agent episode reward: [12.78307191950995, 12.636935293724695, 12.55870454628813, 12.889371167915682, -3.3163135122477216, -9.491577982572663], time: 315.108
steps: 1474975, episodes: 59000, mean episode reward: 36.823098274693486, agent episode reward: [12.49197656715136, 12.352922011634517, 12.271426085952417, 12.524576372922619, -3.6149827373219052, -9.20282002564552], time: 312.664
steps: 1499975, episodes: 60000, mean episode reward: 36.66648781753704, agent episode reward: [12.49418102309068, 12.299333085808904, 12.255999864078166, 12.530765907469657, -3.4696160477808635, -9.444176015129504], time: 314.917
...Finished total of 60001 episodes.
