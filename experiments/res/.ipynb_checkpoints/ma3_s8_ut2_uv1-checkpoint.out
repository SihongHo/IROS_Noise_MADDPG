Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  1.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -32.02694183370918, agent episode reward: [0.9297663723177024, 0.9824091840306935, 1.0185549366725009, 1.0484087199685697, -14.296471354241977, -21.70960969245667], time: 192.237
steps: 49975, episodes: 2000, mean episode reward: -28.63223416629766, agent episode reward: [2.6627466757149576, 2.9033243654896768, 2.5509360823994864, 3.0441224962567124, -28.179587626430415, -11.613776159728074], time: 319.276
steps: 74975, episodes: 3000, mean episode reward: 10.74654138936539, agent episode reward: [4.129471855672871, 4.227551762355339, 3.7497571173974276, 4.162539621737485, -2.2659534203480725, -3.2568255474496612], time: 321.726
steps: 99975, episodes: 4000, mean episode reward: 14.870266649795008, agent episode reward: [5.287619579004352, 5.164949310640159, 5.3167236104928595, 5.15615349509881, -2.8857076926640413, -3.1694716527771307], time: 327.471
steps: 124975, episodes: 5000, mean episode reward: 18.97220998868975, agent episode reward: [6.428244334620287, 6.321650254686973, 6.472470524224673, 6.33177732584959, -3.2159420481073036, -3.365990402584465], time: 327.468
steps: 149975, episodes: 6000, mean episode reward: 24.871327515613345, agent episode reward: [8.014635192637519, 8.084935826188312, 8.360925568449359, 8.21249224813678, -3.891592265123799, -3.9100690546748242], time: 327.517
steps: 174975, episodes: 7000, mean episode reward: 25.395310711154313, agent episode reward: [8.25823926562383, 8.113894574184929, 8.471862551020251, 8.30469210410499, -3.876615991402101, -3.876761792377584], time: 327.892
steps: 199975, episodes: 8000, mean episode reward: 29.3847545490134, agent episode reward: [9.531745842188702, 9.610008476595555, 9.743386588591337, 9.649530216542816, -5.138349763416266, -4.011566811488741], time: 327.478
steps: 224975, episodes: 9000, mean episode reward: 31.213465262481847, agent episode reward: [10.214978458993635, 10.162841946719578, 10.30842751940327, 10.190440816487946, -5.714056942564852, -3.949166536557734], time: 330.464
steps: 249975, episodes: 10000, mean episode reward: 31.053266581612036, agent episode reward: [10.246617754178027, 10.314245073824098, 10.351903590698466, 10.17893111200371, -6.133904725075005, -3.904526224017262], time: 329.528
steps: 274975, episodes: 11000, mean episode reward: 40.68628710246146, agent episode reward: [13.213321116255631, 13.303468542254766, 13.277047966900815, 13.2851831956041, -7.588676154098445, -4.8040575644554036], time: 328.971
steps: 299975, episodes: 12000, mean episode reward: 42.312632953761934, agent episode reward: [13.827683867192231, 13.8382000476319, 13.835050429079285, 13.828176243307004, -7.353712349582749, -5.66276528386574], time: 330.674
steps: 324975, episodes: 13000, mean episode reward: 36.14745441554929, agent episode reward: [11.7687551379676, 11.758798957810136, 11.757759753436455, 11.77909070657018, -6.325644754106721, -4.591305386128355], time: 330.39
steps: 349975, episodes: 14000, mean episode reward: 38.725949113201466, agent episode reward: [12.697192300108146, 12.700192609594367, 12.687691007506693, 12.715647220112395, -7.050750783112077, -5.024023241008047], time: 328.548
steps: 374975, episodes: 15000, mean episode reward: 37.60254649753095, agent episode reward: [12.63675031595217, 12.56591006902668, 12.561034152336754, 12.540701653106138, -7.9777727068344735, -4.724076986056321], time: 329.152
steps: 399975, episodes: 16000, mean episode reward: 37.26431746552268, agent episode reward: [12.375066098562463, 12.330529161183499, 12.335268242568459, 12.318412421194328, -6.654206253377554, -5.4407522046085095], time: 328.511
steps: 424975, episodes: 17000, mean episode reward: 33.52077376219007, agent episode reward: [11.13508355487774, 11.135272258667861, 11.106572416330602, 11.093290401952599, -6.13976118491408, -4.809683684724653], time: 328.377
steps: 449975, episodes: 18000, mean episode reward: 30.323733122692545, agent episode reward: [10.276025069118626, 10.219514896205627, 10.150158107323149, 10.175147087043042, -6.300488834179283, -4.19662320281862], time: 329.754
steps: 474975, episodes: 19000, mean episode reward: 26.80151522613968, agent episode reward: [9.029276095158835, 8.972376339592754, 8.978075118841176, 8.992722233515272, -5.494771475558902, -3.676163085409452], time: 330.64
steps: 499975, episodes: 20000, mean episode reward: 22.197013639592285, agent episode reward: [7.890501659561095, 7.79604408224896, 7.846665420349909, 7.828503999030066, -4.890569626811377, -4.274131894786367], time: 330.185
steps: 524975, episodes: 21000, mean episode reward: 23.58557910142007, agent episode reward: [8.468423906756955, 8.303698948308003, 8.343520968382782, 8.378307864317682, -6.496134419710224, -3.4122381666351274], time: 327.567
steps: 549975, episodes: 22000, mean episode reward: 21.683945335999336, agent episode reward: [8.274198235683132, 8.144237443887327, 8.203514402351685, 8.115045261351733, -6.194989222415206, -4.858060784859337], time: 333.513
steps: 574975, episodes: 23000, mean episode reward: 24.334416083901903, agent episode reward: [8.674913393332307, 8.589970571624754, 8.580551136254005, 8.538317216313317, -5.433026958042463, -4.616309275580013], time: 329.709
steps: 599975, episodes: 24000, mean episode reward: 21.49260109856349, agent episode reward: [8.167051348979745, 8.049211237562327, 8.0397338585545, 8.044417880743396, -6.755725406533431, -4.05208782074305], time: 332.151
steps: 624975, episodes: 25000, mean episode reward: 21.270614444341366, agent episode reward: [8.390060190341378, 8.3187329630201, 8.304058876526325, 8.243241437812248, -7.373131444041607, -4.612347579317086], time: 330.089
steps: 649975, episodes: 26000, mean episode reward: 22.25304303532398, agent episode reward: [8.615261540238647, 8.512989613095938, 8.446395161610846, 8.414589854817951, -7.976602329997771, -3.7595908044416273], time: 326.406
steps: 674975, episodes: 27000, mean episode reward: 28.38290363549461, agent episode reward: [10.102044480112498, 9.967373250225593, 9.94727518176099, 9.896041565094402, -7.288575390621686, -4.2412554510771905], time: 327.942
steps: 699975, episodes: 28000, mean episode reward: 22.59235627848057, agent episode reward: [8.540561843136562, 8.442447275174116, 8.46051728798265, 8.431444096513651, -6.743197716891406, -4.539416507435002], time: 326.925
steps: 724975, episodes: 29000, mean episode reward: 25.922145380570758, agent episode reward: [9.074215503736221, 9.00717375685001, 9.072723774552657, 8.978555372066559, -7.087770271670941, -3.12275275496375], time: 319.832
steps: 749975, episodes: 30000, mean episode reward: 22.37167188017635, agent episode reward: [8.122663546596566, 8.070217203573934, 8.126638239174723, 8.07291260882113, -6.798907011896389, -3.221852706093617], time: 318.907
steps: 774975, episodes: 31000, mean episode reward: 28.938588509779116, agent episode reward: [10.341176374019993, 10.149920364865643, 10.162169626274576, 10.172833168314396, -8.51208261728863, -3.375428406406862], time: 319.094
steps: 799975, episodes: 32000, mean episode reward: 27.724117443638463, agent episode reward: [10.253109544031311, 10.00600993670032, 10.072924580570707, 10.07379381035516, -9.0863965354656, -3.5953238925534343], time: 319.091
steps: 824975, episodes: 33000, mean episode reward: 26.481385673265475, agent episode reward: [9.940693382551748, 9.740202185237194, 9.83824763360637, 9.677146584420552, -9.037161491476018, -3.6777426210743753], time: 317.589
steps: 849975, episodes: 34000, mean episode reward: 29.30978346988601, agent episode reward: [10.57836643959151, 10.316891290503209, 10.415927970650438, 10.293277916782547, -8.697325836927027, -3.5973543107146684], time: 319.205
steps: 874975, episodes: 35000, mean episode reward: 28.725372173470454, agent episode reward: [10.616553842605184, 10.39810871522236, 10.517612482860748, 10.453005112799657, -9.443890244677288, -3.8160177353402043], time: 319.052
steps: 899975, episodes: 36000, mean episode reward: 36.00158206812547, agent episode reward: [12.798723664147204, 12.39294986024749, 12.656214289579053, 12.534698444739524, -9.846692694840945, -4.5343114957468496], time: 320.483
steps: 924975, episodes: 37000, mean episode reward: 32.895996630363754, agent episode reward: [11.269414628454866, 11.135794928739177, 11.259217776458636, 11.189960704337159, -7.929395592028985, -4.028995815597098], time: 319.778
steps: 949975, episodes: 38000, mean episode reward: 35.8992530422769, agent episode reward: [12.392015694746288, 12.080612872092253, 12.221005012019836, 12.136631498477975, -8.75206215867409, -4.1789498763853645], time: 318.185
steps: 974975, episodes: 39000, mean episode reward: 31.006473955590867, agent episode reward: [10.688520611058864, 10.404941084364724, 10.577332574364476, 10.484598692435638, -7.48256569168809, -3.6663533149447503], time: 318.221
steps: 999975, episodes: 40000, mean episode reward: 36.359544688463735, agent episode reward: [12.658958396030624, 12.33160163469424, 12.479927945399707, 12.344417494123919, -9.47125522197082, -3.984105559813927], time: 318.32
steps: 1024975, episodes: 41000, mean episode reward: 38.5205633180006, agent episode reward: [13.331231770876334, 12.885933573818631, 13.072444929668876, 13.000995582720904, -9.63453371516291, -4.1355088239212465], time: 315.755
steps: 1049975, episodes: 42000, mean episode reward: 34.10780233339939, agent episode reward: [12.78329305755944, 12.279223680463224, 12.523164004686084, 12.368230131421601, -10.606280718986062, -5.239827821744901], time: 315.282
steps: 1074975, episodes: 43000, mean episode reward: 28.09166782789988, agent episode reward: [12.290547937838765, 11.834056083677249, 12.021946898965037, 11.807905060243433, -12.646308823615552, -7.216479329209048], time: 315.533
steps: 1099975, episodes: 44000, mean episode reward: 38.071368461571346, agent episode reward: [14.340872481169477, 13.8049475999727, 14.072906358300687, 13.888211883520292, -12.765105987585171, -5.2704638738066425], time: 317.371
steps: 1124975, episodes: 45000, mean episode reward: 34.956428405182336, agent episode reward: [12.906503930274553, 12.35153201029344, 12.648038671309711, 12.336466456058288, -10.42758130407642, -4.8585313586772445], time: 316.812
steps: 1149975, episodes: 46000, mean episode reward: 36.49405937145553, agent episode reward: [13.271778552681026, 12.668222839221528, 13.013485764321901, 12.751054473702442, -10.23837818227191, -4.972104076199461], time: 316.379
steps: 1174975, episodes: 47000, mean episode reward: 29.958813685977375, agent episode reward: [11.110639947958793, 10.4210071126342, 10.80183740073656, 10.49726462716205, -9.212014667423857, -3.659920735090372], time: 318.945
steps: 1199975, episodes: 48000, mean episode reward: 29.58491708245236, agent episode reward: [11.11735280624853, 10.513640508054156, 10.810090962706381, 10.556864066352192, -8.98751963014026, -4.425511630768635], time: 317.896
steps: 1224975, episodes: 49000, mean episode reward: 27.204070173345286, agent episode reward: [10.395843909811173, 9.796415013206492, 10.112178301888033, 9.85787658101696, -8.63613611486317, -4.322107517714203], time: 318.842
steps: 1249975, episodes: 50000, mean episode reward: 26.691509861232802, agent episode reward: [10.890443002938124, 10.11535908347274, 10.44424353253536, 10.370548326525093, -11.023853990598175, -4.105230093640338], time: 317.01
steps: 1274975, episodes: 51000, mean episode reward: 29.381198472739946, agent episode reward: [11.131699097633769, 10.388556656431115, 10.811522486046803, 10.689460012576852, -9.468542888428612, -4.17149689151998], time: 315.473
steps: 1299975, episodes: 52000, mean episode reward: 32.25825435840458, agent episode reward: [11.783202160077893, 11.150434429945665, 11.368210030054918, 11.291087245190115, -9.437249679636793, -3.8974298272272216], time: 314.7
steps: 1324975, episodes: 53000, mean episode reward: 31.572083621556537, agent episode reward: [11.43327892506174, 10.870929955058934, 10.895390227185528, 10.8766162790464, -8.988913864401916, -3.5152179003941484], time: 315.641
steps: 1349975, episodes: 54000, mean episode reward: 31.790162956427295, agent episode reward: [11.33457246257496, 10.810789243467003, 10.945506027101164, 10.847668437417942, -8.388743936110696, -3.7596292780230742], time: 314.377
steps: 1374975, episodes: 55000, mean episode reward: 32.70482599339552, agent episode reward: [11.833558359828315, 11.299618408509055, 11.359938428578474, 11.389590023766912, -9.489527497411226, -3.68835172987601], time: 311.49
steps: 1399975, episodes: 56000, mean episode reward: 34.773749573417135, agent episode reward: [12.16296936876788, 11.654434756580704, 11.729312869805442, 11.784391962999461, -9.495428878142091, -3.061930506594273], time: 314.982
steps: 1424975, episodes: 57000, mean episode reward: 36.387258631713095, agent episode reward: [12.898491372008701, 12.33722266520785, 12.399144179705981, 12.442689082014136, -9.391155939494666, -4.299132727728911], time: 313.965
steps: 1449975, episodes: 58000, mean episode reward: 37.40102162962908, agent episode reward: [13.091006251687189, 12.662579349619085, 12.659689248940687, 12.529704000541475, -9.594456281463296, -3.9475009396960656], time: 314.371
steps: 1474975, episodes: 59000, mean episode reward: 36.01538400451689, agent episode reward: [12.67304388125355, 12.27386600221845, 12.332240483887352, 12.36782163045195, -9.613174281034759, -4.018413712259643], time: 313.599
steps: 1499975, episodes: 60000, mean episode reward: 36.50267030551462, agent episode reward: [12.704720257466287, 12.233128032356941, 12.3283523028316, 12.252677103587546, -9.435530055093484, -3.58067733563427], time: 310.402
...Finished total of 60001 episodes.
