Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  0.5
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -35.05510970594861, agent episode reward: [0.9448145563946668, 0.92754668867032, 0.9336791095453364, 0.9830717357480017, -23.620509676977274, -15.223712119329667], time: 203.15
steps: 49975, episodes: 2000, mean episode reward: -28.85664909794594, agent episode reward: [1.72225495219003, 1.8777404981643462, 1.5826252718963552, 1.513471647985827, -15.942900431158382, -19.609841037024122], time: 258.092
steps: 74975, episodes: 3000, mean episode reward: 10.178048317526798, agent episode reward: [3.5848578335591985, 4.022798929728164, 3.5698061356962927, 3.6865642450632214, -2.426031834752528, -2.2599469917675483], time: 277.832
steps: 99975, episodes: 4000, mean episode reward: 12.59168769036449, agent episode reward: [4.31519484174808, 4.391511148450558, 4.069028497192544, 4.343864841183425, -2.306909508106246, -2.221002130103871], time: 286.765
steps: 124975, episodes: 5000, mean episode reward: 21.473972503312748, agent episode reward: [7.102734232839024, 6.957523149212928, 7.1952480481985965, 6.939195519542407, -3.3799728732016305, -3.3407555732785803], time: 290.694
steps: 149975, episodes: 6000, mean episode reward: 24.429851636035167, agent episode reward: [7.900295030661724, 7.920108192417833, 8.099730377110886, 8.001020124384747, -3.3205472981319115, -4.1707547904081075], time: 294.143
steps: 174975, episodes: 7000, mean episode reward: 27.357399984827286, agent episode reward: [8.626398527004458, 9.099456113090914, 9.102269443013945, 9.114135582067885, -4.58280142050817, -4.0020582598417445], time: 294.02
steps: 199975, episodes: 8000, mean episode reward: 28.67851549489239, agent episode reward: [9.029829406108068, 9.39420655353232, 9.469404451043014, 9.504525938879821, -4.4090917714872395, -4.310359083183596], time: 296.035
steps: 224975, episodes: 9000, mean episode reward: 33.97710588879509, agent episode reward: [11.01818337255093, 11.126955030826325, 11.18217269425268, 11.122090553654303, -5.920446329313893, -4.551849433175259], time: 295.67
steps: 249975, episodes: 10000, mean episode reward: 43.03904269017025, agent episode reward: [13.929943809692407, 14.111121036579446, 14.21446277120481, 14.082794337916598, -7.120774909924787, -6.178504355298235], time: 293.809
steps: 274975, episodes: 11000, mean episode reward: 47.904015807719205, agent episode reward: [15.617220118420645, 15.701805981887679, 15.70271009767476, 15.604475273974844, -7.5792223007675075, -7.142973363471219], time: 293.184
steps: 299975, episodes: 12000, mean episode reward: 46.64073074473512, agent episode reward: [15.291614138574461, 15.387950932127373, 15.507678354369094, 15.30857069297757, -7.411645327065323, -7.443438046248058], time: 296.562
steps: 324975, episodes: 13000, mean episode reward: 36.97291550899315, agent episode reward: [12.240318725365595, 12.249230000064468, 12.366704963864194, 12.307412859746528, -5.872864960589604, -6.31788607945804], time: 292.906
steps: 349975, episodes: 14000, mean episode reward: 45.198647680261914, agent episode reward: [15.053108378527273, 15.006916360383471, 14.990484407696277, 14.979653549581396, -7.533735723461165, -7.2977792924653375], time: 293.924
steps: 374975, episodes: 15000, mean episode reward: 50.18082518712048, agent episode reward: [16.568695956315693, 16.49903235340605, 16.52220074156164, 16.51322527183283, -8.270892364126182, -7.65143677186955], time: 296.554
steps: 399975, episodes: 16000, mean episode reward: 51.83627683567507, agent episode reward: [17.10599971245049, 17.075472005893417, 17.02661698650593, 17.053307115194023, -8.943638645469068, -7.481480338899715], time: 295.769
steps: 424975, episodes: 17000, mean episode reward: 42.19880483766562, agent episode reward: [14.11448567438877, 14.042687060374437, 13.932311758393277, 14.003198565835746, -7.328539642902618, -6.56533857842399], time: 295.27
steps: 449975, episodes: 18000, mean episode reward: 44.85310617606573, agent episode reward: [15.066641814298553, 15.001486404994763, 14.888527370232765, 15.002805230252108, -7.6566545486863795, -7.449700095026084], time: 295.337
steps: 474975, episodes: 19000, mean episode reward: 42.225814728062105, agent episode reward: [14.20558755014449, 14.130333687137728, 14.074428434195477, 14.167993069369178, -7.6824170443402435, -6.670110968444524], time: 298.412
steps: 499975, episodes: 20000, mean episode reward: 39.96104460170584, agent episode reward: [13.450168786505067, 13.371992108789044, 13.339096488669457, 13.411754354563575, -8.523756681899116, -5.088210454922188], time: 293.031
steps: 524975, episodes: 21000, mean episode reward: 32.31886227890671, agent episode reward: [11.16825060805194, 11.031240920573, 11.0532041230694, 11.07157745083082, -7.0766919121971075, -4.928718911421338], time: 292.985
steps: 549975, episodes: 22000, mean episode reward: 31.046756622764246, agent episode reward: [10.595026874954286, 10.469990236756624, 10.527715772499036, 10.59097820313517, -6.131517195639501, -5.005437268941367], time: 296.963
steps: 574975, episodes: 23000, mean episode reward: 22.054404995670208, agent episode reward: [8.161313301501199, 8.062952367583387, 8.168535769031953, 8.155215628553108, -5.410235865815553, -5.083376205183882], time: 294.822
steps: 599975, episodes: 24000, mean episode reward: 15.820740099759725, agent episode reward: [6.360817818585125, 6.24259811466302, 6.278501995487405, 6.34062934781687, -5.144221903740798, -4.257585273051899], time: 296.808
steps: 624975, episodes: 25000, mean episode reward: 15.179791100439726, agent episode reward: [6.1742738966444595, 6.058565622391112, 6.050218048589915, 6.129202899777695, -4.329922407879452, -4.902546959084004], time: 295.485
steps: 649975, episodes: 26000, mean episode reward: 10.55489035141182, agent episode reward: [5.151202146487862, 5.011309958546224, 5.042315311232791, 5.077006043488778, -4.524513103356371, -5.202430004987462], time: 294.383
steps: 674975, episodes: 27000, mean episode reward: 11.671710714698827, agent episode reward: [5.098239923304176, 4.9256530435165224, 5.000314403974058, 5.045370641402318, -5.018072937705022, -3.3797943597932263], time: 293.085
steps: 699975, episodes: 28000, mean episode reward: 14.026942707789146, agent episode reward: [5.782433833066933, 5.587629501385857, 5.573307438921295, 5.7134733208386645, -4.679114547887992, -3.9507868385356097], time: 292.08
steps: 724975, episodes: 29000, mean episode reward: 12.457456034611038, agent episode reward: [5.416976048632462, 5.222657707058512, 5.303058891347474, 5.411983017264369, -4.792263959072101, -4.1049556706196775], time: 292.878
steps: 749975, episodes: 30000, mean episode reward: 16.886006400690125, agent episode reward: [6.460139098325946, 6.337128160565731, 6.360739727129479, 6.433399151446274, -4.625485438064961, -4.079914298712345], time: 293.495
steps: 774975, episodes: 31000, mean episode reward: 13.766382347888904, agent episode reward: [5.911753503319885, 5.866383805078816, 5.858573941165234, 5.940623618774619, -5.806946030586311, -4.0040064898633405], time: 288.418
steps: 799975, episodes: 32000, mean episode reward: 9.72502863416706, agent episode reward: [5.0155147510786815, 4.817406388255364, 4.904083021315106, 4.958015894577655, -5.3457489933018785, -4.62424242775787], time: 285.471
steps: 824975, episodes: 33000, mean episode reward: 12.594456807034803, agent episode reward: [5.975867143964015, 5.781869700674502, 5.886529600056381, 5.889042569999606, -5.77793708687948, -5.160915120780221], time: 279.933
steps: 849975, episodes: 34000, mean episode reward: 12.17498775988477, agent episode reward: [5.636941222490475, 5.529921414965742, 5.6660840218904065, 5.695635504998769, -5.113286262518978, -5.240308141941645], time: 279.088
steps: 874975, episodes: 35000, mean episode reward: 17.450032405854333, agent episode reward: [6.541786360613053, 6.523454847921081, 6.530323629053957, 6.568828667124462, -4.944971262886654, -3.769389835971564], time: 278.489
steps: 899975, episodes: 36000, mean episode reward: 16.0131642511996, agent episode reward: [6.164159100229967, 6.059292589219772, 6.238256265301237, 6.247847471143938, -5.840415282730918, -2.8559758919643956], time: 277.169
steps: 924975, episodes: 37000, mean episode reward: 18.139374199948595, agent episode reward: [6.7206803841390155, 6.701565900421776, 6.800381383161476, 6.829158927810505, -5.046592059066979, -3.865820336517199], time: 281.729
steps: 949975, episodes: 38000, mean episode reward: 18.871308256949227, agent episode reward: [7.236565828143505, 7.099001250508887, 7.158267643910411, 7.216267676584676, -6.3827118224888055, -3.456082319709442], time: 279.144
steps: 974975, episodes: 39000, mean episode reward: 19.174802628278556, agent episode reward: [7.378876663048142, 7.290711992194792, 7.278925333101929, 7.349414091465849, -6.379916415001646, -3.7432090365305037], time: 278.545
steps: 999975, episodes: 40000, mean episode reward: 19.6522668454803, agent episode reward: [7.804444519786585, 7.557403890680169, 7.609277115521341, 7.766728320444569, -7.100783251604883, -3.9848037493474813], time: 278.882
steps: 1024975, episodes: 41000, mean episode reward: 18.858998233057875, agent episode reward: [7.775825746614552, 7.538620535664621, 7.599196437476319, 7.644976841547422, -7.612056304816097, -4.087565023428941], time: 278.888
steps: 1049975, episodes: 42000, mean episode reward: 19.22751510590512, agent episode reward: [7.600718783007946, 7.421199236944256, 7.4128427135838955, 7.469999008283865, -7.222610286867001, -3.4546343490478404], time: 278.791
steps: 1074975, episodes: 43000, mean episode reward: 18.026178388174255, agent episode reward: [7.043987045501242, 6.780275458347779, 6.819229155176623, 6.809534277353801, -6.171321864707404, -3.2555256834977864], time: 279.522
steps: 1099975, episodes: 44000, mean episode reward: 14.296799527232357, agent episode reward: [6.45086288585152, 6.213408037219611, 6.207670770512808, 6.372167396045338, -7.1905260119674494, -3.756783550429471], time: 278.411
steps: 1124975, episodes: 45000, mean episode reward: 19.62417310589402, agent episode reward: [7.240764016373384, 7.06790366908319, 6.975548021148883, 7.165393329376835, -5.262581555238654, -3.5628543748496204], time: 279.038
steps: 1149975, episodes: 46000, mean episode reward: 17.838755432420985, agent episode reward: [6.607201929027133, 6.438334472255265, 6.293654753211506, 6.557664315215213, -4.320539033333835, -3.7375610039542964], time: 278.166
steps: 1174975, episodes: 47000, mean episode reward: 19.71340936125169, agent episode reward: [6.9416819873703455, 6.876181734970721, 6.68653776869383, 6.9460402115957836, -4.320856308716978, -3.4161760326620128], time: 277.368
steps: 1199975, episodes: 48000, mean episode reward: 19.471485036296393, agent episode reward: [6.485311589293444, 6.423119949068868, 6.172103949348615, 6.571595849277784, -3.882025083492026, -2.2986212172002953], time: 273.199
steps: 1224975, episodes: 49000, mean episode reward: 23.100608492870816, agent episode reward: [7.814999482000524, 7.803673932246731, 7.644261557342536, 7.910580446492573, -4.518114300740977, -3.554792624470572], time: 274.484
steps: 1249975, episodes: 50000, mean episode reward: 21.56022576845817, agent episode reward: [7.315563110699974, 7.298790939980046, 7.111873791461574, 7.347250719563521, -4.701070122308634, -2.812182670938311], time: 274.774
steps: 1274975, episodes: 51000, mean episode reward: 20.7846304677053, agent episode reward: [7.0143419118459525, 7.073160763301443, 6.9081791684701175, 7.080966772865274, -4.746896424544447, -2.5451217242330393], time: 275.432
steps: 1299975, episodes: 52000, mean episode reward: 22.040067600309868, agent episode reward: [7.315138961841497, 7.398567866942909, 7.281337652845173, 7.352102095952805, -4.00963425466954, -3.297444722602977], time: 276.714
steps: 1324975, episodes: 53000, mean episode reward: 24.58284471830676, agent episode reward: [8.318611887574296, 8.291894703778652, 8.142631715599789, 8.42993627637452, -5.627770674375975, -2.9724591906445283], time: 276.856
steps: 1349975, episodes: 54000, mean episode reward: 25.65213016610871, agent episode reward: [8.514557220916478, 8.563695721151744, 8.414937523986598, 8.656950735556576, -5.152872574736062, -3.3451384607666275], time: 274.374
steps: 1374975, episodes: 55000, mean episode reward: 30.920060522599776, agent episode reward: [10.322962054540763, 10.343261545379974, 10.249423305080896, 10.455014104478305, -6.853962944310705, -3.59663754256946], time: 273.479
steps: 1399975, episodes: 56000, mean episode reward: 26.860448983939232, agent episode reward: [9.05199575300791, 9.021852309592083, 9.00108591036996, 9.174959205872215, -6.591720001145214, -2.797724193757721], time: 275.761
steps: 1424975, episodes: 57000, mean episode reward: 26.636065429922862, agent episode reward: [8.868620231904627, 8.944981127129537, 8.805549237790375, 9.028252784709464, -5.638337606154354, -3.373000345456785], time: 273.437
steps: 1449975, episodes: 58000, mean episode reward: 25.400495531470188, agent episode reward: [8.517039761279706, 8.608133878286662, 8.62208636541233, 8.70686672019143, -6.18724817210387, -2.8663830215960715], time: 275.84
steps: 1474975, episodes: 59000, mean episode reward: 28.204592560641185, agent episode reward: [9.464968904550943, 9.632220033176756, 9.55817799962526, 9.732497179397345, -6.522970816715216, -3.660300739393903], time: 274.002
steps: 1499975, episodes: 60000, mean episode reward: 28.405696958705608, agent episode reward: [9.358395825424783, 9.573539753836634, 9.511488050268076, 9.70595176108897, -6.9137545324694365, -2.8299238994434166], time: 273.621
...Finished total of 60001 episodes.
