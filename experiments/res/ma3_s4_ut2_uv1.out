Using good policy maddpg and adv policy maddpg
Uncertainty type is:  Action ; Uncertainty level is:  1.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -22.630518938289562, agent episode reward: [-36.44952420691371, 6.909502634312076, 6.909502634312076], time: 82.926
steps: 49975, episodes: 2000, mean episode reward: -23.33034225277687, agent episode reward: [-35.68521504129951, 6.177436394261318, 6.177436394261318], time: 106.149
steps: 74975, episodes: 3000, mean episode reward: 0.1809282541485827, agent episode reward: [-17.22409498817585, 8.70251162116222, 8.70251162116222], time: 106.194
steps: 99975, episodes: 4000, mean episode reward: 5.454145143079858, agent episode reward: [-15.585781022752606, 10.519963082916231, 10.519963082916231], time: 105.102
steps: 124975, episodes: 5000, mean episode reward: 6.094643772146127, agent episode reward: [-15.259945898538582, 10.677294835342357, 10.677294835342357], time: 105.205
steps: 149975, episodes: 6000, mean episode reward: 5.024409739867468, agent episode reward: [-13.204314573895855, 9.114362156881661, 9.114362156881661], time: 105.825
steps: 174975, episodes: 7000, mean episode reward: 2.9236136347264234, agent episode reward: [-10.129497732056384, 6.526555683391404, 6.526555683391404], time: 106.076
steps: 199975, episodes: 8000, mean episode reward: 2.167798708537124, agent episode reward: [-9.53265884624514, 5.850228777391132, 5.850228777391132], time: 105.826
steps: 224975, episodes: 9000, mean episode reward: 1.6043997630383964, agent episode reward: [-10.056018062504148, 5.830208912771272, 5.830208912771272], time: 105.822
steps: 249975, episodes: 10000, mean episode reward: 1.115746412916737, agent episode reward: [-10.885953579282845, 6.000849996099791, 6.000849996099791], time: 105.724
steps: 274975, episodes: 11000, mean episode reward: 0.9459803609312919, agent episode reward: [-10.951175027350837, 5.948577694141064, 5.948577694141064], time: 105.473
steps: 299975, episodes: 12000, mean episode reward: 1.2667122952978032, agent episode reward: [-12.57782271666699, 6.922267505982397, 6.922267505982397], time: 105.786
steps: 324975, episodes: 13000, mean episode reward: 1.1031812242649284, agent episode reward: [-12.197917177261745, 6.650549200763336, 6.650549200763336], time: 106.164
steps: 349975, episodes: 14000, mean episode reward: 0.6333670053227307, agent episode reward: [-13.255363152329814, 6.944365078826273, 6.944365078826273], time: 105.695
steps: 374975, episodes: 15000, mean episode reward: 2.378280725114416, agent episode reward: [-13.333474972825424, 7.85587784896992, 7.85587784896992], time: 105.955
steps: 399975, episodes: 16000, mean episode reward: 1.7994420465200411, agent episode reward: [-12.854558900279194, 7.327000473399617, 7.327000473399617], time: 105.547
steps: 424975, episodes: 17000, mean episode reward: 1.8526367651413138, agent episode reward: [-12.780693629456964, 7.316665197299138, 7.316665197299138], time: 105.287
steps: 449975, episodes: 18000, mean episode reward: 1.9686293268321748, agent episode reward: [-12.617815817499388, 7.293222572165781, 7.293222572165781], time: 105.834
steps: 474975, episodes: 19000, mean episode reward: 2.709365373308343, agent episode reward: [-14.308005665123279, 8.508685519215812, 8.508685519215812], time: 106.643
steps: 499975, episodes: 20000, mean episode reward: 1.4145483996171258, agent episode reward: [-13.124269221505335, 7.26940881056123, 7.26940881056123], time: 105.369
steps: 524975, episodes: 21000, mean episode reward: 1.3959323255318568, agent episode reward: [-13.51409807652613, 7.455015201028994, 7.455015201028994], time: 105.358
steps: 549975, episodes: 22000, mean episode reward: 1.8176632406144417, agent episode reward: [-14.234847840306891, 8.026255540460665, 8.026255540460665], time: 104.702
steps: 574975, episodes: 23000, mean episode reward: 0.8140752862529325, agent episode reward: [-15.110224704158666, 7.962149995205801, 7.962149995205801], time: 104.836
steps: 599975, episodes: 24000, mean episode reward: 0.43951521276954975, agent episode reward: [-13.899911431769077, 7.169713322269313, 7.169713322269313], time: 104.144
steps: 624975, episodes: 25000, mean episode reward: 0.2505652266791991, agent episode reward: [-13.751946316586393, 7.001255771632796, 7.001255771632796], time: 100.802
steps: 649975, episodes: 26000, mean episode reward: 0.04756272308533292, agent episode reward: [-14.480245270321747, 7.26390399670354, 7.26390399670354], time: 99.261
steps: 674975, episodes: 27000, mean episode reward: 0.19242438160970904, agent episode reward: [-13.467394982650438, 6.829909682130073, 6.829909682130073], time: 99.723
steps: 699975, episodes: 28000, mean episode reward: 0.5400887180544188, agent episode reward: [-16.15578530804648, 8.34793701305045, 8.34793701305045], time: 99.238
steps: 724975, episodes: 29000, mean episode reward: 0.02254301674974957, agent episode reward: [-14.112672889842553, 7.067607953296152, 7.067607953296152], time: 99.134
steps: 749975, episodes: 30000, mean episode reward: -0.05912037332545117, agent episode reward: [-14.732654552214456, 7.336767089444502, 7.336767089444502], time: 99.501
steps: 774975, episodes: 31000, mean episode reward: 0.14982619062607183, agent episode reward: [-13.653417477805775, 6.901621834215923, 6.901621834215923], time: 100.525
steps: 799975, episodes: 32000, mean episode reward: 0.15412943704092974, agent episode reward: [-13.98989878034966, 7.072014108695296, 7.072014108695296], time: 100.031
steps: 824975, episodes: 33000, mean episode reward: 0.6263412041433166, agent episode reward: [-14.126148204837795, 7.376244704490556, 7.376244704490556], time: 99.139
steps: 849975, episodes: 34000, mean episode reward: -0.8283291110995605, agent episode reward: [-14.79442480008958, 6.98304784449501, 6.98304784449501], time: 99.838
steps: 874975, episodes: 35000, mean episode reward: -0.7785234991458685, agent episode reward: [-13.244250840759058, 6.232863670806595, 6.232863670806595], time: 100.112
steps: 899975, episodes: 36000, mean episode reward: -1.0889688881304307, agent episode reward: [-12.365681576691012, 5.6383563442802895, 5.6383563442802895], time: 99.903
steps: 924975, episodes: 37000, mean episode reward: -0.10808862095323793, agent episode reward: [-13.605407123934802, 6.748659251490783, 6.748659251490783], time: 99.461
steps: 949975, episodes: 38000, mean episode reward: -0.5151481446934962, agent episode reward: [-14.164132098734202, 6.824491977020354, 6.824491977020354], time: 100.65
steps: 974975, episodes: 39000, mean episode reward: -1.1753075130517783, agent episode reward: [-14.61246037253259, 6.718576429740406, 6.718576429740406], time: 100.511
steps: 999975, episodes: 40000, mean episode reward: -0.6676476554950452, agent episode reward: [-12.832416568595573, 6.0823844565502645, 6.0823844565502645], time: 100.37
steps: 1024975, episodes: 41000, mean episode reward: -0.997470555580824, agent episode reward: [-13.441291123916804, 6.221910284167991, 6.221910284167991], time: 99.689
steps: 1049975, episodes: 42000, mean episode reward: -1.1942304799358547, agent episode reward: [-13.509523203628314, 6.15764636184623, 6.15764636184623], time: 99.688
steps: 1074975, episodes: 43000, mean episode reward: -1.7421243309939471, agent episode reward: [-12.579610256255732, 5.418742962630892, 5.418742962630892], time: 99.004
steps: 1099975, episodes: 44000, mean episode reward: -1.643076349243768, agent episode reward: [-12.661511771870511, 5.509217711313372, 5.509217711313372], time: 98.438
steps: 1124975, episodes: 45000, mean episode reward: -1.8154173618040936, agent episode reward: [-12.87145859826803, 5.528020618231967, 5.528020618231967], time: 99.684
steps: 1149975, episodes: 46000, mean episode reward: -1.3965019286973344, agent episode reward: [-12.340932987505662, 5.472215529404164, 5.472215529404164], time: 100.282
steps: 1174975, episodes: 47000, mean episode reward: -1.2082310875320545, agent episode reward: [-12.56931167809721, 5.680540295282577, 5.680540295282577], time: 99.328
steps: 1199975, episodes: 48000, mean episode reward: -1.0156122293184535, agent episode reward: [-12.27311993518423, 5.628753852932888, 5.628753852932888], time: 100.53
steps: 1224975, episodes: 49000, mean episode reward: -1.3707667871441185, agent episode reward: [-12.858880018425095, 5.744056615640488, 5.744056615640488], time: 99.934
steps: 1249975, episodes: 50000, mean episode reward: -0.7843803727728164, agent episode reward: [-13.701569038632202, 6.458594332929693, 6.458594332929693], time: 100.61
steps: 1274975, episodes: 51000, mean episode reward: -1.1128258482733329, agent episode reward: [-13.71835724472807, 6.302765698227368, 6.302765698227368], time: 100.167
steps: 1299975, episodes: 52000, mean episode reward: -0.9395801807328955, agent episode reward: [-15.3510008961405, 7.205710357703803, 7.205710357703803], time: 99.968
steps: 1324975, episodes: 53000, mean episode reward: -1.5117161669061339, agent episode reward: [-13.703408110740739, 6.095845971917302, 6.095845971917302], time: 99.411
steps: 1349975, episodes: 54000, mean episode reward: -0.6903859465388166, agent episode reward: [-12.863453248331615, 6.086533650896399, 6.086533650896399], time: 99.373
steps: 1374975, episodes: 55000, mean episode reward: -0.7558119901634442, agent episode reward: [-14.3878572151891, 6.816022612512828, 6.816022612512828], time: 99.248
steps: 1399975, episodes: 56000, mean episode reward: -1.773261105623522, agent episode reward: [-14.606428814460873, 6.416583854418676, 6.416583854418676], time: 99.673
steps: 1424975, episodes: 57000, mean episode reward: -2.4281725034389847, agent episode reward: [-13.713013929247362, 5.642420712904189, 5.642420712904189], time: 98.841
steps: 1449975, episodes: 58000, mean episode reward: -1.5547832978049791, agent episode reward: [-14.792551980439814, 6.6188843413174165, 6.6188843413174165], time: 100.39
steps: 1474975, episodes: 59000, mean episode reward: -1.969593377064547, agent episode reward: [-14.034194007213747, 6.0323003150746, 6.0323003150746], time: 98.588
steps: 1499975, episodes: 60000, mean episode reward: -1.7756425158697609, agent episode reward: [-13.991362879414785, 6.107860181772513, 6.107860181772513], time: 77.859
...Finished total of 60001 episodes.
